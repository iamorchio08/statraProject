/*
lumenize version: 0.9.12
*/
var require = function (file, cwd) {
    var resolved = require.resolve(file, cwd || '/');
    var mod = require.modules[resolved];
    if (!mod) throw new Error(
        'Failed to resolve module ' + file + ', tried ' + resolved
    );
    var cached = require.cache[resolved];
    var res = cached? cached.exports : mod();
    return res;
};

require.paths = [];
require.modules = {};
require.cache = {};
require.extensions = [".js",".coffee",".json"];

require._core = {
    'assert': true,
    'events': true,
    'fs': true,
    'path': true,
    'vm': true
};

require.resolve = (function () {
    return function (x, cwd) {
        if (!cwd) cwd = '/';
        
        if (require._core[x]) return x;
        var path = require.modules.path();
        cwd = path.resolve('/', cwd);
        var y = cwd || '/';
        
        if (x.match(/^(?:\.\.?\/|\/)/)) {
            var m = loadAsFileSync(path.resolve(y, x))
                || loadAsDirectorySync(path.resolve(y, x));
            if (m) return m;
        }
        
        var n = loadNodeModulesSync(x, y);
        if (n) return n;
        
        throw new Error("Cannot find module '" + x + "'");
        
        function loadAsFileSync (x) {
            x = path.normalize(x);
            if (require.modules[x]) {
                return x;
            }
            
            for (var i = 0; i < require.extensions.length; i++) {
                var ext = require.extensions[i];
                if (require.modules[x + ext]) return x + ext;
            }
        }
        
        function loadAsDirectorySync (x) {
            x = x.replace(/\/+$/, '');
            var pkgfile = path.normalize(x + '/package.json');
            if (require.modules[pkgfile]) {
                var pkg = require.modules[pkgfile]();
                var b = pkg.browserify;
                if (typeof b === 'object' && b.main) {
                    var m = loadAsFileSync(path.resolve(x, b.main));
                    if (m) return m;
                }
                else if (typeof b === 'string') {
                    var m = loadAsFileSync(path.resolve(x, b));
                    if (m) return m;
                }
                else if (pkg.main) {
                    var m = loadAsFileSync(path.resolve(x, pkg.main));
                    if (m) return m;
                }
            }
            
            return loadAsFileSync(x + '/index');
        }
        
        function loadNodeModulesSync (x, start) {
            var dirs = nodeModulesPathsSync(start);
            for (var i = 0; i < dirs.length; i++) {
                var dir = dirs[i];
                var m = loadAsFileSync(dir + '/' + x);
                if (m) return m;
                var n = loadAsDirectorySync(dir + '/' + x);
                if (n) return n;
            }
            
            var m = loadAsFileSync(x);
            if (m) return m;
        }
        
        function nodeModulesPathsSync (start) {
            var parts;
            if (start === '/') parts = [ '' ];
            else parts = path.normalize(start).split('/');
            
            var dirs = [];
            for (var i = parts.length - 1; i >= 0; i--) {
                if (parts[i] === 'node_modules') continue;
                var dir = parts.slice(0, i + 1).join('/') + '/node_modules';
                dirs.push(dir);
            }
            
            return dirs;
        }
    };
})();

require.alias = function (from, to) {
    var path = require.modules.path();
    var res = null;
    try {
        res = require.resolve(from + '/package.json', '/');
    }
    catch (err) {
        res = require.resolve(from, '/');
    }
    var basedir = path.dirname(res);
    
    var keys = (Object.keys || function (obj) {
        var res = [];
        for (var key in obj) res.push(key);
        return res;
    })(require.modules);
    
    for (var i = 0; i < keys.length; i++) {
        var key = keys[i];
        if (key.slice(0, basedir.length + 1) === basedir + '/') {
            var f = key.slice(basedir.length);
            require.modules[to + f] = require.modules[basedir + f];
        }
        else if (key === basedir) {
            require.modules[to] = require.modules[basedir];
        }
    }
};

(function () {
    var process = {};
    var global = typeof window !== 'undefined' ? window : {};
    var definedProcess = false;
    
    require.define = function (filename, fn) {
        if (!definedProcess && require.modules.__browserify_process) {
            process = require.modules.__browserify_process();
            definedProcess = true;
        }
        
        var dirname = require._core[filename]
            ? ''
            : require.modules.path().dirname(filename)
        ;
        
        var require_ = function (file) {
            var requiredModule = require(file, dirname);
            var cached = require.cache[require.resolve(file, dirname)];

            if (cached && cached.parent === null) {
                cached.parent = module_;
            }

            return requiredModule;
        };
        require_.resolve = function (name) {
            return require.resolve(name, dirname);
        };
        require_.modules = require.modules;
        require_.define = require.define;
        require_.cache = require.cache;
        var module_ = {
            id : filename,
            filename: filename,
            exports : {},
            loaded : false,
            parent: null
        };
        
        require.modules[filename] = function () {
            require.cache[filename] = module_;
            fn.call(
                module_.exports,
                require_,
                module_,
                module_.exports,
                dirname,
                filename,
                process,
                global
            );
            module_.loaded = true;
            return module_.exports;
        };
    };
})();


require.define("path",function(require,module,exports,__dirname,__filename,process,global){function filter (xs, fn) {
    var res = [];
    for (var i = 0; i < xs.length; i++) {
        if (fn(xs[i], i, xs)) res.push(xs[i]);
    }
    return res;
}

// resolves . and .. elements in a path array with directory names there
// must be no slashes, empty elements, or device names (c:\) in the array
// (so also no leading and trailing slashes - it does not distinguish
// relative and absolute paths)
function normalizeArray(parts, allowAboveRoot) {
  // if the path tries to go above the root, `up` ends up > 0
  var up = 0;
  for (var i = parts.length; i >= 0; i--) {
    var last = parts[i];
    if (last == '.') {
      parts.splice(i, 1);
    } else if (last === '..') {
      parts.splice(i, 1);
      up++;
    } else if (up) {
      parts.splice(i, 1);
      up--;
    }
  }

  // if the path is allowed to go above the root, restore leading ..s
  if (allowAboveRoot) {
    for (; up--; up) {
      parts.unshift('..');
    }
  }

  return parts;
}

// Regex to split a filename into [*, dir, basename, ext]
// posix version
var splitPathRe = /^(.+\/(?!$)|\/)?((?:.+?)?(\.[^.]*)?)$/;

// path.resolve([from ...], to)
// posix version
exports.resolve = function() {
var resolvedPath = '',
    resolvedAbsolute = false;

for (var i = arguments.length; i >= -1 && !resolvedAbsolute; i--) {
  var path = (i >= 0)
      ? arguments[i]
      : process.cwd();

  // Skip empty and invalid entries
  if (typeof path !== 'string' || !path) {
    continue;
  }

  resolvedPath = path + '/' + resolvedPath;
  resolvedAbsolute = path.charAt(0) === '/';
}

// At this point the path should be resolved to a full absolute path, but
// handle relative paths to be safe (might happen when process.cwd() fails)

// Normalize the path
resolvedPath = normalizeArray(filter(resolvedPath.split('/'), function(p) {
    return !!p;
  }), !resolvedAbsolute).join('/');

  return ((resolvedAbsolute ? '/' : '') + resolvedPath) || '.';
};

// path.normalize(path)
// posix version
exports.normalize = function(path) {
var isAbsolute = path.charAt(0) === '/',
    trailingSlash = path.slice(-1) === '/';

// Normalize the path
path = normalizeArray(filter(path.split('/'), function(p) {
    return !!p;
  }), !isAbsolute).join('/');

  if (!path && !isAbsolute) {
    path = '.';
  }
  if (path && trailingSlash) {
    path += '/';
  }
  
  return (isAbsolute ? '/' : '') + path;
};


// posix version
exports.join = function() {
  var paths = Array.prototype.slice.call(arguments, 0);
  return exports.normalize(filter(paths, function(p, index) {
    return p && typeof p === 'string';
  }).join('/'));
};


exports.dirname = function(path) {
  var dir = splitPathRe.exec(path)[1] || '';
  var isWindows = false;
  if (!dir) {
    // No dirname
    return '.';
  } else if (dir.length === 1 ||
      (isWindows && dir.length <= 3 && dir.charAt(1) === ':')) {
    // It is just a slash or a drive letter with a slash
    return dir;
  } else {
    // It is a full dirname, strip trailing slash
    return dir.substring(0, dir.length - 1);
  }
};


exports.basename = function(path, ext) {
  var f = splitPathRe.exec(path)[2] || '';
  // TODO: make this comparison case-insensitive on windows?
  if (ext && f.substr(-1 * ext.length) === ext) {
    f = f.substr(0, f.length - ext.length);
  }
  return f;
};


exports.extname = function(path) {
  return splitPathRe.exec(path)[3] || '';
};

});

require.define("__browserify_process",function(require,module,exports,__dirname,__filename,process,global){var process = module.exports = {};

process.nextTick = (function () {
    var canSetImmediate = typeof window !== 'undefined'
        && window.setImmediate;
    var canPost = typeof window !== 'undefined'
        && window.postMessage && window.addEventListener
    ;

    if (canSetImmediate) {
        return function (f) { return window.setImmediate(f) };
    }

    if (canPost) {
        var queue = [];
        window.addEventListener('message', function (ev) {
            if (ev.source === window && ev.data === 'browserify-tick') {
                ev.stopPropagation();
                if (queue.length > 0) {
                    var fn = queue.shift();
                    fn();
                }
            }
        }, true);

        return function nextTick(fn) {
            queue.push(fn);
            window.postMessage('browserify-tick', '*');
        };
    }

    return function nextTick(fn) {
        setTimeout(fn, 0);
    };
})();

process.title = 'browser';
process.browser = true;
process.env = {};
process.argv = [];

process.binding = function (name) {
    if (name === 'evals') return (require)('vm')
    else throw new Error('No such module. (Possibly not yet loaded)')
};

(function () {
    var cwd = '/';
    var path;
    process.cwd = function () { return cwd };
    process.chdir = function (dir) {
        if (!path) path = require('path');
        cwd = path.resolve(dir, cwd);
    };
})();

});

require.define("/node_modules/files",function(require,module,exports,__dirname,__filename,process,global){module.exports = {"tz/africa.lzw":"Rule\tAlgeria\t1916\tonly\t-\tJunČ4\t23:00sČġ0\tS\n"+
"ĀĂĄĆĈĊČĎĐččĖ\tOctĨĚ>=1ĞĠĢĤħ-ĪāăąćĉċĴ7đēĕėMarĞĝğĦĤ1ĦĨņĬŉįŌĎ8ŏĔĶœŕ 9ŀřĥĢŝīňĮŋıĵĒŦŒŔ\t ĿŘłŮħĩűĭŊİč2ħŷő\tFebĜŬſśůƂŇƄšıƈťƋĸĺğƑģ\tńŞŲƅŢ2ĿƊŧź1ŗŁơƓƁƤƗŴƇƩŐĶęěƨƠŃĖƳŠƵ93ūƪėSepČŽƯŚŜƕşųƆǃǅƸėNovıŻƱƢƿƃǁǓ4ĝč45ĶApŕMĒĽĿ 2ŜǝǐƥƘǥĝǆķĹŻŤǰŜƣǠǒŢǦƛĶǈǊďǜǿǟƖǡŢ7ƷŸĄǪĞǧžưǏǀȂıȐȅǇǉĞĐȗƾŅȁƦȜŎǹœĕ Đ 0ǲșȦǶ97ȩǖǺƞǯȰůȀȍțč7ŤȪź2ĝżȱƔȚȧɁɃȸȇĞ2ŻƯǞȥȿɌ98Ɖȸǩŕ2ǧȯɉƲȳǂɚȞȹ\t3ǯǱȽƿZĒňfĉca/ŉiĈŃ:1Ǳɼ ėLMTČ8Ď Ũż5 ɡ01\n"+
"\tʐȼ9:ƼėPʂŵ1ʇŔżʎʐƢŜȎ\tWE%sʃǥ0 ƍbǰʊǾĢʏʐǝʢCʥʧı46 Ɲʋ7ʲʠůėʤʨ95ʻJanǰ9ˀǝėʶ˅63 ɝż4ˀȼħʢʤʦ˅ȶʼĹǰʞʳʡțʶ˞Ȝ9ˡtǰ6˙˦ȧ˝ʸč8ʚȫˎŜːET\n"+
"ɯne˕tlˊtic/Cape_VĈd́-ś34ġ4ɿ\tʁ˅0ʿʟ-ɬń\tCV˅42 ȇˀ̠ɢ̣VȘʊʽ15̡̫Ķ̤˟ʊǘvʮʋ̡̫ˏ̮˽˿ɱɳɵNdjamenŌĦɻ̨ʀʘĴ2˹˂ʣA˟˫̳˘ʟǝǝWA̰ıɚʛrʋ8̢ͣ̈́͘ɰĄɲ̇ɵAbi͊ˊĖȰďġ8̛̙ŵ͗ʟʌ̢Gʂ\n"+
"Link˕ͲɴɶͶ͸ˋAΎɵB͌ako\tΈΊΌΔ͇ΐͷ͋ΓΕ/ΗnjāΜΉ΋΍Ρ͵Σˊίͳ̉ĒΙrĕΝήΠεαΒδΏDΙźλΟΦοΤρɵFreetowěφϋ΢πνΏLo͍ʐϕϙʹΑϊϠ/ǘuΙchotĺϟψϢγϤOϧgadougϸάΞϖωϱΦSao_TϜăϮΰϰΓ̃̅̇/St_HeĂ͏ΜƃEgypĺʩɧęlČǧ˚ƀŰƖКМО94ɛȒƝǜˁħȾĬЩНʹȑƋɝУвЦǴ\tжЫ4йȆȠȉХдăсʹɒǷǨȔżнǳƳыǥɒǹа2ŎшȌеЛзǥ3ʹǧǗǙбќɖўЪѣɧлч̭пѕˆȷȒȫČгѰєџЫ5Ŏč5ŤėаёѨѺѫѿɎѵaȬĿХѓЙѻı5ū˵ĿŹҌЦҏШґѿҔ96ѤĨȠ3ħɔщрҜҟĳ9ЬĶ҃ĿҦѝъҩ8їȸСȕҙȲқ҇əѢǹҸɼҺɊҐҽ8Ǥəҁ\tѶё͡һѪѠəǕҊȬĳѹӅӑ9ħčҭҗбӎӄҼәȖʍ̢л̄stύiŻ˚ǎӡӐЫˆĞĢҡɐӨtThuŖȋѩҳѫƈ0ĐǹɐƼɆӾ҆зԂѴƋɐӺuǮӽɭӿҨԁĢ҉кϹ\tӸԐԓгҲԖԋĢӓԚgӴԟɕԊƞӥѭԛ1ħԈԔԫӴ԰ɧɐŪԩҚӱԵЮԎȠԝӻԩҧыƈƭɧѶ̴ԺӏԀԣՇӀĚȡՃԡՅʍǸҷΫɪՋӰՍԬՏɏՀaөԞԲԠŅͅͱΡ̊irΛɬ5ġ˫͔̜ʪƝˀ̷ыEʷ˽ƃGhˊƧӛЬɒȟǊ҄ǿʔħGH̰Ƴվրƙւ̧ĶDecɩҍȋΆͯ̀թξccrċ-˚:5͓͕̚ţˀ΄\t֏Зʦ˾ͰϤBissaӼ̓ġǱƈͿ֪ɾˉˋż́˺͚̺֬Хėֲ֛֝ϤNaլoͶĞʔ7ɻĐճƙ;СˀɔėE͛ıҤշ:ҤĶBס̦0ץȄėשAU˒׬ʟןр͛ЉεאגͶϾddֶ_͵abċ׹Ώ׻խ׽ϤAsmŔ؆έχΡ؉דiϖσr_es_Ђ̄͌؇͈ב؊ؗϤDjibϸ̆آϥؤؖϖK͌pāϼμΦؕ؋ΦǬϵ؀sՂخػؗIn؀ˊɶntր͏ĉvΛكذ׽نوnζmoխْ׼مهĊٗȫϫte׍͆εǬnխvİ֤:4Ł;ך18ҵ̫Ȱٰͽ̙M׀˫Ũٷٯ̖ҤͿR˟̨˸΃׊֮·ƃΉbyŢ5ф҂ǻՇ̷ԻăڎڐҒҶȒׂѧԉڍتڛѿҿȸ҃ūڗՌ̚ڣڑ՗ڞ͹ևԳڢڏڑǧԅңѸůژڬڵҒԄҷڱ֙ڳƖښŢҵͦĝėлڲӛګۆͦэəҡүнҧې˵ڷɜѐĐҎۏڭͦۀȒیĝ۞՜ڽڤəۢƜǻ Ѣ҅ڴ۩8ѾӒяũۃێۧۘə۴ʅҮۭ۸Ԫ۱Ţȵѭѐۥӗۅ۠Ӝԍۿĺ ܈ۄĬېՆڦҊŕӸӫӃɣ܊ھܕɧаܙĉוԳըϤTĉpolӬȰ֧ځֿ˅ƈͬۨċ˨˴ˆˍʟ̷נ˼ۑܴېܷ˅Ӛʛyʋ͟ʐܼрܾӜʻȇۮ״˥ů݁ջıȵˬ݇ץ͙պʃՆ̨̼żʪʰݑЦݔ˩ܕݘɟ̿Ħݚ̢ݜƤʛuĉ̆uŚəڝ۬Оں۹ܜĂݱݳiݵͦܖƋŨĞ܁щݿiݴĤԂԙ܎ԜբtSՑڪ՜ފތӴ0ԥƫܘޒޔƻԉͅ ٕ٠/œݲދށĤĠ5˚ܱı̝ˀ̖ĢޘޫӋU˩ƳǬխ֠ΛčǄԷцɒ֭ڼ޼o޾ףޜѥǚĵ֭ҧ߇߉Пǹʬҹ߅ګߑc޿ЬۚȒ̼ʄӭڡƖߙߛޮРՑ1Ȼ܉ĬߤҒԾސ2ūߏԡ߭č6܍ėƺɓČޖݽăߵҟ߸ɨё߳ԕࠀ7گƋߺɆߡڻߘٚ߈ߚȜࠉхֆߪܒ߿ࠐߒȵҫȶƫҘߗۧࠇ۫Ǩԛࠄ۰ߣࠚࠒɁࠂԆǽࠨ߬ࠪߛɂߧěࠧ߫࠙޽ࠫȵޏۋࠦɇ࠰࠹ࠑծԘ࠵бࠡ߾Ӌ࠲ޚ࠽Ңࠖࠍզ޻ࡋԂߋĘՑ࠷ࠎࠢࡓԤԮԧƼࠅࡒ࠺ࡄԶɄȬ߄ۦࡉ߭Ն߯࠾ԧ ࠯ߢ࠱ࡢԵړȓũѢࡈЧࡲࡃࡴߧТ՚ȯ܂ࠩࡳݞԵѢۋȔӸޠŻ߽ࡺࡂ߉ࢅڸǊקۮࡱ࢏ࠒ࢑՘Тƚ࢕࠘ࡊࢄʍݸࠥ࡞ħݣоࡡࡼܟՐТ Ŏ࢝ࡑƃࡪʍބࢣѷࢌ࠸࢟ࢩࢳ\t؏xސࢊࡗұࠆ࡛ږ02քӋźࣀ࠶ࢍпࢲ՟ڞޕǽࣂࢨ࢐Ֆ࡝ࢌࢷ࡙ࡩࣄߝࠊߨࡸࣔࢱࣝࡾߠࢦ߆ࣄࠤ߹ࡗɇ࣢ࢃࢺȉࢫŻ߲࣍ࣕ࢘ʍࠂѶ࣮࢜ࡻࣖ1ࠂҸࠄࣣࣵࢠٴՈҋ߼ɓ࢖ࢹࣾࡍߺȉࣧࠏअࡕӌ࣭ऋ࣏ࡕߺ࡯ࣚݼࢎऌࣷƚǹѮ࣓ग࡛डȸѶ࢔ः࣯ࣖƼढȔԶࢯࢂࣽठࡵՉɠफऴࡄࣇ܆ũ߄ࣼࢗऻࢢӞࢭजࢧऄࢺƟयɞ߄हुӴࠌोČࡸॎटऻࣞ۶Żसࢸࢲ2Đࢽޝޑөࢋऑ࡚ࢠ3क़ڔƞࢮीॖӴ3࣪ɨआलߐ࡛3ࠂаऱࣔޣϤָ̊b̄nɴͺצȰ־ٳĎ˔ʽफ़׉Ŝ߭˳˅Ӈͨż˯΃͂ˑۡ঍ůএջ٦ϖEl؂בՑٮܯ4ٲ֩˅̕ ׂׅ͙ͮȜʻ˖ƭচħজ˞٦֞Ώœpuϑו԰։ްč0˔ٿܻ׆C׸ؒϖ়াoϖBঁtyώظؓ٨̋৏৑uΪmbݲؑϽϤৎϑϖG؄ࠐ֝خ৥৐ϤHؐ৖৬৚০ϤKiϵܬৗ্৴৮ΦLuৠয়բhӬ৳ঽ৵৿ݵτИƖאmتǓҭॠօĻnԒॕਏ਑܄ǧਔࡶਖਘޢֳΦWΊdϪekŮ8ʔ̘ٳʅ̨ʬ࡯˹קǇরৄ৆ŔݭĘ̦̑ͤݏ־ݣ਻ǳ਽ʹਹͩƨݫʱৈ͙S੅Ӝʪʈƨ਻ːעӜ̘˖ۮܴਚͶċͣসܦ৿aϺɺ1Ġ॰ৃĎ˫̪͠׆ͮخL੣os৑ˊguਆৌϤੱ੤৑֢zza٬lĂੰੲੴاϸضৢعΡ੼ੳزΊفբaઆ੽੻تώઃઅ੺੢ગਊˊdઌ৘Ϛઇৼ̄ث৻੻દ׏Ċ͍κઝ઎બΦPٚϑ-̼oহޥىReĚiĒɩٯś֧੩ߩবĚ޳׆Rܾ઻ٟىœhăĠуٯন΀ৄˈ૊ʟ޴̢SCʃƳ੎ь੆ࠕਠľṶ̑ԕ૤ѡʹۊࣉŕޠǮ૪ܥɰϖJoտǹsৠrgɈܯ޵ਯ9਱Ǝਲ਼੭ਵĨ੏Ӛੇ਻૤੎֍઱εૹૻ૽૿ଁ৤բĈӼخଖˊଘݲଚؽ؅؅̀ૣuઢěɁ࡬ࣉҘࡨञޔଫȜւ8۔ڕФऋଳ͹Ɂࡵлק଱п଼ବȵےଷख़࣋ђș੡ΡKտrϑumীȼ૘֪ɪଐପ͹৊ݧĢʪׂʉż̀׵׆תخ୏Ŕ୒m૸ਁકƃTીsǓ߁॒ՊȣेƖୱnֶ୴ࡕߟआ୸ҧ୻୽ȃମߕɟƽ୹Ĭ஄୳ȃࡵ҃Ȯࡁ\t஍Ǣृ૱ࣳࡐ஋ăகȃ஗ߟǰऊ࢞஝૦Ʉɞࣴࢸத૮୶ࢮ̷ஃ୲Ǣࢴ࢈ɞज़ࣛञபЬலࠃɇமԡஸǣѬளࡊਗľॆڼிࠔ४Ǽசய୼எѬ࢒Čஒऋஸ॒ࠞ࢔Ӯ஛ஔரȏ࠭Ƞࠌ΄ȤƳ௕ࡍӌࠗȘۧ௤ܠ܀ࡐ௢୰௜ͦऎࡗ௧ӯࡉஸٵݖ૟աॣࡗ௙்அͦऔɅ௓ƒګஸӚइࠠ௙ே௰Ԃ३ଯࡇఋఆ఍ӵ߂࢓ࢥƱ௮୺ఔԃࡌॡ୊ݣ௵ஷజȢࡅொఠ̡௢୍ε஍ʠЭܰਯ˶݅ୣ˰ޛʔҖ\tʗ˅ૈʈߩܴத݂","tz/antarctica.lzw":"Zone Antarctica/Casey\t0\t-\tzĚ\t1969\n"+
"\tĢ8:0ĖĘAWST\t2Ħ9 OĊ 18  2ĥ0ġĢ11ĺė\tCAīĭ010 MĈķ5ķĹĦļ\tĤĦŁĩŅĮľıĳ2ĶĸĺŒľŀĘŃŘŇ2 Febĸ1Ĵ7ĺuŒŔħ\tŗT\n"+
"ĀĂĄĆĈĊČĎDavisĕŁĚzĜ957 JanĴ3ŒŰŕĘDAVĬĝ64 NovŒŵƉƋğũūƕţ\tƙƛņ0İĲtĴŞŐĻĢ\t5ƬƮĬřŉŋrĴŉĮűƫƗƭƚƾŇŮƳĸƶŠƹƻǈƽņ1ŨŪŬ2ŮǅĦŲƹƖŵƽŹāăąćĉċč/ŋwsāƇĘƦĝ5ƟǙƓŒ6ƬMĩǋƱśƴĵŏǑĢǓŵǼWŸźăIndiƑ/KerguelenǱęěǴƸȅƬTFĬǤŻǧžǪƁumātDUrƄlș ŉǲȞ947š0ƬPMƜƌŨƐƒ14Ƥƈȹ56ƠƢȽƼȰȥȋżǨſǫSyowaȜǳƌƎɅĸĠƹ3ƬSYOȥRuș\tTroȴư5\tmaxŁǁ\tlđtSuțĿǞĭŀCEī\n"+
"ɬɮɰɲlư4ɶɸŁƳɼɾʀʂűĕŀUTCȦǦŽǩƀ/ʍɳƥěĮ0ŎǷǗƤŀʦʏ%sʠɕȩʤVostokɞɋƎDecĴ6ǹƬVOŅʵȨʣǫRothȔɝʨƊĝ7ɍ˂˄ĴŒ-ɦǈRɪĬ","tz/asia.lzw":"Rule\tEUAsia\t1981\tmax\t-\tMar\tlastSun\t 1:00uċĥ0\tS\n"+
"ĀĂĄĆĈĊČ79ċ995ĔĬepĚĜĞĠĢĤĦĨī-Įāăąćĉĸ96ĐĒļOctŀĝğġģĪŇĔŊĂ E-EurŎĴčďđēĕėęěŚŃ 0ĪĩĦĬšeţťŧũĸĶŐĻĕSľřłŜŶŹňŻŽŦŨĳŐŒŭŕŗƈśĢƋīƍįżĀsĳƀČĎĸ84ļApęďŵŷŅīĭƞ ƠƢƒƤďƤ3ƖŘƭƛ\tƝŋƴuơĉƣčƨČ9ďƅƇŲƉĢ2ĪsǀŠƳƵǆƷčĻǊǌĖĘƘŴǒĦǔưźǗǄƶŏǊ2\tonlyļŰƘaŘ23ƯŷƲǂǘaǇ9ǭǯǱļƆĿǏSǶ\tǸŷǁŢǾȀƻƕůǠȈǢǓŸƱƎȐǚ9ƻǊƄĽȇŁƙ ǣ0ǔȎƟǩǙǫĹƔŔĕŖŘȖŜȧȩŠZǯăũ/Kabā\t4:36:48 ĕLMTċ890\n"+
"\tɕɄŹĕAFɏČ45ɔɖɅň\tɚT\n"+
"Ⱥnȼĳ/Yerevaġǒ58Īɋ\tɍɜȁ4 ėy Ȧɠ\tǹɘ\tYERɻ57ɾĘʃɗ0ǃǅǿĳ ʈR%sɻǋʎr 31ʁȷʃʅīǦʘSʜʢȆȦ3ʥɷȜŏAMʚʜ5 ʭ2ɽȦǓʐŷəɎŐ7ʿĦʓǪĊʴʶȋ012ʞȦʸʽǤ˅ɣʴɦƞɤzɮ˃œŮǟűȤŴʑșǧŋ˚˜Ǌ7˞ƼǡŜ5ȍȹȻɤɫBakĨǹČ:ʻɸɺĸ˽ɿʣʰʆBAKʋʍŰ˕ˇȭa ̆KˋǝːʡʣʾɕʄǺŹ̑ʪŐʢAugʠɓ̙ʦ̍ʕʳZ̓ĹˏʭȈǶʮĪ˕ƩZʜ6̴ōƒA̫ʛ˃̴A˛ę̼ʶŻ\tDh˷Ċ2ĦķȃǲĕJŃČȋʦ˥Ǽİ͈͊ˌ0͎ǰ͇͐ecʄďʻ˱ŉɨɪĉ/͚kĊɇˍɈʒɌ˂1ɑ̥ɕ˰5ǹ͌ļH͵94ʢȳʃɇ3ɣBUʊĸ4ˏ̂1ɟ̙˰·ļI̞ɝ̮ľ΅ɢļΉ΋Č5ʬľ̤ΛʆDACɻ7ʢŰȦ̸̙ͰΈDɏ͌͝ΥīͭĊBDͩͅ˴ͫThimphĨͺɶɆ˾΀4ʍ̡̣ΐʃΓɣΖɻ8ʍ΄ΰˀ\tBTɏɧ˳Indĉn/C͉goǔɄ49Ͳļ˿Č0˄ΒϛIO̷ηΕϹϠɩοa/BrĠei\t7Ʌϯ4ͳɹ΀26ʞʃЉΔĕBNɻ3ʯ̙ɶ̅ИϾͪЁRɲϪǯ\tɇͦЌϋɜ88͸Ч˼ϭɣRЏЯΆΈΊɻ΍ʎyʃϯʆJΗ΁ʸ̂ʠΛЕĖ˂͆S͉ngΌī͏ļ͒ŜƻƿǦDыэяɝʧ΁Ǟȳńǀ˱͘ăьФΌďђȔƬŒїŷљ˙PRCƦŒѫǟǲ ƨѯŹѱ˧ѳѵƤŒǝȅƇś>=1ďƿȚѲѴƦ˫҅əƫĬĠ҉1Ɯ̛θРЀ/ѧю͉ЇН˰4ƻʹɻˍʃНƱћ\tC̬Ϯҫŷҁүν˳ȽUЄmqЇͺŶͽҨ̀8ϻĕXJ˘˧HKѩǮ͟ƩҕďǹΔǦѥ\tӋӍѸȆʄīӓƜǖӊӌɝѷӏҔęͽӞ͗͆ӘӣӎȄĕD͢ċ̚ΔȪӗӢ΁˫ѸƪƬƻөӕӫӸύӮ͠ӱͣΔөӶӬ΁8ԄǳaǲǭӿǻԁΌԍΠѠƗȵӴӟŉ˙ԋ5Ȃӥ\tѡ2ĻԉӠİԋϮĸͻӐę҈ҊԜӪԟӸԮѸNovӳԨԞӡԭǉőƨѬҖnҘԍԓŹӖԠƨѸѡʡԳԊԶǜՂļԹԻԱӒΜՒĸ6Ք7ŒӦՅҘŒՉҎԿČ՞ƁաԤƗՙե՛ԩăԋ7ƻѸԆӜԳԀԵƁ͞ӯѹգ=ՈΜջը9ƂՎծҗҊհӵ˲ϿȽHǯg_K֓ЈɅɇлӂϳɽȳΤМŷӘӋұʢԆˑоϛскʸʭϑ֡Ź֣̒ʛ͆TaiwɲΌӤտɿċĻѽҜ˙ֶָֺӭ։ƽѣƌ˦İֹׄġɝӺԣӼֿ׊ʧѰֵַ׏Όגտ՗ӳҍ׌ă׎׆ԌԭǞ־Ҍқ͇יׅאצԘ˭ת׋ӖפׯԡԎՄ׳חѾ׭כΠǭΠՃ\tן׻Ǖ׵ךץԮΠķբ؆ј׾؊Ք6ԙ׉ס؈׮՝ўؔѓ͓ז˥ѿ׍؉ׯ7Ձ7ȡה؏ט׃أƁئȡѡ؆էآؙĵվ͒͠lנ׫ءףحض׹խؖѤҝȽׄpІ\tНαЫɐő Jɲʁ1ҳрWт3Ϙŗٓ֩ртɞʹΣ2ʢŝĦٕī׶Ҷִ˙ėcaĨթƹőǭՄկպԔ٬aٮٰőٲ6؃ןՙՑղǟٻ՝նԣǴٶׁעڅٯ՝ՍډǠٶզڍ٭ڏթĻѸڊ֋1Ѯ׫Ӗڗټժ׈ͤ؟Ӷڢ՝҄ևǞהڔքٸ˧کթګΫ˭گ֎Ծİڳև؁և؃ڮڝ׀ڠ͆ڼ7ھյڷۂڧڄۆئ˫Ȳ֊ՆҊԧձںăۆ՟ېɤҕՙەӔڱڻٺژևԗč˖۝ۋڌڡۣټ7ۦЮۊۓΐیͨҸɫکДɄٍ͌Čˎِْģ٧ڎĨMO̬Ĺ ֧͌܃ҵҰ٫˧CyƫǄƁښדӑіۄ˙ܒܔǥևܗտرǭסۗүܓЄܟՠفשۃŹօİܝܩիفرزڄܲܕĵҒۧԯցتՊܹ͆ܪם͠ӛԦ۵݂ܨܺۥܵƗܤͧ݊ܞս˝ǍȣųġܥݒܳƸŐԍՄԛ۫مɫNicϫŏǒ1ͼɊ֜ȁʢ՗ģ4ʃȧܧݓEE܈ɊȆݴŷ̺ŏݸͅLinkҞݥݧƒƐoو/ވݨaݣπbiliĈȋ:5ϯҋ۽ЭЯɴޜǞTBЏɽх2̄ɣޤỈВ̙ʑ̨ũ ެ܈άĘʠ٤ʤ̦׫ެтʝӼʁ9ު޲ʖGݹ̾Ǭ߄ŤƐƀ߇܈ɽ̯ˢňߌſƒߏ߉ȯ ֟ȵ̴Ǧ߇޿̊޸ߞްɷߖƑŏߙδĦɽєȦϵɕ̧ʲĊ߫͜фߤߓ̗٦ߦʆ߇ɦξȽDޕң˼ǒۼݮۿّnְٜޫLкˏFebȦʢȌ߼ɕпɣ֫Ό֭٢ЛࠚϛTࠐիмʁࠡيϛWޭA͜ʒ֮ʍƮ࠙\tࠛļࠤࠀ۷֖ͫlͮtĊͺݬޞЮϒޚͼɣͿк΃ŗчиΟ΁ΎԐģΑ͹ΜĕϕΌΙpࡅ۠Źࡘɝʸ֟֯ࡕшϕР Ƚّͮr࠿֘ϴ:ۿ֜86ώ̢ģЯЉ࡯ˎΝЏ3܊͢޹̲ύࡰީ̙ЉӁ\tJAVЙˏ՗Гࡖ\tࠬB࡙ːǸٟٝࠜࠟpʮ࢐ш࢓Ԗм܃ĕࢠΠʒɿ࢞ɣࢥՂ࢐ʆ࢓ࡧȽPǯtϥ˷֘1ࢇɣϲɒɊࢨࢆࡰࢹļP΀3ࢎԺࢩļࢫлࠋȦ߃̙࠶࢚͑١࢜ࢗࢿ࢟I࢔ɝࢽԐࢣ࢒ࣘԭࢧࣜࣖࢪࣟթݳࠎࣉ࠭ƦɊ࣌܂ࢿࢮࣘࢰ۸͊ơǠЉʌ֙۽ȁࡸޚДլMࣄࣆvࣝࠬT࠮Θ ࠓࠕ ࣓࣎ࠢٞ֬࢝ࣨࢤࣲّ࠭ͫyapŧĊϯ2ǒɉࣺࣅ ࢏࣏ࠫޭΌߑΣ࣮ࠢшΨтٿࣩ࢘ӉİIrץۯƦɣǴ٣؟ؐ˙शसԍڥऽؗ͆ुؤط҆Ŀ͔ॆीषׯ۱ӚƇǸیӖै̟ܬԐĢܚܯث˧क़Ǭƃԏӧݐफ़׽ॏץǋॣݖȋ०ӟॗॐƓग़ӧׂ݀ॠॲǊּ݆ܷ॔ॱ४ܼĹ।८ाय़वॹĹঁ؍Ȣ঄ॎॸֺεёڒॵঅ२এɳĦ঒տ݇ॾेॲεͥĦҧˠ঍ؼঞঐĦড0ণ݇९؇ধঘ0ڑֽǠॅদ३঱঳ॼĿশ״র߷ॴথ१ॷইন0ܡ঻ূ॰িεृওȋॶ׬স͜ৎছॽॖৌ͍ˌҋঃटকৄăक़εķ͌ড়७৞঎৅ঘࡻڛ঵৑ؽ\tৢˍԢ৖়ঝ৓৥ƻ৥ȡ़মिগ৛৺ˍȡভ৘৸ˍॻঢ়৯৙ڞفজਆ਀৥˫৥ঋ৽য়৒਑ˍਓˍঋਅ৩ৡট0ͽ৭ঔڌৰ৲ਣԣਏਟৱਡऽ͌ॕՄ২ষਙਯਢব॔মسਠনʻুঽ׼ৠਭ਽঺ो৐ਐ৪ˌ݈ਰۛਖਦ৙ੋਢۛਞلਇ2ԍਰਕ৮ਗਧਮ੘ਢਝৗਬ৲Δ͌Րਲ৾আ਼ঘ੥ফǞ੔াਇࣅˌКਊੜ৙ੳ੦ਸ৶ੈ੫ੴƨ੦ৼ঵੩খ੉੦઀ফ਄ਹ੽੃੬Œ੦੍ਜ਼੏ੲએফ੓੢لࠁɫTehॲͼҥ؃ࢻڞʰԦɈ؃Tόί߲࢑IRт7ʍथɡ࡞ॲમ̬ĶʰΔक़ષܐ৅qƦ৴͠ש੷३ીƤھƧײઌुેčڈ঴ęՐઓএ૎૊Ƥبӑૅ૕ƦՔɒ੆ԛưȸॿ૖ګ૟ݠߓșǥ੪੃૎५εۛהģ̚Ǥؠধ૮পۛѡ૳ʦૣޒЁ˶ghdadޙࣸЌϱ͵ͷݽࣸɆࡼɻͶުƩт8ࡑн޼વaીAͅ˙ZiЦѝفєѢ૔İଠଢࡐऩՖԺଦ੕˧଩ׯҦف૲ͥ਴ନଡଳ੅բ૳ଧăଲࠞଵӑڟৃਘହପɞفן૳ݵ਻\tୁׇܘѭޙ୆ৰ୑΁ਉĕୌ৷଱଺Ԗग़ԑढ़īݵDୗୟࣚ਎Ƈାସୀ୨װ΁ঋଡ଼୕োଟ୯Ԭ৭Ѻ਋୶ପ5চ͠ة୅ੁେ୮୽୿੆۴͖୏୘Ρୃę୬ୖ͆஌Ѫԣ؅՚ੱ୞୽ૂܾͽݵ৿ୈ׷஛ۑƽķஊڍ஌ૐ஀ӑǭஞ૬ந୪ौӾର஠Հତ͓ୣ૶୼׷଼ঌࡻਬ஌ৈ؝אଷ஑஺ԭு७ড়ி୯5୚ࢉŴஸடஅ׷௎ӛԈள௓ԭ݅ஜ৤୭୐ௌ௛১਺஧୯إஶغ ˫ି௟ପ௦ڥݫઌ୘اஎˌ૛ழĵைɤ̢ڦோପ8௹ةѼ௞୘௿ரו௽॑௎שԍ௫ఄ௕୫௪௘௬॑௡ۜƬܮஃ୧௾కӛ௰ఈ࣫௴ҙ௶௙Ƥ৕৉ѻ௱୯ɑ௴ӵఃపॊ७ʠ఩ପ૟ਤȋఘஹஙׯవד௻Аళ఻ஔ૑ȋం௅఺ख़॓Ŀஐ୵ేॢశ2ķ఍୯ȁఆ ஂযெǊனܾȦణఓŐ౛ఱస஋౓஼ଶ౞୘΁ଵాఌఒ౩௹Ǵ૓మఴ௹ӛలటॺু۴౒ఴఏौ౗౤ఴక़୻్উఆ1౅ౌ௷Ĺదঢ়Қెಌčౕಀ௤ఴరఖǑ୴హಒಘ౶৺౮ୟ঑డ઀౳঱இணĢ҄ಡЦঠ௴ऌ˥௒౟ಮ౉ౄ˥ಁ঱஢ত౐ಱமಢĦ಺ૻҒಬ঱ౡ಻ԗದ͜ೆૻȟೄ͜౦ҕ௩ಽઅ௙ε஼ਅǦಸীӻ೑௄ఙஒಿেݎŘರ୎ಖ঱કఢՄFri҉ి஭೔ಳĦ௎ૻೞౘే૰ಈએ೎্ೣĢĻ೦Ӗୁৣఆ2ਓ೽ˍನ஽஬ഉড়೜ஏ೷ಲഄˍూ͠ૻ഍஘ழ৥಺Ǵ೬೮=೰೉ജആಠചೕˍȒȱতട೯ദ೟ெ৹ˬ಩ԛം૿/JɮǄaĂmޙ͌ޚɽࡲࡄ̙ࠇŶଉ͑΀଒൅ŷୁIଞ˧ّpץɉୡܿಛಲ൒ൔۦ஍७ȉt҉੘ఒ൚ଳಘہ۳൘૬൤࣠קԏǲڂೱҜચπokyo࠵ࡰɶޛଊЬϗࡿcࢁΐŞल࣑Ьُ࣭ٔदрC٘ٚtࠍऎī൫J൐İJor଄ؤೆଥ౗ܰă඘කसȟܠોݚ˙ජඛخƁઑǲ৑Ӗඪस௎؅݉ඩ඙ණܻ೿ܷܦ඲ؤಎբభ୆නමूఆෂԝ͆඾૝డਗහඣ॑௹رබ൑ළఉఠբഭԲݢභැѶŐɣѡේ඼්ූƦಘ־౭ස෥ෞǊഋהഇ෎෬ඹĹഖܾࢸෲෝ෴५ವ෱ඨ෕෭̭డಐஃා෻ھȞ˭෣ු඗෦ౚݞܾซො฀෻೗Ƈ෣ౣڄ෋Ƞฐ७ธזȸලฎĹಘعଯ૵චࢉรংεٴঌǏടภǕยෞಣಮ૨ĝρŇȘษ෋อ৛ฮǴǏฺౄܛด৆ೋݏಊมෳ৆஼رఘ์෺৆౵ǎŁัƛ๒็೨৛ؕƈ๘ȘӶ฾ഩفոͽ෿ญีˍƨȓতใφๅ෫๓৫๬ഫѡะ೭าƍ൳ЁAmđɳ˼ǹ4ൂЎЙඊɕݵ෋ށִ๼/Alđtǲ˰࡯डݮ́ࡒʂ϶ʆAࢻ·ِĠࠖη߅ĉࡨɍ޶Ӆɤࢻȁ຤ߴຫʵ̾ε߸ʟࡣаຝɺഷQyzylළɃ˼Ĥԡࣺນʀປ઴ɣKI̶ĸຠ߯٣ࡅʆ໋ໍƸࡨƫඑ\tຕஃ໔କࡋඐबື໊໌ϖˏ߁໡໛ລĊ໔ຩຜ໣໕෵඀ģફ໚ϛQY໰ȁ܀ࠌČ߻жʱȬ̩Ċ໷̽߬েːຶαļ༄࠹֐ɫAqtobă຃ɶൈຆ̀ާບࢅ້Ʃ̈Йʒ໐ຈ໵ຝ༠Ʀ̠໘໨׫̇Tໞߜٛ໡༊ə༧ૈ໗ʟ༫ˆຯ༭໭ࡕ༦Ϟ̟໲ત໮໪ɤQTˋຳ༈ࡔ༥˖ཇ།Сຏ༑ڏͼŅઢަ່ࠧແʆFOࡏ໏ຢ໑໮ļཝࡏ6ࠩ໛ȅHEϖໟ໙༳Ĭཫ໥༷໙໩ຯSཫ༽ཌྷཪཬཁ֧གྷ༾ʒ༻ཇ܈ິ ȵ໾̌ྃ཈າĦ྆ຶཀྵəཏഷOषغઠбൽ༚ཙ༝ཛɣΊA༡ມࠌརཱྀļྠ཭ུ༹ஃྠ༯֟༲ϛྨુྪ༤ྲྀ༁ƀྠ̬ɑ࢖Б˓Яޱຯྐྵߚǋ̴ĕྲ̔ཿ໴࿀ྷƒཞଝྍ༇έྐϛ࿎ऴăKyrgຼŐจլ൧҉఑ศۡ࿗࿙࿛z࿝ॳ७ݡݑ˙࿘࿚࿜˪ীุǐǒ࡝୏࿯࿧˝ೖ˭വۖഷBޗhkeކɄɵб໅༛໇ྜྷྑ\tFRUྡྷ༣ຮ࿌຦တU޶̕޺̘ྦǦဘ޿̠ࡶ̖྾໒ī࿹࿜KGཉྎࡨࡶˎສဪ࿖\tROԂව௏Ŝಅİဵ့ಈஸ୏ွΌ൦೑௑૬၂ɝķױ൞֋෪ಋă၈ĺ෯ೝ౞ၑ஍୹ಪၕံேൖ సಲၖ๕ొ౑ఒၖఊज़๧௞ၦ෇ค೸ြၛΠܼ6ऻज़ڂ௫ၖၲɣӛՙ၎ၮၐၰčܼЭ൮ցൢ಑ၿӸϗෘقႅ૴োຎƆoɂɶഇޚฮࢻ0Ɋ໧༤ω໊тࠊ܁༤࣐ࢉඍЙඏ໙Ⴃࠝࡠऑ ӄඋ႞ʋ༛ʟྥࠪΔ၂ֳɻؔီϐЯ࠶Ⴗҷ༎ͫP൷юङюࠪ࠘Ѝ႘ႚ༪ႜ࢑K႟ˏඉඅႤඎ༰໠Ⴂ֪࣒ϏȦࣧඒļაဳLࠔɲପ਩ృ੗෹˧უbქׯყഗݏนܦწხ̀෶ශცİჵnღჸႌ၀ڄჼღഝ঵ඟ࿤ɹფჽჯುƗၽӶᄃჯೆ෰઄୏ᄑ̀ೆఝಕჴᄊ୽ၲרज़ධ͆ᄗၱ՝๞෤˙ᄤڽஶɳᄕڍᄪۇතට࿭ძᄝගᄲȔදჺăᄰးה෈ԴᄵჭᄋƁး௖ၭᄐᄶƦՁႊᄹػ๲ᅂჶƤՁ५಩਍๨ᄼᅊథᄬᅏฅᄣᅚč෨ᄡၭษᄪ૟ॢᅎᄢᄩᅠ౔ڥಊำᅟᅃఴപ˟โ૩ณ჻ᅬඥಓ࿫ᅷᄴᅹᅲ఻ķ๭๷ᅾ׋۶Ⴡ଀ІЄǷࠆɷൃޠŷᄗຌဳNB඙ɩ൸Č3Ք΂ஈᅯӀ٨ӖᆖᆘeᆚȞᆝǞոಉ݉ͩࡨɫKu഼a_Luτŧа4֚Бݮˍ໻཯ޚ˰݈ƅ΀༇߯໡ࡹऻພЙࡾდ࣯ҚͽMພ٘БᇏɕࣁůᇌѩႬ༤Дᇋࠥईऊ໳ეႪуऑူࣣǳᇛ༶ᇗࠪʆMYϟᆮȽᆱcςჇࢇĤ࢈ࢻАޯᇘ࢑Bཞᇍ܃ᆤrᆙϜཞұࠒࠔᇤႯѓ࣒֮ྜྷҬΝሃླᇮሔůᇲҝϢϤɲ/ėlϤveϬുᆏ༙Ͷൄɡ5ˤů΀ၳဦǳࢌ\tۅ֓oغƺᅋ෷ᄻĖሷሹ૏රฌۘሿ෌Ǌݟ๮ᆆᅞ٬ቅᅓฝฯቊᅰቌюሸ͜ჿה̰ᆍᅐڻቅಮεլӛ቙ಛڨቝೀࣿ͜ȕȤȊ൱ږብ۴๭ᅶŚቫๆቜቔغ৻ളቐቲŘݚຎ֒vଆͰΆᆽሩɒʸϏສHOሴĵႮሀŹMቅኊVჀདUěɲჭǶ޸ࡹДˏᆾኇ̢ࢭྟLྡᅅ܃ኑቶ\tUእንҞϨoiჭlsֺДҬࣺ༇ኈᇐྦྷእΪ኎ᇯኤኦƺ༷लኩϪغCኊာ႙ရከቅዊ܇ຍ࠺Ёȿth຀dχɈĤڞ໅ЯϓΕକ໴ҥȡNPϟƳP˷ޗ࠿ಹ௴Ա०ƹ࿤ ያkይ৆ᄍŘዱ׊Ҍղድዬĝ৆းଥᅪǂዶዸ঱੟͝ଭԻᄨጇጁዮ͜၄గෲຎȿषᇷЇۻɶࡱኅϴ࡜ϔٟ࡚ጡ˥࡟ᇧࡢཌዡࡗтΡऑ·ሲĕKAࡏΫྼဦጀዷጂġPႸስƳE࿛ptǇʌൖఢᅸżፁܓፄǚፆΠቈ೶ቃţፂፍȮɵၝጆŢፋፃፅ၊őථѢǦචፔፌ፞՝ઊĿௗᆇƎ፜ፖŪ6೵ƗૼᅿżያĂĝބăǊ৤ྎฑ೭Ҙၟዴ፷ሥࢴϿ፼ೊชᎀ۔ፓᎄ፹Ͽ࿼ڥ૳೙ዿᎎᎆăຳ೿న೦ۗጀ፸᎗ቧ͜૱ၔፉ᎞ᎅ፺Ꭱ෽௣᎝᎖Ꭸ೺ವฺൡባ᎕഼Ꭷ᎐Ħጋਗ਼ˡĝ๠ቛ፶Ꮅᎏ᎘ᎸౕጏŢᎭᎷጌವซ᎔ᎬᏀᎠ৥ഋ़ᄇ݁ዪᏎᎮഊ౫ќᏅᎿ᎟Ꮧഏ୓วዳᏔጐᏝᎷᏟտϏว෉ᏕᏥᏂᏧ஀௻ᅀ፤ᏇᏮჿᅇᎍᏖᏦ஬๫ঃ๯ĨͦᎾᎦᏁเആᏢᏫᏤᎶᏮᄙทᎋੀቒᐈᐃ৥๵˟෢ᐍᏛᐂᏏਃቹቱtั᐀ᅞຎGaz͋ࣀ႖ྚϳʒϙຉ്ୟݸкࣛʀຶȧ፥፝ފ߈Ⴙʍᇈཌݵൎ܈໴ຊ෦ᆔŐऍ୴ᐘᎨᑃ্Ⴛ࣍ʁƛݽʆᐯ৔࣓ᑏʒᏴĄᐸ৛ᆑᑐཽᏐ࢖࠲Ƌ༤ᐴᑖᑉകᑋ໡ݵĕᑑജᑔᑇϿᆔഷHࠔrಭ˼Ӏণ႘ᐪࡌൌŹୁᑑࣚࠧᐳߧፕƀᑃթᐺຢၞᑔ౟൏࿃ᑀŷ຋ᑘ፼ᑬᑣᐸ͆PςቀଏԸମፚăᒗޕ໎కऊᅝᐏİᒟቀርడᄮӖᒧவѸฦᏛ\tᒭኍਿᒫᒖᒘᅅᐅᆭዔሠɲޕĊ-ඃ்ረϲƧɽ֧ʡٕޱࡲ܉Ώ჎ŹᒭPHላࢢሏආऩतࣇࣨᓑᓓዓᆉ/Qኛ૒˼Ͱݭኅ܌߽ɣGરგĠଓəʪ\n"+
"ރޅᆯͫᓡ࠿ʟȽ˶ઞַߔຎRiङdh૴ɇໄݮύ༈პႎଔɦᓳkᓵТᔁଅhᔑຏdeġᓲބᔐȽᔀᔂᔕᇵuֹitഷSބgच඙ăᔆᇃʸᆾʢᇮᔮ˼਄ᇆʸᇈᇞϛᇓᇡȞᇎႡኣѣᇒᇔЙᇖᕀࢿ࢈ᔼࡊᇝࣈᇚᔽлᇣྀ൹एࠞᇨྜྷᇟᇫᔽ՞ᑦᑅᕘƅGཱིመϛSᕠഷCሸomb൸˰˻˽ᆐࡅ˻ੳሯҩዤભጣᇀᒉ϶భ઻Hᕸݼᕻஃጧ٠ࡢ྽ȧጥጬ̷ࠧԦᑍ̳ϚшL̈ƓთήᖍጰϚʆᖑ༆Б߁ΐᖖዠᕷဳS࿙ȮͽČ਱ಙ۞൩Ꮳİᖣ೭Ūᖦȁণѡ൰፵Ĭᖤ፰಺෰௝Ꮎᖷᖯ՝ዺӳ᎜ыᖸڇ፨ႄഒᄈᖮȮཧၬᎳܦᗋ፰๏Ɨ೷Ӷᗑᗇವ੥ᖶᗗڴ௴ਾቬӖᗜőڵլීᗃ˙ᗢࡴᒹᅩᖫ୏ᗢ઱ᗫ஽ᗏᗄᖿሺ቎բᖼቋ˧ᗢ8ඥ૊ᅖᗳᗨᗅ҃فᒣ਍ᗠᗴȮࡳ೿ᗹᒥѦᘃႁ౺ᗭڍᗼႂፑƗՐᗧᗻᘐႃశ۴ᘈᘂᗵᅡুᘙቴᘏᘢఫ௯ᘁᘛᘢ఼Ꮸ૚ᘠᘬȮᘮ৉ᗚ፬ᘡᘳ቗Ꭴᘦᖾᘹ࿩಩ోᘎᘽŪᅭᏠႭሽᗢฉ౏Ꮣᗮᘐᙊਪ॔ჳᘉᙄᅔ࿟ᘻᖽᙉઈೢᙀᒱᙉঁቈᐜኩᙈᙎ፽0ᙖ഑ᙣᖿ቟ആᎫᙓᎢু๸ЇፉᙃᙯᒛԻउᎋᙝᗅ೾ഐဏᙹᙩݩᏃᙶᒤᗖᙻ৚శᙱ ͋Ꮨ৥ڭҕฒᘼᗗതተቩᎼ๹ᙳᚒ৚ᆄԚ๗ᚗݑຎDađscܕࠇᕭኟᓧᑚƱᗅᑯᚠǄэ༔ແᆜࢄညྜጱ͇U٘༢ཡ༤ٌߴ܊ᚺယέဤ޻သѰᚺအႬ9໾sᚸTӈስຎ˶юk൵ᆺǣབྷൾ໿΍ĥ؃ޥɻۼӼᕁࡗΩᔛᓴᓺФᛖᔝɫᒗჽm_Pᔙᔄᛧ᛬ͫᛔg᛫ᔖViᔙࢴɲăഷćhᔪჭŘǹͻɅᚩᇽဋ̃ᓩଔHဓᚽጸ༻ླྀᛃ޸ᛅᖎ້ཅA᜖࿃཮ഇྊဖĊ઩܈გْ໽ဥལĕ઩ཐҞDuჭЇ຃ዝᜋе࿅\tᓫᔎᔜᔖᜰᜲᔖMǄٮŘᔧᚢĘͮϣແ႕ͻᚶި᜸S˗໎ᚼྤྵᕣᝑ໖ႛሲӕʴྮ༱ᚾࠣ᜝ཱི᝙ངཷˊᜟᕌᝤᜣካ༅࿝ᚸU̶ഷֶsဃ᛾ᚳЉޝຘᜍཚဎआᚻྣຣᖘྂᝪ᝽᜗ʟ᜙࠴ྶʔƀងᝧʭྫཅᝯᜦᝮᝰᇴɫ֒_Ϩi_Mބᔄࡹ֚჊ᇆᇖā໙ស࢑Pણ޷໇ᔺʆIΩ࢕ᓈࠗʦࣝIγᕕ࿒ɽ჉ᇥሑफᕗϷឯבྴ឴ាΠᔸឤᇉឿʋᛌឱ̲࠴ሙৱោܠ᝿ݫᛤৱΩ","tz/australasia.lzw":"Rule\tAus\t1917\tonly\t-\tJan\t 1\t0:0Ě1ĝ0\tD\n"+
"ĀĂĄĆĈĊČĎĐĒ\tMar\t25Ĵġě\tSĥāăąćĉ42čďđēĕėęķ0ĢĠŌģļħĿĪłńĮēıĳ29ŋĢĢĻĦľĩŁŃĭņĺepĴČ2ĸŎĢĤšĨŀ943Ŕ4įř\tlastSuėŭŏşőŢŴŶŖŧOctĘŷƄōĸĤZĎe Ŀtralia/DĲwiŉ8:Ŷ:20 ēLMTĈ895 Feb\n"+
"\tƻ 9ĸēACSƱ1Ƴ9 ıyƺƼƾ3Ģœǁ%sTƇĄWĪ7ŹŦįƍƏŽſƁƃġŀƔǕAǗĉ7ĶǛŘĲĺƂ>=ĚƒćƆŲǧĪ8ŷǬ\tǝżžƀƂŝǤŏűĽǖǹǚŅźǮǡǱǳǣĹŠȇǸĉĊƋįNovĈŬȑůŐǷǨ99ťȋǭĳȎǲȃȒǦǗƫ06ȘēDecƐȬȠȆŒȯŌŬŌŜȨǿǠȂǴȭȢĴȾɉ08ǜƎɃȁǢŌȄŰ\n"+
"ƖnƘƚƜƞƠPerthĘ7ƨ3ƪ4ƭ\tƯǄƳƵȵcǋĘƧŏǐWǒǄŵ3 Jāɱ ɳǏǗǧɷɖƗƙĆƛƝƟ/EucŽɲ:35ƪ8ɩɫƲƴ ɯɾƧ4ĶǐCɶǓŔɺɼlʝƨʠʂʢʄǷQǘĚǼǾǟɑȹǥʯǘȦŗ\tƷbɐǡȬǶȔʰĉƳĪȗēʴȀˁɆȺǦ˅ȤōȤŃɂȪȐɓɇȇHoƞdađȖŃȖŷˊɏʵˍȟʸ˛˝i˟ˡȤŷȖŹ˖ǰȫɆƆɗəʈɛʋBrisbĖă1Ĝ1ƄʖƮưʙ5ɱ̆ĸǐEɷʱ̏ĜɴʰA̓Ǔʅɘʇſ˽ƠLƥdemĖ ƽ:5ʔ56ʗ̌ǅƴ̖̑ĩ̔̚ǩ1̴̘Ą̛ɸȥɻɽƻĈ̗Ģ˜˞ˠ̽ʮȔSʱǹĶ˦ǞˌɅ˪ȅǦ͍ˆȲʳɏĉʷ͖Ƿ͘98ȿ0Č͑ˀ͔˙ˏ͠ʺȳʽƸū˂ĺ͗ǘ˲͐͢İȍ˶˘0ǵͳ͙ͬˈĢ˵nȏĶ˸Ϳ͌ˈʲȧ͹ĳƑȑ˃Œ͡ȥͮŻ2ŃΈȓΓˈǻ΍ŻȞ˙ΒľΔȊʼΗĢΚʹȖ·Ō͸Ż˨ͩͽ˚ΜȰ͚΍ApŚͲΛΤɋĬΟǮαɒγΣĄ͍Ȱɍ̧xįιȩͻμʹω\tϋɎƏ˗͞ɕ˺̟ʉɜ/ḀŽˮăƾ14ƪƬ̋ɬʚʾɱƾŏǀǂϫǇǉϮʒǏ̶C̸97̺̓ǍǏ͍Ǒ̜Ƿɸ6πʼǾϘˎ˫ŒІɍǼΰ͓τ;νĄЏ͏ϖͨДĈЍľІŜ̹ȌϏ΅=ɍΪЅͭǼʾЛϑЩǩͶ8Ě΄ȏЮȔɸ8ˣ͢˥ΎЭШзȉǹȲд˷ΑΉЎтͮЊͻ·͕ɕЯ͢ČȖ΃н˗э΢чПǹЈƌɏȪΘϙȡрˆɍѓКσѡȻњȖğȤɁǽўϐЌ͟ѣȤǳήУоцЖAƱȰĢǼągѺͪОЗɋĚϕͧЋюѢшζͮώǯХͼЕǦѾɊБςГжҏŌϊaόǀκғеΪϛɚʊƠ˜̃ɠ\tƾ4ϥуɪ̱ɭ Sũ̻є̚ǃĪ1̯ǝ̩1̩ƒҺНɴEDɸċƶƸӆ̒ϻЇӏƱ̷̜Ҩ˼Ҫ/Cur̀Ϥʒʔ2ɍϪ̍ҷҹ̓̐ϰ̽ҽĉҿ ӁęӄġӆȠ̚ӊҾ7ӍƹӨͅų͊ʤ̹́ʨӼ̑Ӕ̾ǦV͎ˆ͸ˋɄМͫȔԉǩʻŧЬѨпŒԒϼбίͺҔҝľԚ8ȲѦф1їυљĄԢԤёКіѩԈǹѥѮѧҜѳяԑ΋ˈ˴ѕѲѻԲάɋԝĳԗՀǷԉѿґu҃Ն҅Ѵԙ҈οԶԎԱՈɋηʼҒҌјѼՉҙρՅԷՇԺϓҊĄҤ՜ԩ՞ɋҠҢѰϗԿՏϚʆҩϞMelboӜ̞Ǎƾ52̰ϫƵϭԄɴ̶̾̕ևǏԉӕǔǷNԊͷՔʶԸҎľ֒ԓͮЬ2ΡիǦ֚ԛǹгԾԟԘ֙ǹԔύթղ֑֠ǹԜѹժҖְ΁ˆѯŻ԰֨Ą֢ԣъ͜Ŝ֗Ѫֽћˈѯԍ֖ҍׄA֢9˓ƴֳֵ֮Ȕ׎ȲȰՄ҄֯וɋҀθՌךɔׅ֘Ȱѷͥ֕˩ճף׍՘ґ֧֭դŒ֒ȰќѹՎכײխϔҡ֬ФҦױ֩զ׼ҋדӇմ̞նʋSydɘˡ̗ϧցփӥֆƻөϸć֏֋ؖӽ׬֏̝˻̠ә˿oken_Hill̪ĵƨ̊ҴքӺӆǀEӬƳ̯҂ 23϶ӪǁظȤǈˠ϶ǎӾЃɸϽنǏ֒ىםٌχĄϺЄȇLH֤сͧ׷؆ף֪ٗЙԦŝδăٟԋ׀͒ՕƒěϷַֹٞ٘͢ԞΆ٣φ٦͢ՙѝƏ͝٫Ĝهׄٷׇͣרβ٬ٿǕٷ׏ˈיժ٤ɪٯȤחѸɂٜٶ٘Պҁנڕ٭ڀڗŌצͦհךچԹħٟҐҁׯ׿ƅԪڧՠΧқ٪ĸږ׺է՛֮ڎڮɌ׻կыװƅڜؠϜ̡/LordةowƘ̐36Ϩ̲ؓօӎ֌ύطиӃř̴هٟٗʄҨntĲƎicƠıcquĲiƘєz۱ʙǇȚvصӫӋӀƎӂӲŌӴ̑ӉӋӹ̵ؙؕ̈́֊ӭǇώۼ ͅsɱ۰۲Łʖřؼ̎ۖӐԀ9ӒܘԆ̔ƫ̆ƙκ̩ɨ ɦ۾ӨȠŘIҽۂIndƟnӚh̀ſ̧ćɤ0ŭؒӤۓش̓ܺєCXƱؠ\tܯܱĖӚocoćې֞ƨєʘĉܨƻېهēCC݆ŲFijiˈԴȤșțҥхŏȠЖݠݢڃՊēԖҜܧŞĒǕݮݣȰŜǼ۵ĴׂŮĸݭݡݺĞמڰբՕݵĹ-ݸބɉ̆ސмھǱ2ͼٝރݯܠΌވݩĚދ΃ގޚĞΙĞмňޞɍޠݷݟޏܠΦŧި˗ЧڳެȇݹސŹէݾڍݬޢޅԧڼį޲ͻު޵ލ˺\tPacifۦ/޸1Ġ̬ƨɨܾĊƵӁ26̏٫޸FJ̔݇ߋߍߏc/GambۮĳƭƧ5ҰرݕĊւǝɾ-ϯєGǍߤߌߎߐř۫esžƭϥʀے߶ӯƎ߹ЀźAR݆߉ߥࠂߨTahitݣࠉ̫ƧӮߘ̈ࠎtɱ-ؗįTAHࠕƗߊࠁߧߩ۬mĒϦƪůے84ɨɯܦϾǌʒ߻ࠌĞ۷Gҽѿʛȶؼؾۖݛhܭ̣nk ࠗ࠳G࠵ࡖ࠲ߐSaipĖۂࡗߐࠚƜwaĘߓʒƄߗزĪࡆ̓ę٫ēGIL࠯̞ࡤߨEܰɟbӜņ࡫2ϧƫࡅࡁ࠷ࡴߊHOيǇ߸̓ࠩܪࢋࢍڋɾ1ދēPࢌǔϛࡻ/Kì̧ࠞࠞ࠷ĜśۑߘࡱƻࠩĜ4ݔINࢎࠦࠨࠪƮࢲ̿ܗƼ࠸ӪLࢹࡣ࡜ߨıjӜoĈĠࢄذࢇ̏࢓M࠮Ī6࢏ࠏӨࢊ࣏࢝ʆ࢟KࡨjƝeƥࣈĝƾࢆࢫ࢈࡫Ӫ࣑࣓ࣗࠧ࢑̈ƿ\tKWѽΝʇgؼ0ߞ࣯ࣗࣁߦߐChuuk܅ͥĝߴ̱׏ࣦӽݛHUࡹƘ࢟Pohnpࣟ܅3ܼւ࣯ࣥ࣍POࢳ\tࣼ࠘ࢠݏƜ̅Ĝ5ߔ̯जܩ࣯KOӬܛࣹ࣫ӪरलȤझशऱࣘɘ࠱ࣽߨNaӜu࣡अࢰࠌޖɻ̨ԧझݚ\tNࠔŔւܕ्Ͽ࣯Jल࠽ࣵęࢻ࣡ॏ॑ࢴϵ࣯ࣕॡǕNCǘђϼӣģȶޞ٬ݫނ१३ǩԴ7ѯ֝ČӽޡŲ२ˈٹįɯࡪѡЖॿȖ׵ɂؼͲ߈࠰࢟Țumeࡩࣧʔ4इӋւňęࡎؖȠॿ२͋ħNZĪ֞ͮݾ חށŏআথĉӢΖǮ Źٽİ१যȥԴ3ޓѱХ޴ۀهমদС9়גҔԨĹMসĪ3ŹŁһҤڕষॾহ৏ŔєҸŪڛূ্ŁঁŇĖ঄ॼԪতǘްݧȜִٝׄࣿaɡ߫২নݨҌʟעׄ১ǩǫ΍ݳڲ՝Ǖ৯ৱ࠶৻֜ͰՆ৷ڎ৺ϼĶѤڄԏ҆ਂh৲ਅ਎ٛգਉԐণহ7ԭˇ٢ּ਒ਔϼਞٲ׾хਉφ਋ˇ͛ձিՖȇਢ਄ٱ٨ݩ޴ਙ҆਋ڊҐ؄ڿγਚăਲ΂׭਽׿ਸՐă਺ΩɊԦԨהħੂѦ״ৈٴŭ਩০থ੓է৛ס৭ਁਓਃՓਜ਼ũѺੇڥ੉ਖ਼ҟ߂ңਧҕڎੂ؂կڷװ੗Ļ࢞ࣂϟʎkŽܰय़ϯ࡮ݕԣʖ۵ӄॎĢ১তϻ4̯ছęवઇথઉӖࣙ੸ੑŭܾ࢘࣋ં ઄ؼࣹ߁ऌAग़ઌ̨઎।ʟ\tੂCHAʄࡓࡕ࢟ąc੻Ėdƙۢۤࠞۧ/McMӜdoਁoإǘА΍ݾ̈ॱŞ٭HЖCૄःǩ৅ˉ֦е৥ލŲૐૅ૓੃ਗՕॼ્੶ઔी/RĲotĎgࡩࢮࡃĝ઀ईࢬࢧ٭ݛKيઃțࡳࢶӽ૛ःCK۠঎੸Niuă࢒:ĉݓ࣭࣌ࣉєNऎĪपࢶĠॠ଒ॶࠦӂକ॥ऎࠀ૥Țrf˝૒Ġ࡫ܽ࡯ݖࣦଦ˕ॐईଔमॠFए࡛૥ߋŽॅ߱ɤ̮଍ƻ߻įPW଴ऑۇt_Mۇࠆby̪গଌચ8ࣸॗ୎ङୀMҵ̳ࡏߊGୃ੸Bռ૬ƥvثĂęࢨગब଩8୑ɾ߳࡬ɩPୗք۷Pଡ଼॓Ԃ୭क़ग़Ƶػޖ୴୶ޯࡋcؼʖؼӳमӪBǃण࠳Pࠝۧࢢė-ʞࢨϩ଩उࠨƧॏPडȖʖ܋̩֞ͅஙञܭ੷ଶago_ߋபࡪŭ3ɤࠥચॸԂ̩फ़ଉΘઙ஗ߓଜӪNलЇܢrாєஊиɺ઄ǎ௅įSࡒƥર੸஭஫௓ଵतMˮࡨǊŲWψކͮੜѨӽĚׄ௝ސޜŧ՛ৰеϧڬЖ௦ޛ௠੤˨ৰ\tދ௤Ǖ௰ޤ੫ը੭\t௭ݶ௯௞૊੣ড়ݴŮŐ஧तιƟயʒܧ૱ɬவʧஷଜߜ̫୩ߵ஽଎૵\t௝ल5୒ࢭࣧĢ௦SܟĞӃ࠿śؼఀࢗދ௦௝ଂࡺ੸࡙a˟lۧnƝ୦૯গࠌࠥ࢐ঞ࣯SBएितFakaoଣ࠷ࣉؑఙ૲࢈ଉӪT૷௧ஂܦఢĈ࢙\tౘ֐ȇT૫ঔԵਭɣঅǕ౤n૬םলĳټц૙ౣ౥౯ץ৪॰٫޾Ų౬౮౸Ȱଭި৔঍ఴ૥౾ৰapॅ࣮ଋࣤ஗૳࣮ƫࠫ࢕Łࣦ౟TಕѮ̏ދಈౠOళऐ੸FƂafuࢦଧېନߵ಑ࢊTVే࢟Wో̅ŎݑঘࡰࣦࢊࣲౙǕVĖ۬tಌл௲Ūĵોޘಿುৰೄ࠼Իфؽ೉ॽȇೀnೂ೎৩ͧ೒௣ॳŲೖ೘ЙѬ்੤џŷೝভೋ೗್ˈк৆߃ৣ೦೓޶ħೠ೬ˢਵೲ೨˹ଃ૥Efৰಶଊɦࠣ஼চौঝॆĢ೶ೃ\tVUߣࠖ੸಴ج́Ĉગӡ஖ಭ಻࣯Wଳ\t","tz/backward.lzw":"Link\tAfrica/Nairobi\tĄĆĈĊAsmera\n"+
"ĀĂĔćĉ/AđdjanēąĢĊTimbuktuĞāăAĚĭĤrgentāĊCatamarĉĄĻĖĽĿŁŃ/ComodRivadaviĝğĹŎģAŞăōěŏAtkŢĸŪļAľŀłnĊBuŀos_AĎesŲŏźżžƀrƂķĠĺūŦŵŒŸŔņňŊŌƎļŅŇŉŋŰƍťėłkoůĪƙŏŕĜl_HŊbourƌŤƏėƑŷńordĐaƄģƪƽbƟƵļįjuĩƿǀĊEnsŀŝǅǍ/IndšƓǗǙǋpoliƃƨģFƻt_WayneƴǕǜǚĊǱǞǠǢǰǘǲǟǡsǯǤƷőƹ/JuǉyǕȄȆǾơǖǹǋ/KnoxǕȑȓ_INȋƶȐŶucky/LƱǢŠlleǕȤuȦiȨǮţǕŴȁœMŀƽzƿǿ/ȷǘoȺțǇƻoŁoīȌMɅtƊalɂŏŚo_BĜncɇȼPǧɓAcƊɐƐȵƓǂƾǕRŽŊioɡĊDŀvěɈȜShipďȠɭ/ɛrǨof_SpčƧȌVĎgāǯPacifĈĤȟklĩdĄŁƗłģSƱth_ɛȩǾsšĤshgaǄtīʦėʩkhʬŝʥʧKǠůŇʯʧŅlcutŇʷĊɵĩgʴĒĄʰŔhɅgqāg˅/ˇnˉčʽńhu˘k˓˕Dʴů˛/Dʎĉ˕˗˙ˋĘʧƮrđn˕Urum˒˦KaʩʫƳȲ˯Ċ˼ʠŉǘu˻ņ̆dĶ́ˍMʎäˌʧ̐ĉɬ̎˰ɓCɶ_Māh̔ˆčgɅ˕JěusɎem˦TeƬAŠv˕Tɶmp˝̸̯Ĳ˕̐ůs̫r˦Uǉ˘ʢʗˈ˵ʖĩǄƕ̈́̂/UʖnɔņƻǾt͕ʜ/FŊoȪĄ͛ĩ͟͝ě͡ǯEƲope/Oslɇͣ͜ʒJĩ̞ǫŀǾ̪ɌɎʧSydǭȇA;ƫʧACTͽsͿǡˆ΃΅ĄΈ΀ń͎ěĜΎΐʧȤƼƭowȪ·ΏΉĊLHIΜΧ˖ΓeΆΖΑċSWάΗ˧ŊwāΕΦθNǧhηγɕǢǄǭνΝĊQŻŀͲʗσΊḏčϓωέʞ˂ς́β̚ǄɾϗθT˽̆šϑĊȷlưƲψΥϊ/ʈctƻϦϜξγPěʠīϝĊWƂtϧ/ɕƥŀƭȯlϡγYĩɘλnŸɻɒɔɖɘ\tɕazȯĤɟȱűȼπďnʴēИКl˧eСɅʴɻSaɓʍuͳЗĜЧ/E˽Ё́ɉǋ̪ХжЛϿΏɻƮǡfaȔ\tŅŸŞĤͤŒcɻWānɷegыǋюCŶƫВјŃēьǓик-ЯsʻchewĩɻTɄɆѣћǎкě˴мȜEdŗɆĪѤюɊ˞ŇʋѻļSǨJohǐњэĊNѮfƱǘ͕dɻVЍƱɱ̈́҂Ċʍʏʑђ҈ɑѡŸѵґ˖˽ѫѭѯѺПȌWɶteˏrǑҐѥYĳ̦Ҧʝͥš̥ыɶȩŔɋāŶɎʌʎʐʒйΏɲӅȯͯӑҶrIϏǘхşǋѣuǄǾĕǁčďēEgypлűͫďͮ˧ӡǡĪ\tEƁͪͬӱȤȿӵӯͭͯḆшфȲӿӱ̜ǢŃ̓ԇͯįĜsǻӹӰͯӼƽӵGBԓԀȣɅԗēԙ-ӷɠԆtc/GMTē\tԩT+0ͪԦԨԪԬԮ-ԱԥԧԮԶԪԹӮԳԼԠƊŀλѬ˕Hː_ʹ˘ēՉ˟ː͚ͶԧRΰkĨŠăIcϔӜ̙ĮҷɖēIɖ̧̩̫ȩ̮\tӚĜ̱ɻ͸ŉĖēհč˪՟/Ѳȡʹ͸ʄұĠҢӏԧKѯĨȩμփaօe҇ПӤĮćǻˋĀbyǔȼǈǊҩ\tȷxĈoЃ։aСҶɻ̐Ⱥѐ֛e֝ɘ֠ĨSƲ֥֪֞_Citȇ֜֞ԨŀěӌȲրҤʓȠҘ\tNZӍңʒ̜ņʴժ׆-CHA΍ӀɮɰӓČŜj̘ПˍˬˊēPRC׈ցɼҍnͮˋ׀ʒɛŸͮץׁʍ̥͉ӄ׬ԧЯŗǔ׷ˎuĳסӎׁT˷kױ׊˝׿\t׼ЌpԛӱǪҹawסǠϐԆӺԕφɅؔɾuʫɏշϣїˋROפշSeƱЉ\tإK˫˓aǟƊēSرسОĠԍǖΏ͎гēTƲkΰԲԧUΌԬهהҲȜAɗҸaĿ\tUSĤʖѪ֖Ȍŧaũٖٔe˂ǚɻPˏŀiъٞŴizɅٙȜԉĉӄٕٓѝŁџוȍǝǛȎׯǶƃٞӗ-ǴБٸғw_YƻăڀѸrվă׼ՏǠг̈ٞƮѯiiɻڃ̃ȒȔٞڜѨŇrكɻɯɌoֶē̟ٞѬiʫڏǕɯnҞګٕ҄ʚ֌ƠȜȤƈ˘̱Ƃٳɼ؁Ĉ؆ԧ׳бّɇٞ׹oǔEԳUTCىۓم͓ۓىіҞը؎ͯɊsЎēWѨUۗے۔ēZڔ","tz/etcetera.lzw":"Zone\tEtc/GMT\t\t0\t-\tĉT\n"+
"ĀĂĄĆ/UTCČĎĐĚCĔāăąćUCċčď\tħēLinkėćĒČČĒ\n"+
"įıĳęěĶļUniversalĹİĲĥĽĜĶōZuluŊĻōĵŐĘGreenwichŖŌśĊĿŘĊ-0ťļřČŪT+ŭĺŦĴŨŚŸTŭĕĤŧT-14\tƃīĒƂƄĢĖŲƂ3ƅƏĐƈ13ƋſŻƂ2ƅƚƒū12Ɩůƞ1ƅƤƝƁ11ơƍ1ĎƭƇƞŽģƢƁ9\tƶƧ-9ƫƀ-8\tƿƹ8ƼƘ7\tǆƹ7ǄĈū6\tǎƹ6ǋƈ5\tǕƹ5ǓūƄƄƹ4ǚƁƏƑđūƕžƴ-ƚƜǤƁƠǧƬƅưƨǠ+ƦƦǬǵǴƜǫĒ+ǮƳŲ+ƑǣǽǦȀƀ+ǝǝǸǟǯȈǗǗǸǙȎŻ+ǐǐǸǒȔǌųǈǈǸǊțǽǁǁǸǃȢĊ+ƸƸǸƻȨųƯƂĞǸƭǴƩďȷƧǵƪȯǵƜƟǲȾ","tz/europe.lzw":"Rule\tGB-Eiră1916\tonly\t-\tMaĔ21\t2:00s\t1ğ0\tBST\n"+
"ĀĂĄĆĈĊģčďđēĕ\tOct\t ĜĞĠĢĦGMĪĬăąćĉċč7ĐĒĔĖAprļ8ĝĥĢĤĠħĩīāŇįŊĲ1ōĵŐ\tSepģōĿġ\tłńŞĭňİŋ1ŖŦķĘŔ24ŗŀģĥŜŅşĮŉıČŸŎĶĖũū3ĦŮŁĄŲņƇŶţ9ƌŧż\tƑƀůŚĦĨƅŴšƉčƛźƎŪĝƛƓŰƕƦŠƈŋ2ĦƬėaŽŖƱƣƄųƵƙČƸƜķĹĻ25ơƔŃƴƘŢǅĜƺŒŔ 3ǍƂśƥǂǑƩěǇĖǉļǙƱűǐŵǒ922ǢƻŽďƿƃǝƗǪǠǮƺǤ ƾŘƲǏǞǷƷǙǕœŨun>=ĎǚǀǵƆȂĲ2ǙǅſƭūSȈȊȌǧƳȁƨƷſȅŔșȉ=ưǾȎŝǶȠȒǌǅďőȆȥțǲȩǴȫȐȭǅȯ93ŖǣĺȇȦǮȝȀȬƶȒťŏķǖɃȊȨƁȪǩȻǬŖǅƛȲȤȚȋȶɒȸɔɉČƠȣɏȧȍɠȟɢȾĜɣǮɚɦȜȷǜȹƧɫ3ȄɌɰȴɧǳɴɡǄȾȢɺ\tɎɼɲɟɿɪʁ3ǌɥɼɑƢɩɈʌďɣōɻɜʈʒʊʔǫȿǯʆɜʑřʓȺɷƫʄʢȦʛʥʝʧʌʩƍ\tNovɱɞůǨʋǫ4ƹʄFebɦȓɨʯɶʁ4ǔʄĘĔɼǮƣĢŮħDɵǃʽɭ94ǙőugɦƛˑǛƤ˖ǟŋ4ː˚ȖʅȳɜːǾ˓B˕ʀʽʃʳƏʸˣʮˤ˴Ʃ4ʎʪȆMđȊ˯Ɓ˱˳ʼ˾̀ʳJāˠ˺ˣǁʞ̋Ĳ4ȱĸɂˏǚʻ̔˧Ĵ́ɛȦʤ̒ȏˈʽɋʳƞʭ̥˥ȑČ4̩ŧɎ1Ȕ˰Ǵ̞̖̲̉ɍ˞ģĦˢɓ̊˧̼Ėʵʷ ɅǾ̝ʰʽŹˌƼģſɾ˼̖̓͏ʳǤ3ľ͋Ȟ̺̰ʲ̳Ȇǘˆ͕͟˚͡ǈɂƠɆƖ͍Ʃ5̀95ɯˬ̢ț͓ɳͦͯŋͱĲʹͪĻˏ͜Ɓ̧͌Ͱɹʳʫȵͥ̓ͼͿȔ96ĦɁ΂ˮ̜͞ΏČ5˶͢ͷɽͺΎ·ͽȽ5̘΋ɝ΍̦˗ͰͅͶ͔̐΢άͽɗͳəίʇʹ˻β˦ĲΓʡ˭̣Ϊ̮ɕ6˙6˜ǰ\tlastȥσ˽ŋφξɀ̙ΖɄǦ͝ɇΚΒſČ6ʘϊʇ̤͂ͧ6͘ŧˁ˃ƋαΫνČ7˩8Δϣʚκ̭ϒĲϲĲϴ΁˄Ϛ΅ΙΣϽ˙ͳŻ͑όώϐƣuϹ̓Ľ98˙8ηǤˏ̶ĠЎΆγБ9ͲЇΕ˄̆0ЛȞZđăEurope/Lđdđĕ0ğĤ15 ĖLńģ8̱ Dec Ľчзŀ\n"+
"\tэ ъłȭ%řΒ8 ǉ͉7ьюǀĖƥϻ1їĺǘѡ͉ĥuћļѐνѓĲΒѩяƃEUƳ/ǝLink\tЫЭЯбгеѽЮаJersey\n"+
"ѸѺѼЬ҄ҀnдnҏѾаGu҇n҉ҋҍѻ҃ѿвғ҂ҐѿIsĂ_of_Ęn\n"+
"ШnЪҦаDublѹж:ǋĥм\tоTрϴ A˞ч2ѩ-зҾěӀDпƊ6 ˍ͉ѥŮӋӍ5ҽѡǀIĩţӔјшѦыэѪƃȑѭǓухч6ѰѫȑǏ/ӠӃ̰0 ϫ͉лӦ0Ӳƃӟӡ̰ӣѣ ӔӿԁśĖǏ̻ӕƼĽԉәӨѱśԃӸ˚7 ͇ӉӉĥԋϵԎ̰іǖĽіԊԕӳȭӵӷϕѢtљѰѝ\tԮϱѡј͛ԟКԡνԭԄ9ѯԪѲѴԿǐѳϻōČϾʙʬļЍ̒SǞՈϱή˸ЊϏȈՏѧƲ-ՓѴϱϩϿĽ՛К՝՟ϻˡՁǌȗϋύՙҕĽ՜ΔըՋĜmaxЈŔ՘ϐղզǀՒƗՔՁďոպТս՚տХէƗWćЬՉϽϵΨĜ֌λւƆ֐ѽ֓ƺ՗կվˢմ֏֑Ŕաǯǻ֣֗ĕǞ֜֒ϱժСŨƮ֊ձ֬՞֥֝ն\tևջծЋ֋́ƃ֚ĭ֧֯օֽչϿֶեʺ֭ƗC֦ӢπŔͬ3ԂׄǞגֻĳ֩ɂդ֌֎ƆלְŌţϖɎ̃ʬǌӿ֙כדƊՊčϖ˸׫ț׭ȝֹפױ˚ʿΊͣ֗αׅăץ׈˨ǯ͇ļǮ׮ףĭ؆̖ΉƝ͑2ƛ؍ցװם˛ןĻ ſ؍֤׼ؚϟ˚լί׷ȋ؋Ρ؄\t̰ؐΝգ،׺ؙצ˿ǯ˸Ȍؠאآצ7׳ՌθʚتʉĦجخ9ؾطֵ֡֋سב׽7բТסَؼ׈7ֲئׁ֠ձٕ؏׽Г׊ֈϊ׍ؗךُםΒ٢׌ٌٝ͝׻ĭEِؿ֕ρțөԗ٧Ɔٲםىًٜ֟ٸĦءٱِْϗՏڂ؎Ъِٙķٛհڊڄڌם١־Ėƞ٥ѫؘփ׽٪ڗڈښƃړ\tĀssiaţή̎lډȓיśM˥ڦڨڪײǯфcĝŖԖڃėͮĭڵکרǯˍƟľ˓˓M̹Ɔۃڷ״يūعǀǀڳǐۏƚۆęۈĝטśۋۍۂuڧۄƊͩĖڭډӿ̒ڳDǞۙۧʡ̾عѫĦڳK۰ۤڶȒˋʳϫ͒۞ڱ۷SۯƗ۱Ǭ۾ؓŽƒ۟ƒƃڳMۺۥېǡٿūסڛܐ܅ܓۼǓ؜۫۶ػۣܔЅϽ˫Ɏܙ܃ŨܝۦВДω֪ڒܣă܈сѮĜխ٥ٞܵۻܮ8ȽčֿܻثܭېǬۛռ֡a؝ڰٹśج܈݈ܗ׀Ϗ݌؋܎ڋڥܾ݇Ǧ01ϵڙ٭كʜم݆ѮΑֳڐվܼݛܥČ٪Ƹݠ٬ځغ՞ҲăWEӃŰՄ\tݺѓĪݸحݻэǀؐCEށұЩėޅ̒ؐMފsނލEޏ˓ՈޗދƗAlbanܮʾǯ̎ҕȌܚݐǞޞޠޢې؈ƺ؊͉ƟڣܴʅޟޡޣֿؒؕơՑޫ޸ޮؑו̿޴śڤެ޹ې7ذژۜ؞ݽݏݦޝ߁ܮߌܠ޳ܢٰă߉߂ϱ̌ؓĔդީߓƆߝߖߠرߑڿߛ޷ޭߖ̠̪ߏǮߤܬߔ߯ߋ߱ŧǻǙߚ߀߸֞͐ߢŖߵجߧߋήǻߴ޵߭ࠇϻڇۇԈ߫޿߷ߊࠏߘĜ߾ࠕߞوۨƻߢǌࠅ߿ֱࠖےƟڃࠌࠣࠜϾƺࠑ߽ܫࠆߕېࠬʄǻſࠚߦ࠲ܦɥ2ďࠢࠛܿ܊ڏƮ2ō࠸ĭࠎՋǹࠂ؋ࠓڜ࠹ࠀࡊߘ࠯߇޶ࡉВ޻ɰƋ࠿ࡐࠤࡘ࠘ࠓ߈࠺Ջߍίߣ࠰ތҳҖґTĉޡċ:ČҽӺнӒč4ѩԴމԙʾ ަԒࡹƃࠎމށܧࡾāࢁśՈࢄޔࡩҴҗ/AҤrrڪъ6ğ4ӀӂĲݟѩѫĖݺࡼӔƏǘԀӨࡺޅՋлżѤԻࢧކݾࢌǐӇώrܮǆɥ ǌ؃ޫۤtࢷܕ׿ŧظЁ׏ࠍࢿࣁ̖ߺɍȆ1͹ل߶ߦࣉޣʖ˚ϖЗقݭࢵࣀޣήܩϸࡏࡈࣔޯڇ̴ǽ࣑ࠆࣤ֔߄ࠒ࡜ࣣࢶܿࣃࡃū2ࠄࠩރҡаViennڷğӜӏࡵӸЕ3ӆœࢉĦވޓԙƸऋʅ࣫ࢳ̖ӺԦӥƓऑऍࢅ̰лग2ࢯsऑއEՀ˿उrĽठ׮ऑĖࡻ࣋ऑࣜ࣊औնऑࢋऎࢎ࡫ѿMѹsѻĤͱࡱӔअӄࢰƂ;ژࡶžԐyӉѩ˓ĖޗԙƑࢇnӗѩݙژSK̖ѡࡿࣶचדऴ˪ࢇlч3क़ƃۙ۸/ۮѮॆख़ėज़ܸԐऩԺबӨ˓ǀޗՀč ࢥؕडॏƃ॑ࢪՁठࢭঁھढॹܫॼԙǬॿŪљщŘঃśۙޛޔĝݟѡউԛॸэॱFޅݲ࢚ј࠽чˑ३Ԍॲ۹ƗBelgiumۅ࠭͑ ؖѐׯরল঴শۅ۲ТS݌ٷݎࣇǞ঱঳঵ষ۲হǗľ܎াƆৌু৏ǬࣳĖ܀࣏܂ࣩোীৎȒ৛ڈ˅৉Ɣ߭ৗৣܟ৑܁২ࠔ৖ৢূ৭࠵ɂǋয়৊ি্৴Ǭࡋ߲Žࢼ৔ৱĭ৫৽ǭɊϿ৆tৈਃڤਆ৙˅࠼৓݅৻৘Ȓࡥƞ޽ৰ࣢ăਐȮ࣭͓ਃਝħ৳਑࡚࣌ŭਣٺਅਦਉࢺưਫުਖ৬ɖ߄৞ਜਬਞਮǅεʠ৅Ηݶৡৼ਑ࠞɎǡ٦ਲ਼৲੄Ĳɤ̡ģǙ੉ߥਭੌɣࡂ࡚ؖࢽ਴৽3৿Ξǥݤ৕੔ਗɣ࡙ϊ࠽੡਄਻੕ʂ࣭ڽਗ਼ੋ੤Ⱦߩߎז؂ਕੱਵ3ਨίČ੩ਤਟʗਡ੿਺ਥ੬ʠ৮ࡅ઄੊੣੺੆࣎ď੒࣒ઍੜࠞ؊੾ੂਜ਼৙ޤƺ܀৸઒جઁ˪ࠦŤ੩ਏ਼إ࣭ز੸ઔછੴִۓઑݭઢ̗ۛĔઘੰભ࣋ߘōੂࣹҵѶrۻলŁࡱ7:॔ॄŸϴ࢟૆ૈϵBӒЕঈęপपԠӨࢠݿআ࣏Ԝʶч8भބԙĎौ૖ھॡ֝ॣŸ૞vĽӞЍ્ǜਮހছӹ૦Ƹংࢨƃछ૶।ࢥǘऑਟॣؾशѴࢳোā˟ࠥ৮͛৹੪ħଊթࡠעਏ଒ՋͲ8͵ʆেة৉ଐBଗВ৥˸޽କ޶ଡ঳࠻ʄଥઽ˓մિ࢐SҬۦૈט૥૊8ૌૻΦ:ΦķI૒˚૭ࢦগϵ॒̖ठԝ͉१૘ࢱś૽ࡼ5ૢयझनԞǘ୎޾অԙ٘ॵࢮ৉୆଑ପচԙଚ঒p͉ԓ୚˓ؐ୥ܸୢټ֒୯ݰњ঍ࢊѴ୥כzхh̖યܩࣨݥઓ؅୼c୾झ؉ʶрΘ߭Cஆஈ˚੼ࠑ࣡અஏ୽઻͠ਊࣚٯ୻஘̰ࣟȆǆહஅடࣗ਷ஂ੢஥இ̖એǗϥך଱ґP࢕gҚݽ5ે4࢚ହͱ્ஹ:஻ķPୂԸĺ૩֒ॣ஻୨Ľঠङૻ୐ஐބजࠝଆ௓ࢍƗфnոrिמহષਢࡨ௙ࣾ௜௞Ȍݔחࠩ௤௛Ƽ௞જࡌкڊਤ௚௦୿પઋ੓ă௵௮௷Ǖ۴׹஝௬௶ԅશ۫த\t௼௝઻ݔٔంƆఊ௯ήࠑ؟ఈ఑̻۳ଋĦઙఐ௥௽Ԥఆ঻௹஄ఉఞఋఠ௿˟Ǽદ֭ݸ ࣺ/C҄nhagࣾөुૹହПԁ఺ࡴحୂ࢚JޡপԳƃగொ୊૟ୌড׎حॢऎ୿ୗ్Ԕќైదѻॣ଻౗୸ௗޕҳӆtόntic/FƼoăӌҽે0஼Ӂࡶ0іౄॖ11ԽࢡআГԽՈ૵ǐThƆݰІ͵ݢځॺైǞಃಅՁಇࣴݕϐଯతಎĭݰݞ0Χٶଞܫ܆ƆಗŋȾজಛݴڑಕجಢಥōڠƞɼஂ̒ಠĭಫƸ0ಭ׋͆஋ʇ޾ݦమAm҇౧a/Dޡ௦sవvॖ-й4ுీ࢜ӓ॥͉ૡӨ-ॱWG୦खœӰࢯӋݙಀG௔Ղэ૚ȀಿುࢷcೄScoĊsbysȈdмĤࡅାठ૊ĳ೔ॠ೗ॐح೛֔౔୫ĠӋ୭ॢ೤૾ГୟؕӋॻ୹഍ౠeӆ೫ೃ/Godtవ˃೘ҽ࢘Φ࢛ࡶ૥ڭೕೡ঄ݿഅଘഇೠ೗ೢѴ೚ދ೪ೂ೭/ಫ-೏ʍğі೾നāപ೗೏śಫAശޖીTalҺࣿƂ39ബ೒଺ॆĤ൓ബTധіϫைŔ૫9॥ࢁ൚ভ൜एঞęୢଡ଼कӆӈԈবݡॳ̰ѡࢥкൠ౟̖࢚ঀӊӨݙ५ज़७܅Ͻൣউഈġୢॻथ୦ൣঀ࢚౎ഋ֝୴Ձіൽୱ୹౒ݰൣୋ౺୷େথĠठӼě඘ѼसƗFѹ౤d୉߄Ʌെ̀અඪĒޡත̰ਫ਼Ͽϟ௫Ɔපඬܦࡒੵಓ՚ಋઌă඾බවВ͵ݫ՚ݙରോ࢐Hૄѹki൒ൔ4ൣହّ૦͛൥ෙηHॊ൪ҋඟ\t෈ғට௔8२෧ޚसҟऺаීlڨѺ෗రżࣽవmҰඩ࢕ncŷ੼ަ৯ਲ௺෨กฃהৄڈ಼ৰڤFซŷఓؔ௢ৠ฀ޡฌƊࠐ঺਱બ෇ดۚ৮դਹෆชปƷ৥ঢ়ธஃجณส৤ܠ১਎޶ัขƷ੗ϊਸจతุผ܉ิਂఏĭเƷඹෂ৸วฉ็Ȓ˩ਿฏଝਔЂ߭๎ǅ੦ۇ੨์฿รȕ݉Ư৹பษูਠࢺฮ๣๗Ǭ੼̴ਪม๤แઊਰ๢ଐ๪ࣶ਷๨๵๞Ǭமজ๴ਤ๪੎؀֧Ʌ฾ะ๻଎ɥϭຆǞກ้ࡦ຅๯ກ๙ؔไนලຈࡥܩ๮ທๆຈયƞ௪ຝยาɣ๬࣎ƾຌบ๥ંࢺǦສຘລȾพǱ๿ඳຈ๽௲๜ງາ൓ஊʷ຋ๅ຤ຬ׾ǯઞఁߒ๝າˊడ׭ѫۋຍ๻໌Ǻנઑ࣯ໃแް͐யڊ໐ຫ໙ຏ޲،ݙ຀໒ດŽਖ਼ƃໞັໄ؛໔؝؟໤ື໋ບͣੑۊܐ໑໴ߘڽە໳໭஀ͣફ۠໹ໟ˧યظઑාื๻7ஓؔ໽௣໬แ༎ࠦ੨ଧݷෑளƼiૅ0ൔऄ౳आॾࢭкক࢞૙ğ༠ܹ\t௄૤൪ऩ౹༧ඞ೧ƃ๎ಁ൮ࡿ૝ୡௐऌ౑௔ோӇgӽ૲Ħ༷කإௌ૥୙ഉ༽๰؅཈ଅཎषޜȐ҇ոnષஒ๸΍جGབྷޡཚવ໯ļŭໂĄའཙఘசੀՎݭཟrམར஡ǗďະŴཀྵཱིఆ౹ǚ໫ླཱྀཡఘƺฆ޽໲ศ཰ི͗நཝȁཹ஭਷܏ຣॿʶࣽtރஉ௠ĝ࣐ྑ۷ǂྒྷvྕྗ઩ݔž߆඲ෆྟྡލ྘ʄગனէலѿ঱r൐ஸטࣶദ༣ईǖ൹ொࢬ૕ोԩ୏Ӻଳྠeྖލொӱཎྈཱྀ౛൘ࢲ෱෕ෳ/ZЬ౧୾రଡ෷షҰమరGib࢕lt͑౮ěҽ౲ൖӅག୘ঽཅѬєஹୗ૝࿂̒म౽ൾ࿃ѼଇඨȐĊхŋ੝ޥ̏ ࡆ༒Ŵခแင఍࠙඼ညeဂढ़࣭ဈ້ཞဋ˧໡஋޳་߭Gမ߃଍ࠨဗȁအ̰੦࠶ࡡ޶ဠဒแ΀ྃဆဏဥǶဧͳရ͈ࠋࡕဟံ7༁ຄ߫๣ိဓߟ຿ĝ࠾ཧ၃༔ວ֧΄ฯဦီŋ༕ཤݳ཯ွ׳ّ࣍Ο၎၂ၗ༖ϸڤ၊ၒڇଥſනݚၢଓࢺĜൔဴကၑၪବࡄʑၨံ࠴຃ډ໗ĄၶତࡄࣷျहరAടࣾʥ3೏ʹྐྵрͳཊࡸૻႇ೼ɍധӔഩྸԖ༴޾ၩඔˊୗƑऑၩொ࢚गႎэ˓ႚ཈౾෯඙ཕĭHȈgƼཚƋၫǥဉăႮnႰrႲၤƮعသǞႸႺႲູ׭྆ฉჂႱฤྭ஋ྥཌ߬ჁႯ჊ྫྷ߲ߢ๔ྦྷ჈გႻ௾჌͈֗ࡇႷლར༏੶ణج჉მఅཬฏقజႭტཫͨၚɦక๯შཚ;ຊମჶჰΛ৥Ǥ˅ხსႹდͳؤ5ئ๚ੑၺჷͿᄇئ߼ܳ߭ᄍΛฅ՚಼ھଐᄔͳ੼෍ձრ\tᄛஹစҕᄘ໾ศᄢՖڀڑ჏ݚᄛၷ੟ࠒעؘྱаଡdaЯώƂĎࡳႊŸП԰྽཈Ÿऑᄍொѡगೖ࿼୑୿ᅆჰ࿏ௌ႖௏࿼པ௘ƆIฃ඿ڸฎঢ়ภၮĭᅙল෉ڸཤੈǀڤᅢᅛۑฎગઑᅨ޶ᅪᅤโ৮੾ଟਤᅲ෪৵̍හੑᅰ߭ᅹභȾ๽ਛჇతᆁ੍ࠞᄀ໩ႀƗᆈӹໆ˂ĝ່იᆇᅚᅳޤ൵ķ؊̛֘ݚᆏ˚˙؈ෂᆝ׃ศᆠ؛అᆤჭᆦฉᆨ˩4ࣘ̚ˮ،ָǞᆨ׳ϡჳᄦ๯ᆨᆊͫఛᆶᆎᆗᅺͳͲ6̘ࣙɄᆵཧᆠᆺᅦؖᆶಿౣޡ౦౨RҊkjaྠѻ್ҽϖ೒ПᅋĕӟᇄතӠ௔Ϩ౔ঠফՃভϜᅡ࿦Ķӓᄤ੠ঽଐIᇳႲ੼ܲᇸᅩᇻګ࣭ဳ၏ᆎሁᅥၲƐဤ৺ᅘሇۑᅵላ๣ᇺൎႼۚ཭ٷᇿᅱሎ੾ล်ህልሔำઉሄሒሎࢹሉĲ၁ᆟሎ௰ᅼާࠡᆽሬࡥظဖሌᇲሡეᄱ͊ᅠăሓᇴྣረ௲ሙᆀሬფŬྌሆሸཛཤࠒݭሾེᅵ၈ຣԵሬࠉנሰ๕ᆷሬڇઞரᆧቛࡓ஍ቚቊᇈϕЈˎᆴࡎઅ቏ξࣖ6η˸ˏሞራቤࠞฆࡧሼቔቊ7৥ۇ଎ၺቬϱၽū׍ᄠኁو˙ϼߎቨᇋቪ቟ቻ฻ᄞ̒ሀቻຏᇾတሽሎ7੦ቷࡔᆕجኇኛϻ˫ኒኆኚਙۜ੨ኀኚયቷሤᇹኬ֓ܺݣቃባሿၓࡌƠᇸᅸኚၘηۇቲሪኼቻڇኗ቙቉኷ࠞ˸ኺ஝ᄵ/Roುݽේାृ༢рᇈᅒ࿻ዓൔିĖRୂईඝ༧ඉཎቬొୄౕখཎᅍد൤ዦሁ࿏௖ଈෲరዐዒరV݌ೃҰድીዷ࢏ґ৆nҮ༜noǞL݌ྠ࠳ֲ̘ಉᄬఈጊtጌඅѮ̘ኒા༚ѿRiႰ൒࢘ႇķ࿬࿐੻ૈ˫ዠ૤ԥೞ༦࿷൙ጡරśLՀ૬൷ԉ܎൥ጰķጩƚ౔Ә୚ጯጧ̒ጳ૤ආ࿀फጸႏጺዟॊӔӖ౹൬ටࡼख൰୓ൿബ۸ढ़ዯᅌ༿૾ோј̵൲ݮۼ६८ՋፆऩֶૺႥ঎ඌඅௌ፪එƃጓጕඔوࡾ౅ඥႪ෫ছಶӺඤ9ፑୈಶफ़౅͉ඦ୺ҟయી࿖೬hᎋ࢐ዺduzႁીࣼlޢۤƂˊूጣ૒౜ƂžബWധ୶ࢱാ੻ķKധൣ፠࿐ভ୕৚೔1ዛഃୈǅӺӤᎁཎ࿹ፓ൯གྷଁፗভፙ൵ॕ͉Ⴄސ፝ࡼႢ˞።ඁKඃDॴࢭॷᅔ޾උॽ൶ওঊᏗඒ୳཈ВᎂআВഐൣ֌Ѩན࿾೥Ꭾѣॷ૱෧൭ಶई౷ె፻୺ƗLuպᇵྙ฽ႶӁᏻהቌ֫ኘᐁᏼק࠼ຩ᐀ᏺᐈથݔથ༘ጉᐂฝ߄ب௲ઠᐓᐎႽūᐗᆔ৩ᐚ჋਀گᆆجᐍᐢ߻቗ႵᆍƆᐧᎹᆑϬฮଐᐮ৚ิჵᐬĭᐴܖ໛งᐌᐔᅴ৶ǊલᐆᐺຏਚຖኟᐡǅኖᆳɄ౏ڤᐺ੦ੇთᐳᐿ਒ᑁ˄ݤݚᐺከ໨ଏਤᑜȒᆲϘ̅ᑏ޶ᐺဿļᑈᑕᐈ੨ჺᑟઅᐺུļᅟᑉᏹᑖࣦ࣎ᐲᑠᑖᆄ܍ࡨ࿟ીᐍemboЬ˟Ӎഽዖᇢ౱ॕऑᐧ૫іԝǋ࿱ᐧ༸ɘ԰೟౎ѫਟᒘ׾૦࿶ፉ፜֝ᒟோ൷Ԩᒣ̥ਮ଄Ꭷ̒ᅖǐĘ࿥ߋ໧۝ኻઅᒲ࿦ϻ੦ଥƛኵƗᒹߋ໵Žኯਤᓁኣતቒሶăᓇ၅ࠥՍ׸Ꮨᒸൎᒺᓎଣಒʇࢼᐆᓍᓗ଍၎޿ዎᓇз58࢙ᄿइዩफ࿰ደሡየୋफᏗއᏋ౓ट፫̒ዧདईᏕ႘ۖᓔڪ౛ᓼ࿑ൊࡪరCh༝ѹaЎीः೑Ꭰ࿐ᄈķC൝ӻ˂Ľፖࢱ஻࿪ķ૑॓फ़ൃžୢዷࠖႛፔགྷ൸෧Ꮩࡼᔟ०ŤᅃཀᏍགྷᔡᏃĦᏐᏒ९።ग़ड़ݰӺӖ࿋፬ভᎸಐᔢݜ፼ঐᎶѲד፶ᒮޙႫࢍᓡđa೰ݽؕૈ೽዗ᅀ༰ᔗ૲༫௃ധᕚፐ༩śཇཀлጶ୍ཌྷ࿼๎ᒭዳ࿿ĭN࿇஑௨ࡌቸᆕNӡǞᕰടᐃᑘᕵƲAпᕹᕱሂຊகśᕷǐᕺᕲᄪۓསЂᖀᖉᖃᐕܟɰᐗ΍ᖈᖂᕻᖓโኳώ׫Θᖐᖙ஑ਈ৮׍αᖘƗᖊ๏੍ᇉᑍᑥȝᖡᖩᖒǬኜ՚ณiৈΡᖨƆᖪ๟ᖥݣᖧ˥ᖽǬክᖶࢷᖹ࣑ᖻᕯᖳ੨੖ቧģᓚᗉᗂᖳဍࡌਈᗁᖑᖚȾΑᎪኋᗐᖗᗓᗚ3ถĚሻஃᗊăᗃᗣစڮᕾਤᗪ׳຾ሗ=ᗦᐠᖲᗢਾ኿຺ۜ๯ᗃضࢺᗵଐᗾ༈ႾၠభЩ᎐ґೀώ҇ᄸষзࡲ੝ᓧʍ્ᘑǮᖪӬȾԛഩĽ્ǆᖪN཈ࡽፏԉѐᔯ፞ञೞዪᕩ̒ᖪᕬᏪ౟ᕹೱwᗻ௟ᗖФᘂᘳᘵᕳ˷Ʈዌᐸᗩᘺརᑩ޳ఈʵrᘴᙃࡠݭᙇᙉͿժ6˫ಯʚᗑሟᕯᙂᙏξٚƮᓙቢᖩᙘϠᑩ๋݅ዎOҩoዓ܎ᓧႌᏵᘝཎᙍۜொᔦĽӺ༼ᒤ௉ᘢᘩऩᘫᎰĦᙰĔዲᘰዴ࿓రᙦlᙨArĺ౧ҒgyeƼ೴ࣾǞPoᅫƋฎ༉ᙞƆᚕᚗჅቈ᚜ᚖᆘᓃ੠ఈ᚝ᚣߘྛݚᚧᇅᗿ੏޽ၺᚬᆂᚮʳ޲ሄᚫᚢᚭ၌܁ᒷศᚲఌᕽᖎᓋ༭ᚹᚳᗤļྛ๣ᚿ஠ྏᗳၜᚸᅫᆱྋᚦᛅྏຊྜᛊᛕΛڬٍ̑ਤᛋͳ׳ᓤಒ׍ᇂᚡᅫᛣဣᛞઅᛠ5ࠞቾɭ๯᛭ᙐ༬ᇊٷᛦĭᛠοຮ᛫ᚾᛚΒχᙒۜᛥᛲ᛿6˩ᙑᛤݣᇒጛаWƼsawᎢනᓧᎡ೺ၧࢡധञፕᘧጪཊጷ୬ƃᚿඔǭᒏཎᚿᙲᏇȓറᙷൡᘢধேᜨᛕᘯ࿼ׇൺՋᇤഓᘱƗᚕrĻᏽʄฆથᅷ᛬ೱᝀᘶᚵလᐅᙀᛄ᜿ᖄˀᆒ๷ົᚔᝇሂᖔڈ᏿዇ᚡᝏᐕลთᛙ᝝ƪᐰڼຶ᛾ᝢሧۿᝒᑵᝡᝈᐻᝪ˃ᝓཷă᜾ᝮᚤȜᝳᝎ᝶ܠ᝚ᛃ᝵Ȓᚻᝄ᝹᝿ȰȒЖ̚๓๴ڤងǬᑳఢ᝔᜽᝖਽ཛྷថ᝜ᝮᑾᝦฉឌຉ੏ແቓល˙င৅ញฑ޶លຏܩຑសធ੭ࢺຜᙖ᝴ឬጢɣᑣŨឤึ߭លຠ͑ຢឰ᝺ᖬᛓឃឲណຯᜅᝢઈᐼ๛ែះ᚟ផ᛹ឲખ஋ឞ᝾ឬርϪᝒ๹ᛟ៕Ͳ໌ٓᑈᗶពနࢺ៟ଐឌ؈உᆤଝᐋឫᝢ໚ၸ๋Ʊཾឱ៭ឨఀĝᛔ៴௷ឣ਌ᗴ๹ឋ៕ᑒ࣎ŭ៱༅១ဨ៺ऒ˟਋̅ࢼ៸ᝈூ៨θଝǡǭ̷ڲ᝕៭ᚻ᠋ଞ់᠏ᇽឈ៼ᝠᚸ៭׳ේᆻჭ᠎ჱᠦᛎబឹឬ5χئ֖ღ᠘ᝈᠰᙚ஛ՎᄂឿՕ๠ઊঋ៥ឬپረટᒿ᠆وε٘ᠧᠺᚽរᡂዅנჟཧឌᡊශરසַᡓឬᄰ݃ݣᡀ៚ᝢ١ᡖጐ֢ំᝈ෭๠݄ৠዎѸೳе౮ጦधହсӚૈ࢘ᡲᕘčठ᙭႘ᄙ᝿ᒟዙगई࿷עᎾϻࢤᏜԉƣԽ᡿ႨईঀӾᇮюѫ᜷ᒟ঑ঀᇭያౝĦᒰ጗ୟᏯѧ౿ഴसᇓ౤ᇖ࢑zೱeĢᇟ˨೐᜖ᏉᇟΜᕖӀ෣૤᡻ᎆ႘-˓᝿AZOᇪӔᢂᜭᇥᜣ᝖ᢾᣀഎᢏᏜᢑᢚᣅś᜷ᣈ೥ठᢘপᣎᄙಀᏡᓺԑ႖Ᏸэᇟ౞ᣒᕏᘈႃᢦᚌĘde࡮ᣏે੻ᢰഒğᣭዖFധᢸॖ᙮ᣟǀ᝿MADᣁ౔ᢃౖڊᢍ෬ᣋ୩ǋᣖӧᢓݾಁ۰ዑ࡞ᗕვĝᡒቓᔣࠜငɣជᑤةᡀڤᤖܮɸᆉᡋᑥᡟઅ᤟ߋᛯኩઽၺᤧၱᘽኄᡞᄠ᤭ଘ࣭ᑫਤᤳᓝረ٥ᅿᤎམܮ݂ಙᡝݵᡍతᤸ᥀Ձωጙኵᒁ࢐ଡஇƼ᢫ᝀு೏ो఼ெtࢁᔚྥўࡶԺ႕Ꮙ˓᤭ඔഏউᏧᏞૼᕊᏡ႘ᥡᤏ߂፶ᥠᕉඓᏡᕌݾ୺᥌ґKൎѹѹg࢕තղ᠕Ġᙫྻऊԕᓲ૪ᙹѰᢼ᜴ᘢᔿᐫᔵᕅ፥඄ಆᢟጿᤊᑚঙ౒ݲᕚࡅᓶᄭড়ඡ૝নඈঌюᎷݻࢎᘉऻos೰ᜓѦƑ૆᜖ॆᦰᘐԛॉ૤႔ൃᏂᦦૈйൣۙᘙČ೔घ୚ᄭᧁєӏǉѰ඀ᦑං፦৾ᅂԕᦧ॓Ӻय़᡽᧍ܥᦒᏓᦔᓻᦞᥡᕅ፶᣶Бᦞ᧙፤᧏඄ᦛഐ௎ᣗ᜙মজᦢѣ঩౎ᦟমᦩరSimf҇Юᚖتᄽᥕᕘൗᦊ᎞Ǝॊ࢚Ӗᎇ᧓ബᕂ॔᧗᧌ፘ൴ᆡ૭ే୐ᓳዮԦ፡ԕ᧦ۄ᧛ᔸ᨜ᨒᔻՁ᧖ᦻᦖᦴ᧔Ѯዛ۬୲Ŕ᥯ौᨑࢊד᨟ݰፎԑॷ৔ᨱᆕ᧐Βᒚᦝ჏ᦥᦏ፣᨞᧨᧜Ձᒮ᧵Ꮕᩇୟ፱ᣞᑚ෰ࢅদᢟӺᢄ᧮ፙᩒᦣ᧥ᨢ᧷᎗ᚖgo᥽a᥿Ğீࡽ೾ૹ᙭෮юॱTSAएᙺӰᨺڏTᩯ੍ᨥॖ፺ю᧮ĩ᩶Ϡѡԝᕡ᩻४ᕅVOL෬፨୪ᩚঘ᪅᪇೥ᕚᏖ᧭ബ᪆LᕇᏦ᪌ᦐ᧚ᩅ᧰ᦜ᧬ᦗ؞ᨢ᧰ᜱԱ᧳Ꮧᩉज़ᩜଲa௜ڪ୙ƸᄾുൣᘜᨧᩳƎᖐ᩷ᜫ᡽᪸᩼ɣлᏵࡅѰၧۙKUY᪉ഐᦤᩳᔶᨼ᪑ᨧᩁ۬ᦙ᪐ᅒᥦᣗॱ᫅Yঐᥗ͉ᩔᒪ᪡᪍ܥᩮMᩑݟᔽᣜԨᪧ᨝ڪ᫢᫤༲টᦞ᪼Ųಿڶ/Yek݌ೂnbᒈᛈğĞɸᄿ೿ᘜᩪႵ˿ंӀ༮ጽഩጭන᫂ബSVআᨏȈॗԕӜ᫠ۼᬑᥪᦕ᫰᪄᫡ᬒᣓ፸౸᫕᪠ᬘ᪚ۼYEK᫭᪞ᦞ࢘ভᬪKӃᩘ᧲᫊ᬗബᬲഖӆ᫴Omा᪃5טૉ᡹ᧃ᪁ᏉࢻബO᪹ۗᨐԕᬰᬨۄᭋS᫓᧞᧴ᬧᩃڪ᭓ᬢᏵᧃ᧴᭐᭙ĸڳᬭ᧫ᦞ౰ϵ᭓᬴ݟ᪤᪋᭟ᭊۗᦩA᫴͇᦬࿢ĉᭀᭉ͛᢯᪲Ӯц࿶᭐Ѱ᭠͆OV᧕᪺Ѱ᭧᭡Nᮄ᭕ᨷ᫏ᮁᬟۼᮋV᭜౅᭞ᪧᮉۙᮓ೥ᣛ्ȓᮐᬙۄᮛ፽ঝ᭥᧴ᮉᮃᮅ᪣ᨾᬷюᮂʴᮄᬻ᭲ک/᭴k᎔ҳt᭸Ӝᆱுീ᡹ोᨊ᡽ᮯKR᩾Ⱦ᩸ᬖюᮙᕅᯅ൉૾༤ᮎᬯᮑۄᯎᮕᬤ᭦ᯔڪᯖᮤݠഐ᫨ᣗ᭠ᮚᮌᯝᬮᮧബᮓ᭪᧱᪥ᮭཥബᯎӃ᭱᫴K࢕sጇyᜐѻԈࡱ೺ᒌॊ᧖ᎆᦎ᯻ভᯰ᭍ᬕ᩺ᯮᮡᯛᯆᮍॶᮏ᭏ᯚ\tᯜ᪗᭝ᬥዥᯋᰑᰓ᪝ᮦᪧᓥᰄᯆᯪ᭬᪦ᣗᮨᰒᰠ᯲᮴I௝uᮺ᯺ത౰лᡳᦴᰯᬈĖୁएᰀ᩹ᔘᰉϵIRᬳᰆ᩹᡽ᰞ᭑ڪ᰾ᬬᯐᫎᯙᰊԵ᰿ᯗ᧤᧴᱄᭡᱇᭤᫯᧴ၭ᰽᰿ᰡᮬᦞ᱒ᰶᱚᰨೄᔆiᒺဇଶ೼ᬂᧃںᕛԕᱞ\tYA᱀ɣᯉᰈ঻ᰑᱰ᱈᫚ᬝ᱑ᱷᱱᱏᮗᣗ᱘᭡ᱸ᱕ᣜ᪟ᰗ̿ᬹᱱᱛᩙᱼভ᱇᮲᫴Ya᮷ᰭŕૈᓥᓤᱩൣᱫᔨюᱮᱸᮆ᭎юᲂۙᲄ᱉ᱻᰝᱽᱹᨪᬣ᱐ᪧᲥᕅᲧᯪ᯦ᓱ૚Ს᮫᲍Ჰᲊᬳᱡ/Vόdiv᦬to᯺ᓥ̱ᦾᬂᜦ᪁᰻ᱶভVLᯇᬔ᱂ࡹѫۙ᳒ᯏᱺ᭖᲻᱌᳚᱿ᰖᩁݠᰑ᳠ᯥᰜᣎ౹᪔᳓᲌ᬶᓶ᳤᳑ᳬᲾKవғyጟ᳐Ğ̵Მ᭽ᱬᲟ᲼Ტᰇ᡽ᲱܥᲳᏔᯒ᲎᱅ᱯ᱾ᯐ᧣ᲀ᪠ᴄᬩᴌ᭪౱᳥᳗᳓ᲅऩᨿᓱԴ᳚ᲴཊᢃᓫކᲷ᲋Ჹᳮ᱗ᴀᲾ৆kవྵᱶᦱᆱᬂ0᜜ᔲᬅ᳐ϵJCՀᗣᒚ᣸ᑴബJदᴴངࢨǀۙᩮᲬ᧝ᴈᲶᰑᵈ᳡ᳯᵆᕅᵎᯐԛࢭ፱ᵌ᱌ᵓᴟ᱖ᴜᬐᴥᬵᯬᳯ૚ᵈᲑ᮴ĘႰᄸާъଷᕗᇢᯁ૕ᨋᴣፘAമᯈᮇᵅᰑ᣼കᴇᰎᵢᵹᵴᵏ౎ᳪ᱌ᵺᴙঔᶂഃᵺ᳭ᵡᶂ૚ᶊᴪĊdҳkᚖyᬿिᘐႈᵭᨈ૦ᵱᲉᏄᵴᴁ᳖ᵸᶄᶀᲨ᳝ᳩ᳘ᦑᶦᰔᮖ᳢ࡹᵑ᧚ᶬᰛᵜᳩᶉᶡᴦᶌᵝভSRޅᲾUώ-ᕰ࢕ᴿ੝ା࿫Ꭽ᳽ᲞᲗᬱᴥᱳᵷᲤᲫ୦ᅉᘪᓼᶱ፤ᶳᵊᵽᶍᵿᵻݰᴎᶯᶤᴊᶅ᳧ᶵᦗᎵᵳഅ᧪൷ᴡᳩᴝᳬᶹ᭭ᵘϵᴞᳳ᪬᥏t᫸Ᲊ႐ᣮᩧో૮ݠᶰബPݻᶢᯊģ᧠ܥḅTᰍࢮᶂᷘۄḌᶁᓱḊۼḓᯝ᫦ᴚᯠᷨḑڪḘᵛᲆᳯഃḌᵥೄ࢒ᩢy၍ுዝ᯾एᨉᵰዛᷩভAN᳔ᱴᓼ᫪ʅḶ෬ठगѥᴢḉᰑḵ᳛ᵼḏᶻᴊṄḔᶶṃḼḙᯟᵐṍṅ᧪ᷧᲈḳ֕Ḷഖ࿔ৗ᥾ࡰᦁϵ࿬Ꮙࢩᔫ࿵іᙶᏊᦈᕥ୔আधᨊḜṖܫމᵂᜠᳯബᎲ୧ᒔᒮ᜻ᚃѺᦪᄶীṝṾбjҸlᇛऀ\tҌ෕ẂṜᩢഗరᚕd᩟೬ڪẊṽ࿚ẀẎẂ৆࢕je᳄ẉᎊẘ঳ẁ᧸ᶔpẞạẋảᩡᣩẂZశĊ˃ẖkẂழశҚẌ࢕౦ҩᇜaǞSpaһለᤒࢻយతềểާקฎǻǲីỀỂỄሏឝ៤ਤỊỔሜ੏ệ៎ăộỌྥᖅỈجỠਘᚩដ޶ỦចᑯỞŨồỡࣖ޽៻਍ཧừឍ࣭ᝬଐỷ๷ຊ៙અỼមỮỷᗫྙᗗ᝹ἄᗱᤚាᠡứ߭ἄິ៷ỤỒịᤢຊỗἀỰक๠᝸๯ỷ៮ߡࡍṟ˒᠅ĭ἟ຏ˸ฦఈ἟Αવɻ๓Ǧ᠄᠗ƗἬቡἣỻἚد᝼ƒἫἹቀ᤯ࠧ౏ỘἾལረƠᄙڤ἟๽ួἸἕச௩ᇁᐆỷߗ၅ἯᠡៅቹὓؤှᠹٷᐒἴἾኸᐣઊᝅศὓࣖىᖝᄬ᤼ὠ὎وၘש༂ᑰὦὡᡐ؝ᝌაņॿỰAfẔБᇏᝂ֋Ȕළ௺ύịώ὿ϠቖίᄒྞỠᾉೃБߗေҕ჎໗ᾇѹᾑ೭ᾓሳƮܪᙀᾙnᾛaᾓὨϢࠑᤔᑶşᾢᾤᾦఙܡኘᾭ὾ᾒᠽྤڽრᾳᾊᡈᇶᾠᾫĂᾺ᾵ᾼ఩ᛈᾎᓡᩢࢷත౮࣏ᥓᴲᎅ᣷ṀᣗѫỦᒦᢈ୩႞ᦆׄἚ଄Ꮌᢛ࿽ᘱރᾤఱeᰬڪ࿨йḮ࢝᡽૚ࢢרᶝӔṧᄙǀݺጴіӤԛ῱ῬআᔳᤋݐἚᒟ഑ᇯ࿄ὼᾴᾜᒟсୟĎᨖϵṷᰂṻᢤލᣥᇕᚌCޡ჊ᣠጯ᳌૔rᣰᎱḵࢣௌ॔֌౻૛೜രঋԽῳ፮യঀԨṁᣘᢣᔃẏીS᳆cᴬᚖ৏ࡱᳺᶛआ୞᡼ऋࡱኤআᦂ⁀ᎽૣӢᒡ࢚ṧᄧऌ‫೿Ӥѥᢋ⁇ṷᙽ῟ଈἴw༝є໌මᗏᖖ⁍ỉ⁚ڧန⁞Тᖖಕ༙ᔄᎌ࿗஬з႐౵ᓧᭂᎴᦎӍෙ̘ᔝႋృȈऑS⁣ĢᔀᕭႬăTЬkҊᕼỆᚷਤ₅௝₈ᝁ͙ᡑါ߭₍₇ཚᝩ܋ᝥၺₕ₏ᐵᅦቘόಡ₆₝ᝯᄱኞଐₜₗ฻ᄑᄠ₩ᖫઉᓊ₨₣ₗᑌ؝ၿ₡಴₳ủ᏾₧₌₺๟ȼգᚷڤ₮⃁ྙᗮઅ⃅໅ᾕὁₛ₿⃋ᕽ₠ݚ⃊៖ķںၹ᐀⃔ኑࡄ⃃޶⃔ឨ؁኎ฉ⃟၆ᕾ⃄⃏ᚴሺ⃢ಖ⃨યǻ₷⃓⃨ᄖ⃫ַಪ⃲ࡠ₭⃨ᠥάၛ₱₾₎ེჾὝᗴₓ಍ູ⃨ላ₲℀Ϳ৥̴ᒾ⃙⃏ᠷ࠼ታ⃿ₖͿ₫נ⃰⃧ℋϠຏ۪ቂℐℜΒ₵ŕ℅Ɨ⃊ᜉ᏾⃒ℕ₝℩ᕽ⃝ₔ⃏ቼϻಈ̛ۜ⃎™ℳϱ͵ᛶ℄⃹ℹᖵձЙ᾿₄Ⅎ੦޲ſჀ℧Ⅎᑝ۝ᾅ⃬ℹࡥ޲Ǚ᭘ℛ№၅ᛪℸ⅗وȽ༕։ኴᐆ⃊ὢŧኮ⃵℆ℹὰᤣة⅚₝ᡃₑᝀ₱⅖ⅭժـᠳᐥⅧ⅛ᡕ෋Ͽᐗℰⅸ₝ᡢⅻෂ׍ⅷ⅋™ᡨေڮቿ℡⅛ↈᕽታⅲཚ݀ද℉ℬ→ᘄࣵℚ⃞⃏8ࣖП᥂ನ๯⃊↝९ᜊಊཧ⃊݂ಶጏЉᜋ↢⃏᥇ݪᄫЌ↨↰ǲĠᖭĻᜄ቙ዎҨ࿦᫻̏ᔌᱨᰲࢁଽዞԵധᎺᜲᕀĦ₮ඔෝ፠᰻ݙ₮TR෬ᩱऐ෧⇎ᦚĠᥴ౞୯ṔḢᏨᏣḡḛᤉХᎈ⇜૝Ꮥᩔᩎᨩᩒ᭖⇮᥵࿒Ҏర↾ޡ᫼ڮ᮳ೄ⇷⇀ڮ᪪᥸ࣽʷĿĿ᷉आᎡ∄࢙ᎫᶜᨊᕈᕁᬓḸᔹ᧯Ꮖঀ⁖ይ˚ዢౌᦎḺᨴᨤᧄ᪵ᔩѲ⁏ॾঀᏧᒪޙᥩ೥᰻ᕍᕆ∀ѿUzhẓഝᎢൔᎵᙫ⇊ᥘ⁔Ṭ∖ᨘ।᧋ཎतदᰢᦎṣ౓य़῝ྦ᭡∝ఽᔴŻᨓᅁ᪴ᣄ≆ᷛḏ∧ᨍᏤ∎ᢜ∩ᯐ∫⇳′ắᄹೱo∱ᚏŗ᪰ᩦᨃ∈ࡳᔒUḯᶝ≚ķᨎ∑≎ᔺፚ࿮ᒕዬ∾˛ᨾ⇒ᵹ᪜≕᪒ᘬ∨ᥲ∪⇩ށ","tz/northamerica.lzw":"Rule\tUS\t1918ćĉ9\t-\tMar\tlastSun\t2:00ćğġD\n"+
"ĀĂĄĆĈĊČĈď\tOctĕėęěĝģ\tġSĦāăąČ42\tonlyįFeb\tĎĞĠĢŐWĽĨŀĈ45ńņňĐAugć4ĝ3ģuőġPŔĿĪ9ŘŚŇįSepĴĘĚĜŏġĻŪĩČ67ĝĠ6įıĳĖŶķŹĺ\tļħūžƀĈ73įApĔƇĶŸĹ1ĹĥƎŽƒŢŅŰĐJaĜƃƊƝŐƟľơ97řƤŜ\tŊŌ2ƔƫƞżŖƱƃĈ8ƃŝƗŵƚĸŐƬĤƽŬ8ƀ2Ƃƕǅŷ>=1ǈġǊ\tƮŕĆǐ0ƀmaxįĒĔǔ=ċƻƭǌƁǠ\tǢǤĐNovƌěǕǗƊŻZŅăEST\t\t -5ĹĐȀT\n"+
"ǽnăMȁȃȅ7ȈđȁȌǾ\tHȑď10ȕțȋȍǿȁ5EDȂȄȆĹŀE%sȢșCȁ6CȨȒ-6ȬĆCȯȱȎȖT7MȷȪȔŐŀMȾȘɀPȁ8PɅȅ8Ȼ\tPɋƠNYCČǐůƵǦǆŷǘŧǛżɚɜĈɞƴƄĲɢƉĹŻəɛɝǗĈ6ǃ\tƖƘĵɣǫǋɳɩ92ɶ95ŢĐŲŴƙɾɱƌɧɴĈ5řɷɹƅɯƛŐǼǾ America/New_Yorkď4:5Ⱥ02ȅ\tLMȂĊ83 Ǵv ĊˀŏŤ58\n"+
"ȃďȇɈĆȮȰɝ0ˇȃȫŐɨ\tˍʹŭ2ˑˉɕ˗Ł6˛˓ġ˕˞ɷ7ˡˊġȭɘƯChʢagoˏɟįJķ1ƺƜƼƠˮ˰˲˴ɪǗĐʗʌɰʚʏ˽˯ʣ̀̂˵Đɡ̆ʙǙ˼˭̋˱˳ɪŃʕǒɼƈ̓ɥǜă˾̙̌ʃ̛ʆʈƌųʘɤɲ̖˿̦ʓžʖɮ̮̒ʏȣʝʟʡʣ/̤̘˜5ȟ36ʵʷʹ8ʻʽǵˀ8˂ğ9:24ˡʲ˪ȼȾˏ͖Ĺ̀̀ȽˎĈͅ Ǧ ˀͦŹ˨ȕȊČͣʾˀ5ͨģ͜Ő͞˳͠˘łʹ͘\t͸˟ͻͽ̗͚͟˦΀ŀ͸Ɍe̻ʠ˰ʥʫth_DakotʤCentʠȅȺŘ:1ʴ- ͈ć͊ʼͯˁ΢Ρʯ4ˆˈ-ɇͼɊ͡9ʃ ƅ 2ͱλͳα͗ŽΈ̺ʞΌ̾ǴrΐΒΔΖʤʦʨSaĂmΞ:Π39ȅΥʸΧ͋Ϊ͏ά1ʯʄˡγŽεȂǟʼκ2͆ξĠΆ͙ȰΉ΋̽ώΏΑΓΕΗ/Beāahϕ4ɇ7ϚΦʺΩ͍ΫĞά53ϥɕϨƁȞ͌ʿ ІϯːπɕΈƠDΚvʠ́ʃ̃đḙ̄ɿɦПСУɪġɬ̶̄ɽ̇ź̉ƯРnТĔ̎бЧň2ŃǻзĨйлžʔ9ɸ̝Щ˻ǬЬкЮъщывƆд̠ʛȎϵ΍цУȹʰ͒ʱ͇ϜЉЖ͎͐Ġğ͕αϦɉ΄ʃЛ˒ϦўĔГŗ˚ѭВѰ4ˠѺƭЭѶѰſБˋđˬĨCAŁċоɡϢɤǚ̢ͽҋŗĎоƧĜˀ̸ƍ˭ҕʆǙъɹɻэǉ̕҉ҟ̓žЦʊҥжҝҨž̨ѕİг̟Ҝϴυ϶/Los_AngeĂsȓʰĞ˅Ѥ͉ϞЋϠŏɇѹ˒ɔ҆ɗζѽˡӔġҊɖ҃˧αӚŽӖȿΊҺ΍˷ȎaŦͰğЍϙĐЈǂІκĊ˛ɓʰȔ41ӋČĠʝşλ0ѩѲȪӡĐɎ͹ӒԅɕӣͿˈӷŐԇȑɷ9Ӷ-ӡŀԍǁԂɻλЙͩԏ-͒҆YѰ8ԂϬϮԠȸԘĆԚ9͋κ3ԂКԖԣͼԥζӍʿԳԶɕAKɋτ̼΍SitkaȄϢʰɔЄӼĊſιĲ͎Ծ0Ɲ˹Ր9ӾŞgԁԃԖԆɖԓ˙աԌѼѾԬȕԈžԕԡԭӝԺϫՔԳͲϰԡԷŽԹ˘Ի ԽոԿՁϳՃφʤMetĖՉ։ՊӬ˹ϖΣʶѥӲՓtՕկϖȺˁӰѥ՛ԜԀǐՠ֘ԑգԉզӕը֧ġԒ˘6ծժ֨ղ֕վԴԫԋ֤ԈҹՄ̾YΔuΗĳˀήƬͱ͉֜ՒӴΰȸ͒Ċʰׅ֒˘՜֠Ԃάշ׋ȕYդͺրԤ֩ל֫\tי֭֯ȪչŀջČստח҆ՀՂʜӦ̾Ӂchʫ˱ăׂģ͓4Ր֔׉Ծ5͒ͣ׆ӽ֟՞֡וԄ-ȞȕҊ֦α،҆؎̿AWTˀŭͱ՝ׂλŤĠuˡؑͼؓҊPؗŗթȝȟ֤؎ƐʝƗءثנAȡխرԿHԦճ֖յԵןպغѧ׫ץցׯћױϷʟՋӉɔʄ׽׈ՔӵؐƬƝ3͏؄Ĉג؇הֶ؋ǚǳךԊٞɕNמ˒1ٟ\tNդՒɻء٩B٬פ٣҆BفԲֵο׬ԸفͯكȅצĆ׮փװֻʤAdΔًΡŤَ٘׾ّ׊ȝƝѽ:ٖ՚ٚ՟؉ٯȕ٫؏٧ǚŀ٥ӗةٴנڞخٮٓȕٱףڜٵٷմٹזتظٽ͍ك؋زŽعڄћPacifʢ/HŅolāŦںږƝϭ׽ъ ҙˀʼڛؐ̈́נص͢ʼԝؽٝ،ԳɥHȷۜͤayλӻۗ٧ۙįۛ˙ Ʒͦϙؾۭږ̔Őۤ͹ͱʊִն؊ۡۚךІӨͦ͏۶ڵ֤ȡ\n"+
"Link ۀۂۄcۆۈۊۊܒہۃۅJohnĘŅֺօ/P׵ΚiǲȔ2ɔ֛אϝЊʿΫٕڔ٢ѮĆѷŭ׼۔ͧ ث1҅נȐ͹׼ԝܿ݁݃ϧѼ׼κ݉ğ݂ѿ݄٬ӟѳѻζ6͏ͥϤݓǥȗքһBoisăβϖήӯܱѦϟ͐1ȇ٨әէζƹۧ۩ՙ܉ݨܻ҆7Ѭݗ֤݅Čݾ۲ŋͦʼݺܹ҇ϳƎ IndiƨapۉݥؘӺ̏\tӨĝтюʀľގސޒnޔޖӆŗʅʇű̷̬уҰΊޏޑޓޕlޗبČޫǄ̞ǇЪĥݡ΍޲ޤʤ߂޴ާȅȇ4ʯڗΤӱսЌΡȇсϱͽѰǐͻޢ޳ޥ޵ޗ;Ѹߔߞŭڥ͗ߙ߃ߜӆߡʓدrλ׼ݺ˩įͬʒІ۾2۵ٝρĐȳ˘ӊԝ2ԟٺ˜֤߲ъٳ߰˫ζ7ݒ˒߰ȉȑǟڥࠇˌ҈ȏēΚ̍ʆǗоҤޮޟЫƯǦ̲ࠗࠚśެʋјҸƠࠡӂ̲ŢɷسǅࠝҦяࠠࠖࠬ޹࠮ъנҭ࠲үܥһ߅ޥ/ࠫ˲߈ϖߒʼڏߏӏέږݖďρ·Ѱ5ࠋࡐĹࡄͷ҃ӻ۞ڳ؊ࠍ˖ٲͪ҆˥ƱܽƨͦԪࠁѠ࠳ӛۥࡥֳ߿܀ࡢͼࡤ7ࠑͫࠏƂࡳŽ˗Ū V܏cΚȎs˟ޚࠜࠨ޾ࡾࢀnࢂnࢄࢆо࠼ࢉʎްࡿࢁࢃeࢅʒƔʒ̪࢈ҷࢊލࢌࢎ࢐࢜޹Ďʉޭ࢔̈࢖ࢤ࢙࢛ʆƳࠥ̐ۨՋĺ̢ࠞࢗࢍࢰ޹ǀъƔ޻Ү̡ࢋ࢘࢏࢚žаࢴҵїࢡ࢕ࣅࢼࣇࢱ6ࠤƥ̫ࠧ࣎ࢭ࣐ࢥࣈɷҳࣁ࣌ࣃњӥچ/ࡁʤࢯ࣒ࡆ̓ğІߍ֓ࡋѩѢАМؒ٦ࡖӾࣩ࢐ߡ6݇Ɨλࡩڴˢ߱ࡡαࠒ˖ѰࠊࡻࠎϩƂ߫ͨࡲࣵأ͚ǟІͯ ߮ٝइࡽލPʠrň޸ࠛ࠱ࢬ۹ޠĂܒटडߢޚ࢓ࣙ࠾झप޹̩࢝ь࠽ࣄऱrठळࢨࠦ࣢фΊञऺफ̳ҎࢶқڻҒࡾूऻʒࢿ6࣠ࢠ޽ࢹोल࠯ޚ̅थƋ࢖ौफࣔभࢫयज़ॕृҲž࣠ख़ॢࣣќ̾ࣧ/Tӄl_CՇ۩ȫЄğࡉϛӌܳѨϡӉࡏ࡫ओڤߘढ़ߕݙࣾ߬ې߯ࡸڮआ˝उࡕःऌǮ݈͆ʴݺࡑϲȋƠPikăʒࢳࣖĒňै॔ঝটডࢲࣉाष̯Ĩঞঠࢾž࢟तॢॊ঩঳ɷʅࣽɭ࣍॓ࣚ߀७ޣޓܧֈʠsbur՞ॷԣ࣮ॻܲѧߐ،Џߠࡓ5΀লؚ̣҃ࣿμऑࠌ঍̴ֳ۟ࡪচই˘7ӳڲৢࠂנͬࠐएλ৯ংςऔĠख͍घ৶छࠔƌΗʬফЄҫशग़হƯSਂ঻ŭƑवࢪࣘুरਊ਌ফ̳ॎিिްਁē਍5ਏ˅মग़রă਋ਞਗĎ়ਚয̹څܦ८Knoxࡆڕյࡊॽ৕Ťڹ৩ߡЄ΀ਧਃ৪Ҳए߶৾৤ɷػԞ৶ਾѰĉࡰࠀं࡟৲ऎগ੍Н਀PЀskiࢆॗࣂषਉ঱ੜਫ਼੠ਐࣗਛżਜ਼Ƈ੧ঢ঴і੫ঝ੦੟߳ভ਑੫ৃ߄৅ࡂW܏aǢcਸ਼Ⱥৡ࣯ॼ৔ࡌ֏3৚ऒ৸঄઎੭ė੧࡛ࣼࣿ১੓੉ࠅࡻࠈ৫঒੔ࡹ0খࣿ৵ঙਖ਼ˎकۧ߬٨ੈࡣنࣤਰ੽ࣨevۨਸ਼ȟ1͆ਹઉݯ͒ߊ৘ζʇ੆νचચ֮જࠓࠉࣴৣࠃડࡷમތޡҽuݥvilĨн࣋থćґҧΊ૓૕૗૙ХॠŴǺ࣏ލૡs૖૘਄ঽЦ॒ʍ࡬ࠟन૫૭૤ޙ࢒ॡਓॣ૪o૔૬ૣ਄ƃҘƉࠩ૒଀ૢ૮޹ҡ̳੹ਭ࢖૷ଃ঴੡࣡଑࠿΍KΚtuckyҼଊଂ૮ਸ਼؞֑ߎ਺ઊȺ˅ી˘ݝ˒ߤଓଥਿ٢੎ઐ଱ģΥଣ૸Ίકۓā؝ભৱ٬ڒःઝރࡦnࡨ੘૴ȶ৫ݎՔࡱঌૐӤ६ʤଛΛଞଠࡃŅtʢॱoࡆϘ׻Їࣰପ͐ǐږߣધ͹୬ج୅ମǮԨ୒߷ࡪ৿૑хֈrݤĳŗҍ࣋૲еसи୻୽Ҍ૦ੳஅt୼ՇƐޚޜҐࢢ஋஍୾ъƀо३૽५و/Р஌இȫ3Ѝӻ٘՛ઍହ୰˘ݰݷͰୃऄڟৰࡼࣷःடகई૊ૈஸ৫நலঔƒয়ঊ੒࡞ঐ୹Ίևਲ਼m܏e଄ࢇষ૽੤ேΚoொȎ்ૻ਒૳ਔनை௔ோফыण޼௚஄௜௓௕ௌ̴क़Ҷ஛ਮهࣥ௝௨ݧȇ࣬ࡱࡊ۽ųॾ߸୭ԎனԂ௱௟੄Ԕ੆௃ऋࡠ৫۝ৠ୶ंଷজ˭ޓډĭ஀ࣖҤஒনఏޥ఑īఓƵʗ߿ଈ҉ఐՊѸޚƷȄŎࠞœ˽ఢŁণƵ՝šţťɥũఫఙణؙஉۢޯżCబƢשң௏௤௑ͽిࡥকਬਤीెషשǏǑࣂǨ૨૴ғా౎कǰǣǥШǨǪగడౘ৺ౚǲ٪ǵǷnǹఠਦtܟܡࢱ1஘஁ǅ ౟ౕż਋౮ܢĭ౲ࣖҭ౱౫ਁ౺౰җ૛ेřƹౠ౬ಃĭಅఔşćт؞௛ಋܠ౻Яͭřࢵň౓ల౷Ơ౹ಖࢱɞ͢ಚଗࢉಓ૾ਕಌ͢ࢿޙಛđŅǕĎॉ૟ಂಢͭಮЦʗMಲ=Ńڻਥಷ౯੨Ҫರ౞૞࠴Ĩಡೄ޸ʒנʗǨޞࣚಠ౭ಸʒʅǂਇসಶೌಗ࠙ऽଐోਜೞ࣓ҡ೚ੲଘೕಬ԰౽యǓǸǖࢸ՗௥ಕ್೭౉೩ࠨ݁ಪೋೖ೷͊௎ǧೱǗ೼ƊDғ೥שŎ౑ɺ೰౩ೲ೼౅ഊౙǐ٨౜ഃഐċഒೝ೿౻ക՗ڧ౧ಝ೼ஜࣥ਋_ಌ-਼ȟ5ନࣰݿďബӈ ೥ʽѰْ˒ളമ ౗a఑ڣ஫ٳ഻ʴശുಙપִˡബೃ౻േѸ஭ݲαൌാീழൌഊേഖӻʾോ۸్ിՊുଙ̾GoҾe_Bࢶ-ʯ՗ϖԂࡊറഫ۸ഴ٠஫୆ൄഽఢഷζĈ൞Գ൶٪դઌ൉ڹൌ൷ಹ඀Ļഞࢅ൏۱থˀ঒ൔబඏӘ൓ൟ൙҃͆ͥ஬ݺ൮ඌಌA৹બ൝αචൠ఑ඣெȚϒۃ౛īଅ౳ĔধಟƯHථfධĉ඲ࣖʗඵಔත޶යǤಘॆদ಴ಊෂදළѱࢇಐ߶ೳශමසරʄޚ૜ ƃವೊăු෌ɵɝŃ੹ řುౌෟහ෢ം\tۢොधෞඹූऴμ౜ಜഄි೵෋෪ɪƔ௘ȄŢ෧ਜ෩ූƣ࣋౿෦૩භෲ෍෵෿ܮ෹ೂคญලɠࢶહ෹౅ณɝตा˹ฑ෨ฌɝ೮෶ࢷ෯૵෱෕ญฤ੹ϭภฃยɪċ͢Ц૜ೈวғปาஉ ෉೔ซสɝಎƵҭվฯżฺ9ۢ෿ݰ็Ơ้3ʅணाಽഐ͔๎เ෠͢Ń෇ฦ්๐෾ඳ෭ź๟ั๊๡඾ɮλ๘Ĩ๐ฆতࢶɞุ่๦3๯ไ̬ธข๴แಥஐķ๫๳๏๵మा෮ช๭๵ฝƦ຀അ๥๽๊຋੪Ґ๻຃ຐ3ਏٖลതຏ๚๊ਏಯ੪๕Ǖ๗ຕ๙෼๊ใลฐຂວර4ҡມึ෸ອຉຐѽŁࢩഎ௣ஃบ๦ຸҖਣ४มຐࡔ࠸೛ௐಶ้ໆ࢞ໂ௭ะ໅ࢿ؁່ౄ໊๦ʱೡ੪೪ຮ෍6̨Ɠ໔ຽ໖ຐໞރ२௬௤ദܦป൭ࡍ͔ژʴ܆ݰˡඨปණ൸໴͝బ໷಍໹ۺย໼൐۳฽܀s໾ӛ໻ழ໵ༀउ൳ඨൕՊ໷൤ʤGĖࢂ൪൬˄ાٗݬ՛໱ěͰ༇ඩ༑ࡓોʮĹ໶ࡓ༎ȕAդ7٢་แ༁ࡥ༢༐ɺ਀๕ĲŅͭऴઌ˶ķೈǚ౅༹t༻ۜಙाཁຈȏŅ༺ĜಭͭċຌĜಝགಶངཆຑདཉ෸ǚೂམཏຩෘ๱Ƒ්འͭਪŭҬ̬ϑt຤ɶཋಱࢍཅཡະལफɥགྷཌྷུŁࣕถদ࠮སཻཙເƱ෣ົࣃ྄ཱེི໒ɹम໏żཧ੷ƒ྇ச໩ౌྒηƺ഍Ҥຜ೴ྊཎČ๊೹ಧҷഥ௮રһཧ໭Ĉğ༜଩ Рઃ฽ఆࠄʳୀୋ໳ට໺౎༳3༦໭Őཧ༳כ˒༏༉ସ༧࿂ྃĜ༳Ɠ༵࿈˘๊༢࿃৹Ǡ࿐྽યୗϽĖࢍ-ϑblŅȅŤί͓ྯര࿘ൡ༷ࠉ؊ඨŝȗƠTʫ୞̦ĮॆĔ఻ൌ౅࿳୼Λ࿶ສੲฮ຦Ĩ࿽࿵˴๝๫ஓစ࿴࿿ဈง̬ဃཱဆဎ૚๰डಈ්နཅ෡์မ฿ဌ࿾လ̚ɝ࣠ຳച೉෰\tရ̦сผཛྷഐํ఼࿲ဍဣʃ࠹టೇ෸ဋăာรͭ྇ྏྗਜှ฻ิ໡̠࿼ဵ̦๓๝౔दศါ။༼Ł࠰ຼ၉ಶ၅๧௫୾ಁၚ๶ཨ໎၃żၚŮ޸ೢໃ၄ၓढ๢੣ၙၫ਎ູ၈นၯဢ̦ਅ୿ၢķငွၰ4ခ౦Ƕ̷ၼၒၶ଍໦ၳြႅဇ೏ޚʾஊအႌೠਙၨྐဴႆྒྷƱ໧ীၣ੻९ၓȫ౱ږയ͉ʆࡻ༶ࡤൿএŐှࡤłޅb۴༅ႧబႮ૏ġႭ།Ⴔ౎ࡽ႞Thědʠ༘ॶ௴γۑ஽৷ߺդȞྵ١Ⴛ࿫ࡵ௄Ⴌၓࡵ࿀ઠ୐ა఑ႽਯһNipi˲ĜȫЏѫ჈ლՊႮԂߵࠆࠞȧԉႰႲК༆Ⴋ༈Ⴜ࿚஝Ra܏y_Riлϕ׍હშ઎༶ਿწ௹߶΀ǚ୏Łʴ༃ఋ0ჵ௾༣৪༓/AୟΕՉფʲઅ࿨Ⴅ჉ρᄈѼᄊpλٳρᄎ࡮ႯᄒႳᄇబਿ௸ᄩઘდୄఎĨ੿࢏ĭຒҤƹၴෝ\tᄼཡธ์ƀႄᅅఒ෬ఖබᄻ܏ᅆజਚటဳƯᅋ͢ฬпćƪ්ᅘຟஉฮᅖᅐᄽతоద฽ဩᅄżᅟŮࠛಐஒಓŦǚవᅗᅑభஉ໛ᅤཱུຒ૜΢ᅪғᅭຒʗฟᅣăᅭຠ຺ஂၘᅃᆈၲ႕ၣƠᅟҪဉ၏෺ᆓ࣊౾̬఻ཱᆓঽၖྉಶᆞ޹དྷ໚ೣᅬᅷʒႀྖஃೂᅟ6ᆙ๸௙ᆭౌᆯ๨೯ၗᆀᆨᅥࣀᅡ೓ශᆯࢿ೨ྈ࠽࢛ᆢᆩҢǮದᆬ̓ࢅᆮᇈǎᇊьಝŹᇆǬ႞ᅅრeŠѠܮ୫׽ǎୀlˀ୯ġᅋ;ࠐ΀ᄦඬRᇛ઀ᅌ௢ఱႊᇭgᇯఛၜĝǏཱᇴᇶ๊ҡၠ်ေᅂဪᇼޥͭᇿ̪೑ິᇻᇮሆᅙཽᇓೱഛ්ህసຘᇸืሌᇵሎ๊ᅓੲྞශሕၡީਚሙဠăሢᅦ࣋ᅨన૴పƯሩహᅯŠᅱళᅴżሱᅮတᆳљౌሹᄿഏǕ౶ၐғሿመሒಁሹਡƀ੢ਈಶቊ޹ቌᆦၩሸልస໓ᇱၮᅃሱቘ࣋ᇌಁSwۃ஖ਠ෬ቚဪቡባቑᇸᅺਦቢfቤཀྵय़ቍ೜ᅃቩተऽங໨ᆴ೤ቯ஖ᆰਆᆐቼᄙሢѠ˅ᇟ஦0ᄵ݋ሢܻᆰए୍̒נ߻ᄙቷtॳৌrଜӇ٨͓൱༝ኊവų݋༶ܻѽነј৶Ϧኍࡓ؊Ϧኖދ৫ʴԝኑદபżEdmᅌīᆊቁǩᆺƠኹኻᇷቺĳᅕཱዃ಍ཷᇹಁዊಘ෽ႉ්ዏ෎዆႐ǿኺ෡ዑኂሽਜዔłథŋధᅪሯĨዟ຅ŝᅰŢಉ؟ఴኸዙŗየቓ႖Ưዟᅚᆋ዁ድደၱ෿ቭ˖ዻſቦ቎ᅃዔጁዖዾጅႀዸႊጉቬᆧዂዻ༯ుዒᅏዘዄ྆ྤ቟఼႞ዃ࿵ფȔ྿ංЈ՛͆ʊ݋ዊܻǎኤబϨżVƨcᇰ๢ᅎቄጮጰጲ๩዇ᇺሧ\tጯࢍᄐዡŌᅩЪዥăጾጱዱාሴያᅲዮƠፇᅸ෿ᆜጼፐ೎԰ూᆹႊፕबዖᆅཱ፛ၸъཫሼಁ፛໥ࠐొቔ႞ፇ଀чԗΡĞܮᇠ൳ӡፐԯጪӠྼ࿫ӣᄙΓwsŅॳኚeܑ፯Ѫѣ൲ݳ͵బԯੀ፹Ő፶उኳԀᄷ݋̐ݠო΍Cኚܣጟ֙ყᎉݞ᎗஫͆Ӵᎊנլఛྸλ᎖ɁɧTʩKጸᆸᇲ්NᎰYᎲዅ቞ɮወጼᎷᎱዋ๝෵ႊᏀᎹᏂ࣋ႏව೽ăᏆᎺ˙ፁዣፄᎯᏁፉሳᇲፍሷəᎸᏏሺᆚŴፓශᏎшጂྦĹഇғᏣɷዲጚཱᏪ԰೧ፘᆡᅃᏯԧጙቻዝᏔᏇǁ౐ઢሑሂࢊ႞ۀӂniωě՞נzᐋɵ༢Ꮳ༳ʆए౓யႨ੏ϙԲӻ኶ჷ࿫ᇨĠ୴֖ੇ୔ᐛმჹࣥIqϒ૔ĳᐊᐌ൐՝ࡻᏣࡤη০ᐙ௻ᎋ౎ᐝӾϬᄓჩ஻ኄ࢚ۉֿăᐬzŁІ؛๑΀Ꮳᐹᐟᄪயঔǟખ߬ܿಓᇪᄳ࿖Ꭵ୵ᑏఇǮІඝᐙᑕᄲᐸᐥܦ჻ܐ܏_ޏĂ֖ᑄቑᑊᏜ੄ǟᑍᐡૅ્ऍ՗৴ᑠ২፺఑σ᎙̾ాmbʡdӃჄ݀įᐋᑅЯ݋Ꮳܻᐳᐘኒᄗᑌࡰᐼჶர୳ѧ෥ͦز΀჋ᑷᑒͦᑺंϦእᑤһYୡwkᐅfΊᑭಥᒍᑰጩኮᑼՊጭ႞ޏu૖ʭᒰʆ࿀ӡᏣԯ7ϙኴኩމĹᒎԦᒵᐷ࿫ᒸᑿʤW˯Μ׵rݦďԷ፰ژ؆ԁˡչᏣר˦஭፲݀ࡪᓁᑰ፷؊ӡ༶፼႞፾ᎀფ׌ӹኟጣڙߗαᓟᑰᓡႚࡰ܈ᒝᎏˣᓨᓋᎧᄗ፼ࠪexʢ၌ႀదฉጕđᔈᔊၡଆŸᔎශևᔉcၷᆱįྲōሃၑᔘᔒሤᇱຎጼᔢᔚŁᆷᔝeፈෛ఩ྑᔑᔩŗ๷ลᔦᔗᔲ̲ᔜĐదᅿີȏᔹႇଆl๣๬ᕀᔙ̦ъ୳᏿౪ႊᔨᕉƪᐞ፩ዴĨᕏǮཾປျསᕁᑑᅹጏࠠᕜĠŃǱᕌೲᕎᕡʳ౤ᕓႝᓐ̿ጰķॷɇ׼஦сۓࡧݐЎᇥį߻שӻྲ؝ࡻᕖᐲ͏؛થᐶġᕖᐝ஬༃ᐵ୷঍ᄙևᒄՊქٍᄢ෢ᕶୋݐ൯ணᒞͽդ8ᕾᔭᖀᒗி԰ʴᕿᎬ઎ᖉᒧ΍ĒΗm࿴ࢅѠະ଺ᕴᖡઃ๑؝ኞᑻபש୆఍ഋ΀ᖫનഡମᖐ୞टeŜΟ՘઺༝َᕿᖹಉ׍િ઎ᒟᖾ୲ǁᄫࡗᕁᑾ௯ܦᕏॳॵϕͅኈᗏ໱ᕷᐙȟಉ͔Ꭽނɪ܅༠Еዬ؊߹ᖞ˘յΪ჉ϦᎣͭӻඑͧᗴᖝᕼิ֕ᗮ඄ኳત঒ρᗃᒠኢᄶ࡝ᘃડᄑކᓷᄖᘍᄙOj઀gᖓବᓳ՚ᕵܾᗪӭኞᘇଯᗱྐྵԂᘂᗖᗷሇ৔ᗻȕᗯ๊ᗿશᘁᑡᄖᗗᘅƅᘧ၀ᑹᘒ࿒ᕺᘍྡྷᖿ؍դ԰ᐒഄއࡪϦᕖГഖᓌδᖬᒀ˯ჀЁuᖓᕲኞᘡᖷվӻಉʓ൰ᘽᗰᎫᗳᘸࣸና඄Ԃᗺᙣᘴ஭ᘷᖼᙩᗸӻᘼᎢɁᘾ݈ᘋᙆᙁᗂᗝ੏ᙅᖽĈᙈԝᐓվᙌᗜᕈ኱ᄙHʠᖰsૣ˳ݨᙠႤɵྱᖢᗒ਼ʲ୆ᗼᙷᙤ໲ᘫᙧ჊ᘮ͢ᙫЋᘱށ඄ᘵ۩ᙰఌᙻᗾᘆᙶᘳணᘿᘭᘄ۱߾൳᚜ᘳၿᖘׂᔄ֬ރᙑᔐᚉᒏٳᚺ᎘ᗟྪaza֌᎞ኊ൰ᙜᚖᖸᙟ˄ϣᛂᗽ᚞ᗲᚠᙱᕻᙪᘰ᙭ᖹᘀᛕᛝᘺ᙮ᙵހݔᗸᘉᑓᙺᚁᚷৠᚹᘲךϙ۔Ϣᚿ֥ᛁ݋ᙎᙓʤ൫˯a༘ސʠėďɇǊᛒᗑᛤ؁ᚇᚨᘨᙥᛜᚭᛯᗹᚦᛡᚪᒢᖺᜒᙲᚯᛨᜆᛳ᛫ᚴᘹᚣᛰঊᛲᜎູᚽᛷᔀįᎩƱᛂ᛼ᗄЕ݈ङᛝᘘႾijᙘሆݨ࿦0ᕳᗧᚽᕸƝʱ᙭ᗭᜫᛀᛚᘪ᜙ᛘ᚝ᇾᛠᝇ᛹ᘅᙹᔄᅴ࡮ᖹ۾ڹբᜭႯᚸ᝔ĹPؖభӿ՞ϢᝋؠᜫᅴئᝢΪ٢᝚ךᖄત჉ӡ᝕͹ᛵࡧᜪӓիդʇᔄӜԯࣔᛸᜭࡶᔄԙ੏ڥӡᕖԍᑑងԮ࿖ᘔႱᘖďឈᕁដᗅᜫចھྩՅƨΗᑩsabӄ᜞୤፲ᕴᗨᖙᘤ୪ᖜᚱդᝆ᝹ָឭᘩˀᜑᝌᚲᚥܴᝲ᝺ᙳᜡធࠞɑុ᝘ᓪឺᄐ੆፴ើᝡዱᝣ؜ᗴᝧឯၐPᝪ៉ᝬខᝯ৴ឹ૴ឿᜨᛶំឰ߼ៜӛҋ᝿঒ᝮ৫ជݴᙼᜫញ࿖៣៧Ǯតᓝ៩ប਀᛿ઁᜅɷ࠹ƲᕫኃƠ៴Ǣ࣓៸ದጋ॔ȣɺࣥNėសیˊ؂ᓴ֝΢൉٢߰៽ᜅࡵႷளඬ൫rŌƒᅚ஑ᆿ෺᠙᠛Ʊਏ7ᆥሊ᐀ཱᠡރำᏰᕥဲ්ᠪƒႀҭᏡᏌ\tᠱᠭฏဟ࠾႞ᠡിҾലՍ͓ݫጣឮᡁኇੇĐB֝ឫ࿆Ĺᠪ༒៼ӄizফĬతሟೱೀɱൟۤżϾ޶ᡕዋŗ࣠దǨ฾ශᡠᡔফ໠оᔞ෥ᔠғᡪᡢీᅧዢᅩႄᡳফ8๜࣋ᔞĬᔿᠷᡓᡴ԰ᔫᔼዢᔾ࣏᠄஝᡺͂Ğί՚᠏ڪᄖᢍᗞӥᛎୟܖϾrmu఑ྫྷ׌ᖖᚤᝁᖍं࿯ɺ༮উλ܈ٝ࿇࿙ࠉڥඨŀᡑ˭Rރཀྵ᏶ᢇŌႃ්Cᢶᠲשנޜሠᠶᢾྡྷʅʃ˶ƨƌᛍǹᔖ෺ᣆᚂᕘຌᕄᏋೂᣑη᡽๰мᣏ໪һCҾឝᄀʣ˜ᗥՙڏ՛ͪᣦࡉƌJَ֝ᛶᄤ͝ᢶО˭ubసฐᔔć๤ᔏC᣷᣹ሞ࣡Ȟᕆͽᤀၕፀན౨౪ᢁ᣿᣸ᤈᡘ੪ᣄᣗᤇፉၧޛཀላ᣾ᤕహᤗҭᤓౌᤎస6ዲ஑ᡱఽᤜᤤ఺᣽ශᤢ௪ᏃᡨᣐᤩᆃᎽᤅ᤮˦෬ሓᤛᤏᤸɷᆥ᤟ቈႄᤷъᤂకกᢽᤩཀྵ৬ၳᤍ᥉ރ಻ᏸᤶᤜጒీੲ᤺᤭ᥓщ᥋೺Ꮶጼ᥃ᠥዌᅉ᥈᤼Ʊᠬ՛ሥ᥁ཱᥟᢸ݄ౝഄᣏ౅᥃ᖠשದဧǕᥰಶᥲᇂ຺ɡ౓᥇᤻సᥧᚂቒྜྷᤚጵ˽ᤜĉྡྷᇋɮሦᄔᣅᦉᤴׁᔯĠᇎᤡᦉᅚᆄᡛᦕᦐᥤ԰ྡྷ᥼ШᢼᦜᥱᦉǪĠႛ̭زᦖਜ᤮ᑲǮ॑኿ᔷᇖဪ᦮Ġᔵࢵᆹᦫᤲᤏ፨ᙐ៺Ĝᦻᤔᦽౣ࿸ᤋዀᦻᦥᧄ0ᤂ᥽᥯ිᦴၑᦶ0ഌᤄᦹᧇᥗ᧑ౖᤇ൛ལങᣎ᧐ᦼՊ᧝оႏฟᧂᦗᧄᅿᔥ᧡᧊᧣՗ᕣ౛ǳണᦆ᦬ᤨ᧪Ɣᕤ᧗ᦎ᧚Ή᠅໫aવ᜻ߒ͒ឥݬ8ᣩএ߶ᗦHᣯͱ˷ᇣĈ֢ૌӛᤇᣵхᢿᇉዖງᔏDᨙጆራዢຬཱ᨞խႈᥜǇುᡝғᨥƒᔻƶᨢᔷᠶᨭƱᣓޛᣋ๲ᨤᨙᥔైƦᨸᨲᣞល࿿Β௞ࠬȅߋ؂ᗎӱᨉᡎྲྀʉDᡌఉ᛭ᨓலᨥࡵ୑ᐠঁᢧ༭ᑷᑳᒖᨔ᠗ᩝᛓއᒢࡪᩛ࿱ਊϒǶᏼᖾᕙሂᢁϑlᩫ೸ǁ᤿ૼɣ๻ጜॲᩱવdʫ࣫ΟᢢХੁᩪᄘƠGᙘ஖ᡭᏉ౧෵ᢁ᪈ᛍ୉Ꮡລཱ᪐஖ʻዌ෗᪏᪉שᢆ੪ီႄ᪖ᣇ᧞ţᤧ᪇᪜ᣒ฼ᥢጼ᪢፨ᇱ᨜ᦇƯ᪭Ǒዖᣖྨ࿛᪖eǢĖࣸŏ᜿ጣˁκᣲŐ᪢ᨗ෱Շ੶ᢅዌᥗ෺ම᫈ש࠹ᇑቴᨩ๥᫏ǁऴ᫒ྥ᫔ጼᫎୟᩭᦃᠮŧ᧽຃᫖԰ᥦቒ቟Ǌ᧶᫤᫞ǟಈྜᦲ᪦ซ᫏᫮᏷ႜၻཱ᫝੟ഖ᧱౥᧎ဨႊ᫺Д᫽įႏᇔᢊᕭPΏ-Ӫ-Pʡࢼᩇϖᨅ᠍Ⴅ࿮ᬓᜬP᠎܅ࡧ໯۬லᬂजභŅd౏ᩭሁᤌ๟ᬤᬦ᩵ၺᧁ᫹ᬫ᪮ಆ෷ᩯᬪސ౉Ꮧຣ഑ᬈᛉ΍॰gଞტϒpaਸ਼ɔ഼ᖶ߫΀ۇᬷᢖ᧿һƧǢ˰ࠂȔબᣨდ᭕஥\tK᠎ត჎კᒗୈǁ൳იᖐēୟᐅquݧ൮ᛗϚͦ᭰ᩋᬗ᜾ᙛᔼF᠎ᚪ༢࿰ռԜતᢱࠞA࡮ԧᘏ᢫᭺ᢨᄺᏍʢᢷᣁഘᧇ๺Ꮆᮊᣀԛ༿Ĝᬺᅁႄჟጱ᫵ᔥ᤬෺ᮙᇒዖᤠਜᮟᬲఔǅᠵ౅ᮤ᪴Ꮌĳཕᬼă஝Ēޥᭀᖓ߉ˊᢢᨈ௄Π᠏̐ᡌܽ༠ƹᙀ໦ݷ᭟ރͱ۳હᑊᮊߡθᘣͦචᯅᚂ൅ᄋ൳ᗶᚶ࿓ᖤᑜᦃᯊጱ᭎஝ᐃ៵˜׍᧌ۑ௄ྭ؃ͽ֝ᯤ߾᠑ᖏ܎ܐ࿛ᯠǢ࿛ాyǢnᄙਜ਼ʠཅჿᔊᬒ͔͓׏ᩋϙݜࡌᢦ༬١ᙯ࿀ᢲڂ༊ᰈୖ᮱i᭪ӄ༻൴ߊᛑ஦બඑྺᡎ֤ᩜᣁᯄ඘ָᘳ፸ഺᒶɖᓏᬽ൥rƨd_Tৌʭ໭ᰗᚳ᭗ࡢ᭙ʵ᭜஫᭞ᯙࠄᓄ஺˞ഖͱͯᐓ᢭ᰏ","tz/pacificnew.lzw":"Link\tAmerica/Los_Angeles\tUS/Pacifĉ-New\t","tz/southamerica.lzw":"Rule\tArg\t1930\tonly\t-\tDec\t 1\t0:0Č1ĝČS\n"+
"ĀĂĄĆĈĊĚĎĐĒĄprĘĚĜĞěĒĤāăąćĉ3īďđēOctĈ5ěġĈŉģĥĺĨĽ2ĩ4ČēMaıęňĵŔĸĦĻĩ3őĽ9ĮNovĲŚğŋŝŎļ9œčŀĮJāũĴūĵŌĹħů4ĿĭēŵnņŪĶ-ŭŽŒƀŁ\tŃŅ1ŇŸŊźƉşĉ43ŲƁĄućřƓŜōƊƘƚĬƍƏƅƓĠƕƣƗŰ6ƛƍŖŘĳŉƢżƯ4ƱƧĮƩƠŉƬĢƖŏ96ƦųłńŷƷķƮǅǇƲĮĕėƑƆǂ\tŻŞǐ4ĩ6ƱŕŗǌśǎƹǜǞǠƎǋǖƫŬǏů67ǒēAİĘőơǥǛǰǲĉ68ƾǋSun>=ƶĵǘǚŮǞȀǾŤǴǶȃȅȇƆƸǻĩ7ǝƽƂaƄ2ƚǭƭǦůȚǳ\tŖđǀǤƈǯĩ8ȀȜĔĖǣŹǃȮĉ8ŤĉĊĮƴǙȄȆȈČȗȌȹȻ99őǊŅȓɂƒǁǮȤĩɉȧƩɎȕȢȷɓ2ĞČȲȿȡǍȭɜĞǲȲǔ\tċǗɒȘɝ0ȀɯȐȨǢɘǬɣǄćɯȱǉǪɍɁȇɐȉŬZĎe America/ĻentinʏBuʒos_Aires -3:5ʥ48ʣ LMTĈȺ4 Ə ľ\n"+
"\tʸ-4:16:ʩʣ\tCʮĩɝ ȩʷʹʻĵǴRʯĽ0 ǔˉĒˋČşAR%sˏǆ9ʳń  5˔ʤŉ˘˚˜ɔ˟ʴʵ˥˖Ɗ˙˛ʯɯˑƴˢ3˥ʥĵ˨˳\n"+
"ʅnʇʉʋʍʏʑʓʕʏCordobaʣʻʽʿʪ-ʬ˄1ʱˠtʵ1˯ʼʾˀē˃˝ˆˈʸ˕ŉˍ˝ċ˒Ė̠˼Ĩ˲˪ȏ̜ˢˤ̩˦̲ć̴˝91ˇŗ˸̱Ŕ\tW˙̿́ʴɝ˺˧̳˩̿ˬˡˮ̺˰˽˪˵͂r̺̈́˻˗͐˾̀̂ʊʌʎʐĆʒʔʖ/Salt̑ʺ:2Ġœʫʭˏ̛ʴʶ̡͖̕ˁ̥˅˶ayͅĮ͉Šˑ˓;̼Ą͑Ǟ͓̝ˣ͎Ύ̾ɔ́˷͕ˊ̫͇Ήȼ͋ˡ͍͞͏̽ΐȼΒ͝ΜΖΐ͚Κ˹Τά˳\tɻ̷̚Ε͉͆˿ʆʈͥ̅ͨgͪ̉/TucumȞ̒ʹĜ52͸̙ͻˡͽΜ̣̔˂̙Ɋ΄Ά΍ιˎΊ̯c·͘˝6ΩΔα͠ΦγΠ͛Ϊ̪ˌΞϟϭ͌0θ˱ΧɉϧΰΫϪΏγή̓ΛĒ͟Έϟɯʲƃˢ̟ϝĮ͈ЇĞЉȄęϼЄΥϿ˜λ́ν̄ͧ̇ͫʏLa_RiojͲʻ27ʹʲ̗͹ʰŰ̷ϔ̪ϖ̖Ϙ̦ϛ·̬ϠΌϽϸϬ˞̷ϨʹЅϤΘϮęлϲ͊͂yˢ7ϷчΨуЕͳβ͙ɞщіЅмЈ ЊъЍēЏ˴БѠГΣхЗΗεʴηϩІTКͤН̆ͩ̈ͬͮn_ŵϊͳ3ˋЮ̘ͺвͼЌϕ̢з΂ç̂΅ыΟĊ΋̰Ѝѓт˭̹ѫјэΚ҈ϰ͆ѥшȩѐђ̵͡ϺѕϣҦѦĞћϷўѧңдїҠΉџŵl 2ҙЖқδĞʪѯ8үΏѳͣМͦѷρѹʏŵjuяͳ͵ʼϏēа҆̚ϓҞͳж΁ϙҎϜпмːϡҪϫҧϦуҼ̻ϾΗȼ΄͜ 4ыҡӯ̷2ӃЍǘЏSҜ̓1ёѣьш˭6Ϸǘ˙ӽɔ2ҥӧ͒ҩҕҫҿҭίԍИҬӁˡѰҚϞӆμ̃ӉπςͬCaͱωrʎϋȠĝ̖҄бʲ̠҇ӝ̤ӟкԂґ̮оҟрӨϧӫцԒϭԕԂӵɉΡ̝ѪҽӭϹɉԐпчЁӱќΝҶѧѡӛ˰ѤՖ0ВnҺ϶ѱՑӀζӹԜѲѴӈοПσMʒ̎zЩ:35̡ϐ҅ԱӚԳҊӞйюҐϳҒӥԑԎΑӪԖӮɉӰˢӳՅґ9ˑѯӫ˰ӻԉӾӱՙΝՆ̀ζ֓ɑĵӼ̿ϏҝӴ֏ϏӂֈՍϻӦԗԓ֋ЃӬѲԓʲңȠ֥А՝ SepҺԆբԒѮԚզՋըƣѻLuisԓɱĞɳȿɘȀǹɤĦ׈׊׌ɯǲɻȁɿȔד֟ǃӇԠիѸРͭȞ_׉׋ԫյ2҃ӗϒ̝ҳ̓ռԵվ̨ӢӅнҔՐՂҗ͔ՀѬՍաէԈRԊӶ˷1֍׺֛֑Ԛ֞ʃ֖֠ҢЂ֙ϱ֛́՘ӄ֏֫Ӻŉ֮֡ҮѱҰֹҲؘҵָВҹһ֩ЀդJϊ͵·ח׋ϲذ0Ω1ӛѝӅթפОצσХo_GͯĂgʛϋ3ʾώշ԰г֙Դи΃տԸցԺ׽ԼҖөҘدҧՎ˭іׁ͗њՄէئ՞ЋַҬ٬Պֱգɰե؝ˎـξقӋקUshuaiղ3ʥ1ӕԯӘչ׳ٔ׶ٖҍԷ׺ԹғϢք̶֭٠׀օє٤֬ѭ٨ЂՔϱ՜ִ΅ʵ؅Լ՛ثѨ՟ٱՁօׂ̝ԛׅ̬\n"+
"LʕkժͧCuraʎoڹѷu̐ѴĄٹСУPaz̪šճ6ˁױ֐̠ێَսŠՈę֞ەېǘBO؉Ċ֣̓شԂ۟ʯƉBڽzilۘɖǋʵĈǘȊ۩ۭ۫ŠŢĊƚȑƵĘה۶ۋ۸Ő۰Ņ۲ ɚǙ܁۬ۮƘɈώǓȴř܈ס܊ƣ۪܂܍95ɟɽǵıʽĲɸܗ۷ܚ5Ěĉܐ۽ũܔȬ܋܃ܛǈƜȿܓ܀ܤܙǞܲƍɩ Ťܭȶܖżܘ܌ǞțɽܴĚܿƇܯܚ6ŇȲزƄľۿܕȋ\t݃ܰݎȧɡ݂݉ܶܥǞݏɽܼݝݕ݌ǨȍȾǢܵܣݟܸǾƱǾǲēŦŨݬؓɛĦݘܚ8ݢƜݵǷݔݸ݁ݺݠȹƼ݇Ǣǖ݊Ʌݗކ98ވƜƩһނ݀ݖݻȯɧɽFebĈǝތǺăޙȹޛޓǋޕ݊۵ܷ݄ȹɼƜޝޟ ǲޢוޤޏȰ܅ĈƱޫɭ޸ݯސŤݐȞδܾݞޅ߁Ⱥ޻ދ܉ޘޏ֐ȧ޲۳ޖ݋ޭܰߑȲޔݥރߏ߁̀ߒޞĈ޵߈߀ޮՇ޻ɝߕެݮߧɊߡ޳߇ݭ߉߮őߚީŇ޾ȣߴߘܺŴ߅ݓ޶ݧȼƚȼŇɌɀȔؼ߫޿ގߟǝࠆĮߓɶ߹ߥࠎ߮ޒƍߓࠋࠂߗܚǆ޻ ޽ߎࠃɉާࠚߢܡࠝ߭ߘࠧםĘࠣݦࠞɔްƳݫߜɄޣࠗߘ࠵࠯ࠜࠤ࠳Ψ߰δ࠸ߖࠬࠟ߃ɽƿƚߺݹߦ۸˵ࡃЫߕލޙࡑɯĚࠈגࠌ߻ࡏۮࡘԓǩࠓʀߍ߳࡞ԓ߶ɽހ܇ࡀࡇԓ߾ࠈĉ࡜ࡎ࠻࡟Бȧ࡫őࡍބࡧɯݾƨǫ࠱ߝݧɯ࠙ťŧĘࠕ࠲࡮ךࡒࢊܮ࠳ࢍ߷מȆȀࡻߞ݄לωx࠯ࠔɬ࡝ࡵ׍ҿࠋēࡣࠊʂ࠹޷ࢡɝچࡃɘ2Ǹࡦࢫ01ƚࢬǝࢥߢ࢞ࠖࡖࢴࡿࠒࢺʀࢰȖ࠺ࢽܡɝࣃࢹޟࢻࢲࢽȠࢮࣂࢱ࢐ࢌ0ׯҿޕ࣊ࠉɏࣄࢪ࣎ࢆࣙࢯ࣒ࢩࢄࣕכ0ڄࣀ࣋ࡤࢨࡆ߼ࡶҁ࣐Ȕࣃࢼݠɝմҿَࣩࣚʁࣜࣤ3࠮࣑࣠ࣽ࢑ࣧȀ࢛ࣺ࣌ܮףۇ/ŦrĎhaĒ2ĝ9ʿˑӖϙ،˥औĵޙFNс֐ֺּęԁʹझ͆ठԏֻֽċजŉटडљҭ֒रϱफԓ́भДषČलع֧͔ӛऩࠒNԞЛفʗeĂmЖࢵʦېङ˝छѱޙBϹȰतֽچӄक़ैѵԡѻͱʠॎ˦38΀॓ĩॕпޙAMсग़़ढ़Ը˄εЊׯˢŸफ़ٷऋѶ/F̌ͱĂձओճ˖ۑच؍ׅॗ؄ज़दॽबथयॖݠक़عؐՉԌإݗָऻथࢵϷ঎ुуؽΝय़ٸঀRĖifă-औĉۏঊ॔ঌֱত٢ˑॴधڳঞওमڧসগέњशঝय़ऺঐঢখܸঘऴूΓধϱ঩ॿԡąagڀ̉ॏऔϗӗ̀ষЅহ̿঻ডঽֱē৉ࠆোৢऱৄع3ঐׯ঒ࢣ৑Һ৓िৰљࢵज़঒পԡŖceЦইࢰʦӕ\tৠ७঍৻৥ো২ؾ৫ɉ5ζڡ৺ৎՍې़Ӳ৵є़কէ৤أ͌জ٪ি৊ॴਗࢡ৏Ҭ৷Ѣਧ৕ԟऌBahڂইҁĝЮਊঋণ਎࡯৳৮৔Аؼζֿਢੀࢬ৷ۥ਱ॾਲ਼ঀͮنۊāoҽʾӸ঵६੃ਘ݄ਭܹӷ৲ܿԇऱ؈ϥੜਬ͑਀οԥmpنGڽndʇ१३ਖ਼५ĉ਌Ҵࢡ॰͢੐ԡڻڂ̐Ж4Ъघ਽শ·९ॱऴ৲़৴ॶٯদઋݠ੾Й৖οPঃنVौhۀӜյۖ੹ৡકܸગ˝ॳডਦڨĄʮ੫ͧBoУV׋ͱϰ৞ઈ਋ষ˰ઌॲʪॴભ੼ǴϙՎਠূાખઍҬচۚҐરઙͧŖʖu׌Ҵ਻ਗ਼੺ઽ৯નૌȯુબૐ̿એथӸધ݄઩ɔʲઐૃ՚યॠہ/EʟȄּরʻ3ख੸ઉਜ਼˥յञખCીোૃ଀ιC૤৳ׄ-ଇ੽ଃ٢૬૦ଆՕଉ׍ګҺʲ੣઒ࢣ৲ݵęূ଎Ǵଉ઱ʏم_ܘnc੖ҀĠچ૚દ̺଎९ଐપૡड़ଔڢଖॸѩଚॼଜࢬଞŧଠ૿କѳƣC਷ĦҍǽĪĮभȵƔࡴ୉ۭăҍȎۢΈǶȫࣣୈ୊ୖǆ࠽ݴ࢈۲˖u୒ࡼ˂ୟΑݛǢɫ͟୧ލ୔ୋ˞ࡸ࢈࣏୦୨ݖ୳ୠ7ܝܳǢ2Ť୰࣭ă୼șƌݪܠǝ஄୲୫ĉ୾șɋɾࣻŤ୹߬Ħஇஐۺޑஊகɪġୱ࠺ச97ࡰǙּɪČ஗ࠍதȦަ࢝ʀ஖஡୺Ɖத8ऀįܠő஍ணஏސ୘ߑǡıɘஃழஎ୕ૠȯɳɗல\t஬ࢠதߙɽ୐ܡௐ୓ிߠȼǩב௎஽ࢪ௒ܨࠦறȔளĞ୧஘ஆ௙ஹɡČ௟ஶ௙ୢɴ௄௞ோ௉ȼ௲୐ࡓௗ୩௒ࡉƜܟĘ஌௶௠௙Ťࢬ்͆௥௏ழ௩୪௉ࡗɦஞ௅஠௧அఐĦלɠ୮௮అ௰఑׏୭௴ఌ௯୞డ1୿ƍంɶఖ0஢ఆనஉǡđࢯమరఠచࢴళƝćɶƱ௽୻୫ੋࢣࠇ஺࣏ࣻదżஇౄࢷ୏னశుଥר̈৙ବʻ4৞॒૽ӘૉʿౚˁSचˑݑୄଲΝCL॔ېҸ٭;ౙʿ౛ౢ॔ଷ౦׺౩॔˟౭ਰ̪౰ƻౡӟ7ঐ౼଍ŉஇ౩сšಃةĮ౸ŒϏ؜౧ϱಎƘϏAƞ౮౷౪Œ౬ā૏ؠĵ౩ۡ౿ਜಌ̤ಛƘಂܟಙĒଢ˂ನŰಂֵ́ԬĞ·ಇLذƑʈİ־˸஡ӄ౸թۊcমʍ૳astʋĒЬԀʹзےূ೎ЬૼEϙಊभ˥Ьಡ୫EASॲۣ͜،ʵೀ̺ʾೝ௉೟ೡৼਕಫ2ې୰୅ϱ೬૱AʓŗńચͯͥƇ\tzഁݡڝϹٟ؁١પۣӡԼಸ಺೯ಽೱ೦௧ು౪ஶOԋ୭ȪɢࢃୈഗࠄȧంӲࣽͣۆঀળًસͳ5ʾʽ૚Ȱڤ೤٥॑ն৪ঋ ଟֶಒČCഗ഼γۅॊ/ڻڽڿۍյ4ಂથଯ޲ę૮ճιेഃԸӽڵڷഥઁڼھa੖ുLowʋ_Pʌପʡ\tൕnkൗ੬൙൅ുKڽĂੳij൪౓Gڀyaq׊ۮಅ঳ˆ੹ȺଡʼউēQ೘ӛಮEଖೃھೆc/وlapౖ૗յ5੷਼ৠҳඋଖއ˥೩͆GAಛƉFͯ൪Ľ୍२౏p\tඔೊȓ࢟ࡴඩlණĊ୘ౙఔࡤŤࠖභඹૺߌඵ୩ශŒğŰஓ୐඲tප࡭Ħ෇ƥȧݑĈःżිސ஧෌೉෎Ȅළݖෙ8ࠐސెం෍ාࢲ෢݆Ɯ௕Ʊැă෢Ňࡑē୐క෰\t෢Ʊ෴ేి෗ෑඪऺࢣιȒ࣫δ෪กࡠఉදࣻĚॅ۵ףtඔ̈එSͱďeŁʥܧЭമۓΤผॺ෵चೣ്·෇FKॲ৲׹ׅศสҧݽোؒČฯ಺০ֽˣˢऩӄษൔ૒̊΅ʒ́Жஂόର੆ҸыGFϥಂƏӄ์ॠ൫ͧ൸ൺʖЖώग่ਕƴ͎4ెGBGϥېֵੈઅ๡Y˝7ਕ౭ҳؾG๫Θ๋๫ƉۊڽșŇޯ࠯ଡ଼வƣ๸ऒஐ๻஥Ȁ௃୑ލກșɈߠܫ๾ຉŗຂ߂ߩ࣢๿żຊӯࠡɃຖĦຘߨ࢓࠰෠๷ຑഘజ۾ࠖພ߯ຠˣຢ຀຤ട຦ɪປຐ๹ടࠑࠈ๾ఏຩ෤ܛࣺ෨ෟຨຯɉࣟ௳ຈ࠺ຩ෻Ğ࡙ஔభ෸ຩஹߓ຿Ƅແີɉ׎ࢴලࠊ෿ăຊɯőЈ୚తɂ໛\tໝĞໟĞۼநධໍࢋຝ຤໠ɲ௤ࣛ໎໰Ğෳఢງ࡛໔ऒซइ࡚ࡤອທ໶఩৶໡ࣻנ࣓໯๹ୁ\t໿໅࣡ണ઀իsȄ೅Ď๙Ĝͷංฟѫܜ๛ૅ̭ۙ఩ыP๳஛̜ӄ༦๬ʲܟ·ຊ༦˾຀ʋ௨යු߅ູࠍP༴Š௲ഡຳ໇༼Ľ୘ස෵ன໒༂ຝགĊɈű໺ࣂǝຨཋ஝ரȝƄ༹ࢠ༻r༵པސݳేຏཁཛɔప߿བྷປ຺ཋ௓ఁ୛ཀࢪཚ༵Ű༷ཧཉໜཪ෬ఫ཭༒ไ൝iωಭԭӔพ඄ɰ঴થٴ౭૧ഺ໥༼PEിฑณʔตouthهěgڂʣऔೱԭྃाĮGԊ౓ກԨibବʨ༚઻चধœਈˁP೘؂ྲત໥ϙ๠༩ΤɫݴE๤๺ഷୃڭ൏୏ց෣྽ਧS੏ॉऌછrt_of_Sඖʕϋ0೩ගฤϮൎڢൔڶ൩૲࿑࿓࿕࿗࿙՟ു೸৚ۭඔ൨ڸു࿧࿔࿖࿘ځ࿬ऌ೸ʔ৚a࿲࿦ঃ࿶࿪࿹૲Domʕ̅က࿴ဂ࿩࿸࿚ുੱʒad࿿࿤࿳࿐ဎ࿷࿫૲൸ပौྕpeဌယ࿒ဃတ࿺ঀƴiന൧ဘခဧဏဝുMĎtsʋڽtဥঀ࿵ဳစുถନŗྗौemΆူဍဲလ၁ऌ၃Kitးုڷေ࿨၎ထၐ࿓׉೅ဗၗ၌ၙငၛੑ࿓Tઠω׌ွԡဿၚဪॢ࿓શ൥ʓၬચရၤၰοTજඔ൧ƣUཛ࿾đҍ஧ƿࡺơ࿇Hݖႁƞ൹˅෤ೱ༇ݷଢ଼żႍႃ႐˅ెƿࡅĜɫႋƉ႗ႏĽࠅĊႛǋ཈ތႊႌႂႣĊ෤ࣹ໺ԦȆޕԬċ׌ލႢ΅Šໄ࡫ႝႫႡႭႻඬƋஞႩࠖႺႄĊ୍ཎஔჇƷჀႀჂ჊ſഠƞܬႉ႟ႬႎჃ්ཱིიࢲ჉ಏȧɩ،ࡳ୩ტීັღࠫĦჩܛఀ࠶đࣖࢗჁნ჊5ჱࢇŨࡥ༊ăჯ6ཥབߣყმ႘Ǿᄂ໅ࠢࡔ࠺ᄀຄǱ༇భჵგჷݡȧ௻ࢂ႕ხდݨݲ࠯ࠁ჈ᄜǾ୘஑ఴδߤალჶᄇୡșܼ͆ႈსᄢ஥ࡩཬıჴ෸ჯ7ᄵఫთჽᄚჿᄳȦძČႪᄪᄔᄬᅃݣȴࣃᄓ႖ᅂໄႜᄌࢪᄺஹܼޡᄹᅂ༾ེჭᅁᄕஐჺຸࡅఏჯ8ᄉȩრჾ\tᅥᅖȴწᅙᅟீణޠᅓᄫႮ޺ɨᅮᅣࠍᅥᅡ໅ࢭᅝᅫᄳߋຠஂᄅᅶოߑȼஓ௝໚ᆁჯᆊߨༀࣲᅻࢠᆐᄼ࠾࢖ᅰᄬȽȲߓӸᅵᅈႏ໠Ȳ௕߲ജᅏᄕࡾᅳࡓҺᄲᆪ໷ܾࠡฏᅼᄜࢅᅳᆀॅႹᆶĞƱ༏ఋ໣ᆮᆨᄛᆰ0ǲ༏ᆍ࢕Ƿɸเ/ံʓeviੴྫྷʿౘ࿞҅ʪॹଌʨᇗˁMԶюಬ१ČტUYсౙϡę੨ᇦᇨઘʆ๔แൄ೉̪Ыᇖྡྷ;ᇷ༛ڎ̀ϏൌॵΜ྿\tVEϥิĮህҬಂǔˢ˟ഒ౞ሃሊ"}

});

require.define("/package.json",function(require,module,exports,__dirname,__filename,process,global){module.exports = {"main":"./lumenize"}
});

require.define("/lumenize.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3

/*

 * Lumenize #

Lumenize provides tools for aggregating data and creating time series and other temporal visualizations.

The primary time-series aggregating functionality is provided by:
  * Lumenize.TimeSeriesCalculator - Sets of single-metric series or group-by series
  * Lumenize.TransitionsCalculator - Counts or sums for items moving from one state to another
  * Lumenize.TimeInStateCalculator - Cumulative amount of time unique work items spend in a particular state

Simple group-by, 2D pivot-table and even multi-dimensional aggregations (OLAP cube) are provided by:
  * Lumenize.OLAPCube - Used by above three Calculators but also useful stand-alone, particularly for hierarchical roll-ups

All of the above use the mathematical and statistical functions provided by:
  * Lumenize.functions - count, sum, standardDeviation, percentile coverage, min, max, etc.

Three transformation functions are provided:
  * Lumenize.arrayOfMaps_To_CSVStyleArray - Used to transform from record to table format
  * Lumenize.csvStyleArray_To_ArrayOfMaps - Used to transform from table to record format
  * Lumenize.arrayOfMaps_To_HighChartsSeries - Used to transform from record format to the format expected by the HighCharts charting library

And last, additional functionality is provided by:
  * Lumenize.histogram - create a histogram of scatter data
  * Lumenize.utils - utility methods used by the rest of Lumenize (type, clone, array/object functions, etc.)
 */

(function() {
  var datatransform, tzTime;

  tzTime = require('tztime');

  exports.Time = tzTime.Time;

  exports.TimelineIterator = tzTime.TimelineIterator;

  exports.Timeline = tzTime.Timeline;

  exports.utils = tzTime.utils;

  exports.TimeInStateCalculator = require('./src/TimeInStateCalculator').TimeInStateCalculator;

  exports.TransitionsCalculator = require('./src/TransitionsCalculator').TransitionsCalculator;

  exports.TimeSeriesCalculator = require('./src/TimeSeriesCalculator').TimeSeriesCalculator;

  datatransform = require('./src/dataTransform');

  exports.arrayOfMaps_To_CSVStyleArray = datatransform.arrayOfMaps_To_CSVStyleArray;

  exports.csvStyleArray_To_ArrayOfMaps = datatransform.csvStyleArray_To_ArrayOfMaps;

  exports.arrayOfMaps_To_HighChartsSeries = datatransform.arrayOfMaps_To_HighChartsSeries;

  exports.csvString_To_CSVStyleArray = datatransform.csvString_To_CSVStyleArray;

  exports.csvStyleArray_To_CSVString = datatransform.csvStyleArray_To_CSVString;

  exports.functions = require('./src/functions').functions;

  exports.histogram = require('./src/histogram').histogram;

  exports.multiRegression = require('./src/multiRegression').multiRegression;

  exports.table = require('./src/table').table;

  exports.OLAPCube = require('./src/OLAPCube').OLAPCube;

  exports.anova = require('./src/anova').anova;

  exports.distributions = require('./src/distributions').distributions;

  exports.BayesianClassifier = require('./src/Classifier').BayesianClassifier;

  exports.Classifier = require('./src/Classifier').Classifier;

  exports.Store = require('./src/Store').Store;

  exports.RandomPicker = require('./src/RandomPicker').RandomPicker;

}).call(this);

//# sourceMappingURL=lumenize.js.map

});

require.define("/node_modules/tztime/package.json",function(require,module,exports,__dirname,__filename,process,global){module.exports = {"main":"./tzTime"}
});

require.define("/node_modules/tztime/tzTime.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3

/*
 * tzTime #

_Timezone transformations in the browser and node.js plus timezone precise timeline creation for charting._

## Features ##

* Transform into and out of any timezone using Olson timezone rules
* Timezone rule files embedded in the minified browser package. No need to host them
  seperately.
* Create timezone precise time-series axis for charts

  * Knockout weekends, holidays, non-workhours
  * Work with timezone precision
  * Work in any granularity

    * Year, quarter, week, day, hour, etc.
    * No more recording `2012-03-05T00:00:00.000Z` when you really just mean `2012-03-05`
    * Create and use custom granularities: `R02I04-07` = Seventh day of fourth iteration in
      second release

* Work in a particular granularity like day, week, month, or quarter and not worry about the fiddly bits of finer
  granularity. JavaScript's Date object forces you to think about the fact that the underlying representation is milliseconds
  from the unix epoch.
* Month is 1-indexed (rather than 0-indexed like Javascript's Date object)
* Date/Time math (add 3 months, subtract 2 weeks, etc.)
* Work with ISO-8601 formatted strings (called 'ISOString' in this library)

   * Added: Quarter form (e.g. 2012Q3 equates to 2012-07-01)
   * Not supported: Ordinal form (e.g. 2012-001 for 2012-01-01, 2011-365 for 2012-12-31) not supported

## Granularity ##

Each Time object has a granularity. This means that you never have to
worry about any bits lower than your specified granularity. A day has only
year, month, and day segments. You are never tempted to specify 11:59pm
to specify the end of a day-long timebox.

Time supports the following granularities:

* `year`
    * `month`
        * `day`
            * `hour`
               * `minute`
                   * `second`
                       * `millisecond`
    * `quarter` (but not quarter_month, day, etc.)
    * `week` (ISO-8601 style week numbering)
       * `week_day` (Monday = 1, Sunday = 7)

Also, you can define your own custom hierarchical granularities, for example...

* `release`
   * `iteration`
      * `iteration_day`

## Timezone precision ##

It's very hard to do filtering and grouping of time-series data with timezone precision.

For instance, 11pm in California on December 25 (Christmas holiday) is 2am December 26 (not a holiday)
in New York. This also happens to be 7am December 26 GMT. If you have an event that occurs at
2011-12-26T07:00:00.000Z, then you need to decide what timezone to use as your context before you
decide if that event occured on Christmas day or not. It's not just holidays where this can burn you.
Deciding if a piece of work finished in one time range versus another can make a difference for
you metrics. The time range metrics for a distributed team should look the same regardless
of whether those metrics were generated in New York versus Los Angeles... versus Bangalore.

The javascript Date object lets you work in either the local time or Zulu (GMT/UTC) time but it doesn't let you
control the timezone. Do you know the correct way to apply the timezone shift to a JavaScript Date Object?
Do you know when Daylight Savings Time kicks in and New York is 4 hours shifted from GMT instead of 5? Will
you remember to do it perfectly every time it's needed in your code?

If you need this precision, Time helps by clearly delineating the moment when you need to do
timezone manipulation... the moment you need to compare/query timestamped data. You can do all of your
holiday/weekend knockout manipulation without regard to timezone and only consider the timezone
upon query submission or comparison.

## Month is 1-indexed as you would expect ##

Javascript's date object uses 0 for January and 11 for December. Time uses 1 for January and 12 for December...
which is what ISO-8601 uses and what humans expect. Everyone who works with the javascript Date Object at one
point or another gets burned by this.

## Week support ##

Time has ISO-8601 week support. Implications of using this ISO format (paraphrased info from wikipedia):

* All weeks have 7 days (i.e. there are no fractional weeks).
* Any given day falls into a single week which means that incrementing across the year boundary in week
  granularity is without gaps or repeats.
* Weeks are contained within a single year. (i.e. weeks are never spit over two years).
* The above two implications also mean that we have to warp the boundaries of the year to accomplish this. In week
  granularity dates may appear in a different year than you would expect and some years have 53 weeks.
* The date directly tells the weekday.
* All years start with a Monday and end with a Sunday.
* Dates represented as yyyyWww-d can be sorted as strings.

**In general, it just greatly simplifies the use of week granularity in a chart situation.**

The ISO-8601 standard is an elegant and well thought out approach to dealing with week granularity. The only real
downside to this approach is that USA folks expect the week to start on Sunday. However, the ISO-8601 spec starts
each week on Monday. Following ISO-8601, Time uses 1 for Monday and 7 for Sunday which aligns with
the US standard for every day except Sunday. The US standard is to use 0 for Sunday. This library says, "tough luck"
to folks who are unhappy that the week starts on Monday. Live with the fact that weeks in this library start on Monday
as they do in the ISO-8601 standard, or roll your own library. :-)
 */

(function() {
  var Timeline;

  exports.Time = require('./src/Time').Time;

  Timeline = require('./src/Timeline');

  exports.TimelineIterator = Timeline.TimelineIterator;

  exports.Timeline = Timeline.Timeline;

  exports.utils = require('./src/utils');

}).call(this);

});

require.define("/node_modules/tztime/src/Time.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3
(function() {
  var Time, timezoneJS, utils,
    indexOf = [].indexOf || function(item) { for (var i = 0, l = this.length; i < l; i++) { if (i in this && this[i] === item) return i; } return -1; };

  utils = require('./utils');

  timezoneJS = require('../lib/timezone-js.js').timezoneJS;

  Time = (function() {

    /*
    @class Time
    
    ## Basic usage ##
    
        {TimelineIterator, Timeline, Time} = require('../')
    
    Get Time objects from partial ISOStrings. The granularity is automatically inferred from how many segments you provide.
    
        d1 = new Time('2011-02-28')
        console.log(d1.toString())
         * 2011-02-28
    
    Spell it all out with a JavaScript object
    
        d2 = new Time({granularity: Time.DAY, year: 2011, month: 3, day: 1})
        console.log(d2.toString())
         * 2011-03-01
        
    Increment/decrement and compare Times without regard to timezone
    
        console.log(d1.greaterThanOrEqual(d2))
         * false
    
        d1.increment()
        console.log(d1.equal(d2))
         * true
    
    Do math on them.
        
        d3 = d1.add(5)
        console.log(d3.toString())
         * 2011-03-06
    
    Get the day of the week.
    
        console.log(d3.dowString())
         * Sunday
        
    Subtraction is just addition with negative numbers.
    
        d3.addInPlace(-6)
        console.log(d3.toString())
         * 2011-02-28
    
    If you start on the last day of a month, adding a month takes you to the last day of the next month, 
    even if the number of days are different.
        
        d3.addInPlace(1, 'month')  
        console.log(d3.toString())
         * 2011-03-31
        
    Deals well with year-granularity math and leap year complexity.
    
        d4 = new Time('2004-02-29')  # leap day
        d4.addInPlace(1, 'year')  # adding a year takes us to a non-leap year
        console.log(d4.toString())
         * 2005-02-28
        
    Week granularity correctly wraps and deals with 53-week years.
    
        w1 = new Time('2004W53-6')
        console.log(w1.inGranularity(Time.DAY).toString())
         * 2005-01-01
        
    Convert between any of the standard granularities. Also converts custom granularities (not shown) to
    standard granularities if you provide a `rataDieNumber()` function with your custom granularities.
    
        d5 = new Time('2005-01-01')  # goes the other direction also
        console.log(d5.inGranularity('week_day').toString())
         * 2004W53-6
        
        q1 = new Time('2011Q3')
        console.log(q1.inGranularity(Time.MILLISECOND).toString())
         * 2011-07-01T00:00:00.000
        
    ## Timezones ##
    
    Time does timezone sensitive conversions.
    
        console.log(new Time('2011-01-01').getJSDate('America/Denver').toISOString())
         * 2011-01-01T07:00:00.000Z
     */
    var g, ref, spec;

    function Time(value, granularity, tz) {

      /*
      @constructor
      @param {Object/Number/Date/String} value
      @param {String} [granularity]
      @param {String} [tz]
      
      The constructor for Time supports the passing in of a String, a rata die number (RDN), or a config Object
      
      ## String ##
      
      There are two kinds of strings that can be passed into the constructor:
      
      1. Human strings relative to now (e.g. "this day", "previous month", "next quarter", "this millisecond in Pacific/Fiji", etc.)
      2. ISO-8601 or custom masked (e.g. "I03D10" - 10th day of 3rd iteration)
      
      ## Human strings relative to now ##
      
      The string must be in the form `(this, previous, next) |granularity| [in |timezone|]`
      
      Examples
      
      * `this day` today
      * `next month` next month
      * `this day in Pacific/Fiji` the day that it currently is in Fiji
      * `previous hour in America/New_York` the hour before the current hour in New York
      * `next quarter` next quarter
      * `previous week` last week
      
      ## ISO-8601 or custom masked ##
      
      When you pass in an ISO-8601 or custom mask string, Time uses the masks that are defined for each granularity to figure out the granularity...
      unless you explicitly provide a granularity. This parser works on all valid ISO-8601 forms except orginal dates (e.g. `"2012-288"`)
      It even supports week number form (`"2009W52-7"`) and we've added a form for Quarter granularity (e.g. `"2009Q4"`).
      The canonical form (`"2009-01-01T12:34:56.789"`) will work as will any shortened subset of it (`"2009-01-01"`,
      `"2009-01-01T12:34"`, etc.). Plus it will even parse strings in whatever custom granularity you provide based
      upon the mask that you provide for that granularity.
      
      If the granularity is specified but not all of the segments are provided, Time will fill in the missing value
      with the `lowest` value from _granularitySpecs.
      
      The ISO forms that omit the delimiters or use spaces as the delimeters are not supported. Also unsupported are strings
      with a time shift indicator on the end (`...+05:00`). However, if you pass in a string with a "Z" at the end, Time
      will assume that you want to convert from GMT to local (abstract) time and you must provide a timezone.
      
      There are two special Strings that are recognized: `BEFORE_FIRST` and `PAST_LAST`. You must provide a granularity if you
      are instantiating a Time with these values. They are primarily used for custom granularities where your users
      may mistakenly request charts for iterations and releases that have not yet been defined. They are particularly useful when 
      you want to iterate to the last defined iteration/release.
      
      ## Rata Die Number ##
      
      The **rata die number (RDN)** for a date is the number of days since 0001-01-01. You will probably never work
      directly with this number but it's what Time uses to convert between granularities. When you are instantiating
      a Time from an RDN, you must provide a granularity. Using RDN will work even for the granularities finer than day.
      Time will populate the finer grained segments (hour, minute, etc.) with the approriate `lowest` value.
      
      ## Date ##
      
      You can also pass in a JavaScript Date() Object. The passing in of a tz with this option doesn't make sense. You'll end
      up with the same Time value no matter what because the JS Date() already sorta has a timezone. I'm not sure if this
      option is even really useful. In most cases, you are probably better off using Time.getISOStringFromJSDate()
      
      ## Object ##
      
      You can also explicitly spell out the segments in a specification Object in the form of
      `{granularity: Time.DAY, year: 2009, month: 1, day: 1}`. If the granularity is specified but not all of the segments are
      provided, Time will fill in the missing value with the appropriate `lowest` value from _granularitySpecs.
      
      ## granularity ##
      
      If you provide a granularity it will take precedence over whatever fields you've provided in your config or whatever segments
      you have provided in your string. Time will leave off extra values and fill in missing ones with the appropriate `lowest`
      value.
      
      ## tz ##
      
      Most of the time, Time assumes that any dates you pass in are timezone less. You'll specify Christmas as 12-25, then you'll
      shift the boundaries of Christmas for a specific timezone for boundary comparison.
      
      However, if you provide a tz parameter to this constructor, Time will assume you are passing in a true GMT date/time and shift into
      the provided timezone. So...
      
          d = new Time('2011-01-01T02:00:00:00.000Z', Time.DAY, 'America/New_York')
          console.log(d.toString())
           * 2010-12-31
          
      Rule of thumb on when you want to use timezones:
      
      1. If you have true GMT date/times and you want to create a Time, provide the timezone to this constructor.
      2. If you have abstract days like Christmas or June 10th and you want to delay the timezone consideration, don't provide a timezone to this constructor.
      3. In either case, if the dates you want to compare to are in GMT, but you've got Times or Timelines, you'll have to provide a timezone on
         the way back out of Time/Timeline
       */
      var config, jsDate, k, len, newCT, newConfig, rdn, ref, ref1, ref2, ref3, s, segment;
      this.beforePastFlag = '';
      switch (utils.type(value)) {
        case 'string':
          s = value;
          if ((s.slice(-3, -2) === ':' && (ref = s.slice(-6, -5), indexOf.call('+-', ref) >= 0)) || s.slice(-1) === 'Z') {
            if (tz != null) {
              if (s.slice(-3, -2) === ':' && (ref1 = s.slice(-6, -5), indexOf.call('+-', ref1) >= 0)) {
                throw new Error("tzTime.Time does not know how to deal with time shifted ISOStrings like what you sent: " + s);
              }
              if (s.slice(-1) === 'Z') {
                s = s.slice(0, -1);
              }
              newCT = new Time(s, 'millisecond');
              jsDate = newCT.getJSDateFromGMTInTZ(tz);
            } else {
              throw new Error("Must provide a tz parameter when instantiating a Time object with ISOString that contains timeshift/timezone specification. You provided: " + s + ".");
            }
          } else {
            this._setFromString(s, granularity);
            tz = void 0;
          }
          break;
        case 'number':
          rdn = value;
          if (tz != null) {
            newCT = new Time(rdn, 'millisecond');
            jsDate = newCT.getJSDateFromGMTInTZ(tz);
          } else {
            this._setFromRDN(rdn, granularity);
          }
          break;
        case 'date':
          jsDate = value;
          if (tz != null) {
            newCT = new Time(jsDate, 'millisecond');
            jsDate = newCT.getJSDateFromGMTInTZ(tz);
          }
          if (tz == null) {
            tz = 'GMT';
          }
          break;
        case 'object':
          config = {};
          config.granularity = value.granularity;
          config.beforePastFlag = value.beforePastFlag;
          ref2 = Time._granularitySpecs[value.granularity].segments;
          for (k = 0, len = ref2.length; k < len; k++) {
            segment = ref2[k];
            config[segment] = value[segment];
          }
          if (tz != null) {
            config.granularity = 'millisecond';
            newCT = new Time(config);
            jsDate = newCT.getJSDateFromGMTInTZ(tz);
          } else {
            this._setFromConfig(config);
          }
      }
      if (tz != null) {
        if ((ref3 = this.beforePastFlag) === 'BEFORE_FIRST' || ref3 === 'PAST_LAST') {
          throw new Error("Cannot do timezone manipulation on " + this.beforePastFlag);
        }
        if (granularity != null) {
          this.granularity = granularity;
        }
        if (this.granularity == null) {
          this.granularity = 'millisecond';
        }
        newConfig = {
          year: jsDate.getUTCFullYear(),
          month: jsDate.getUTCMonth() + 1,
          day: jsDate.getUTCDate(),
          hour: jsDate.getUTCHours(),
          minute: jsDate.getUTCMinutes(),
          second: jsDate.getUTCSeconds(),
          millisecond: jsDate.getUTCMilliseconds(),
          granularity: 'millisecond'
        };
        newCT = new Time(newConfig).inGranularity(this.granularity);
        this._setFromConfig(newCT);
      }
      this._inBoundsCheck();
      this._overUnderFlow();
    }


    /*
    `_granularitySpecs` is a static object that is used to tell Time what to do with particular granularties. You can think of
    each entry in it as a sort of sub-class of Time. In that sense Time is really a factory generating Time objects
    of type granularity. When custom timebox granularities are added to Time by `Time.addGranularity()`, it adds to this
    `_granularitySpecs` object.
     */

    Time._granularitySpecs = {};

    Time._granularitySpecs['millisecond'] = {
      segments: ['year', 'month', 'day', 'hour', 'minute', 'second', 'millisecond'],
      mask: '####-##-##T##:##:##.###',
      lowest: 0,
      rolloverValue: function() {
        return 1000;
      }
    };

    Time._granularitySpecs['second'] = {
      segments: ['year', 'month', 'day', 'hour', 'minute', 'second'],
      mask: '####-##-##T##:##:##',
      lowest: 0,
      rolloverValue: function() {
        return 60;
      }
    };

    Time._granularitySpecs['minute'] = {
      segments: ['year', 'month', 'day', 'hour', 'minute'],
      mask: '####-##-##T##:##',
      lowest: 0,
      rolloverValue: function() {
        return 60;
      }
    };

    Time._granularitySpecs['hour'] = {
      segments: ['year', 'month', 'day', 'hour'],
      mask: '####-##-##T##',
      lowest: 0,
      rolloverValue: function() {
        return 24;
      }
    };

    Time._granularitySpecs['day'] = {
      segments: ['year', 'month', 'day'],
      mask: '####-##-##',
      lowest: 1,
      rolloverValue: function(ct) {
        return ct.daysInMonth() + 1;
      }
    };

    Time._granularitySpecs['month'] = {
      segments: ['year', 'month'],
      mask: '####-##',
      lowest: 1,
      rolloverValue: function() {
        return 12 + 1;
      }
    };

    Time._granularitySpecs['year'] = {
      segments: ['year'],
      mask: '####',
      lowest: 1,
      rolloverValue: function() {
        return 9999 + 1;
      }
    };

    Time._granularitySpecs['week'] = {
      segments: ['year', 'week'],
      mask: '####W##',
      lowest: 1,
      rolloverValue: function(ct) {
        if (ct.is53WeekYear()) {
          return 53 + 1;
        } else {
          return 52 + 1;
        }
      }
    };

    Time._granularitySpecs['week_day'] = {
      segments: ['year', 'week', 'week_day'],
      mask: '####W##-#',
      lowest: 1,
      rolloverValue: function(ct) {
        return 7 + 1;
      }
    };

    Time._granularitySpecs['quarter'] = {
      segments: ['year', 'quarter'],
      mask: '####Q#',
      lowest: 1,
      rolloverValue: function() {
        return 4 + 1;
      }
    };

    Time._expandMask = function(granularitySpec) {
      var character, i, mask, segmentEnd;
      mask = granularitySpec.mask;
      if (mask != null) {
        if (mask.indexOf('#') >= 0) {
          i = mask.length - 1;
          while (mask.charAt(i) !== '#') {
            i--;
          }
          segmentEnd = i;
          while (mask.charAt(i) === '#') {
            i--;
          }
          granularitySpec.segmentStart = i + 1;
          granularitySpec.segmentLength = segmentEnd - i;
          return granularitySpec.regex = new RegExp(((function() {
            var k, len, ref, results;
            ref = mask.split('');
            results = [];
            for (k = 0, len = ref.length; k < len; k++) {
              character = ref[k];
              results.push(character === '#' ? '\\d' : character);
            }
            return results;
          })()).join(''));
        } else {
          return granularitySpec.regex = new RegExp(mask);
        }
      }
    };

    ref = Time._granularitySpecs;
    for (g in ref) {
      spec = ref[g];
      Time._expandMask(spec);
      Time[g.toUpperCase()] = g;
    }

    timezoneJS.timezone.zoneFileBasePath = '../files/tz';

    timezoneJS.timezone.init();

    Time.prototype._inBoundsCheck = function() {
      var gs, k, len, lowest, results, rolloverValue, segment, segments, temp;
      if (this.beforePastFlag === '' || (this.beforePastFlag == null)) {
        if (!this.granularity) {
          throw new Error('@granularity should be set before _inBoundsCheck is ever called.');
        }
        segments = Time._granularitySpecs[this.granularity].segments;
        results = [];
        for (k = 0, len = segments.length; k < len; k++) {
          segment = segments[k];
          gs = Time._granularitySpecs[segment];
          temp = this[segment];
          lowest = gs.lowest;
          rolloverValue = gs.rolloverValue(this);
          if (temp < lowest || temp >= rolloverValue) {
            if (temp === lowest - 1) {
              this[segment]++;
              results.push(this.decrement(segment));
            } else if (temp === rolloverValue) {
              this[segment]--;
              results.push(this.increment(segment));
            } else {
              throw new Error("Tried to set " + segment + " to " + temp + ". It must be >= " + lowest + " and < " + rolloverValue);
            }
          } else {
            results.push(void 0);
          }
        }
        return results;
      }
    };

    Time.prototype._setFromConfig = function(config) {
      var k, len, results, segment, segments;
      utils.assert(config.granularity != null, 'A granularity property must be part of the supplied config.');
      this.granularity = config.granularity;
      this.beforePastFlag = config.beforePastFlag != null ? config.beforePastFlag : '';
      segments = Time._granularitySpecs[this.granularity].segments;
      results = [];
      for (k = 0, len = segments.length; k < len; k++) {
        segment = segments[k];
        if (config[segment] != null) {
          results.push(this[segment] = config[segment]);
        } else {
          results.push(this[segment] = Time._granularitySpecs[segment].lowest);
        }
      }
      return results;
    };

    Time.prototype._setFromString = function(s, granularity) {
      var gs, k, l, len, ref1, ref2, results, sSplit, segment, segments, stillParsing, sub, tz, zuluCT;
      if (s === 'PAST_LAST' || s === 'BEFORE_FIRST') {
        if (granularity != null) {
          this.granularity = granularity;
          this.beforePastFlag = s;
          return;
        } else {
          throw new Error('PAST_LAST/BEFORE_FIRST must have a granularity');
        }
      }
      sSplit = s.split(' ');
      if ((ref1 = sSplit[0]) === 'this' || ref1 === 'next' || ref1 === 'previous') {
        if (sSplit[2] === 'in' && (sSplit[3] != null)) {
          tz = sSplit[3];
        } else {
          tz = void 0;
        }
        zuluCT = new Time(new Date(), sSplit[1], tz);
        this._setFromConfig(zuluCT);
        if (sSplit[0] === 'next') {
          this.increment();
        } else if (sSplit[0] === 'previous') {
          this.decrement();
        }
        return;
      }
      ref2 = Time._granularitySpecs;
      for (g in ref2) {
        spec = ref2[g];
        if (spec.segmentStart + spec.segmentLength === s.length || spec.mask.indexOf('#') < 0) {
          if (spec.regex.test(s)) {
            granularity = g;
            break;
          }
        }
      }
      if (granularity == null) {
        throw new Error("Error parsing string '" + s + "'. Couldn't identify granularity.");
      }
      this.granularity = granularity;
      segments = Time._granularitySpecs[this.granularity].segments;
      stillParsing = true;
      results = [];
      for (k = 0, len = segments.length; k < len; k++) {
        segment = segments[k];
        if (stillParsing) {
          gs = Time._granularitySpecs[segment];
          l = gs.segmentLength;
          sub = Time._getStringPart(s, segment);
          if (sub.length !== l) {
            stillParsing = false;
          }
        }
        if (stillParsing) {
          results.push(this[segment] = Number(sub));
        } else {
          results.push(this[segment] = Time._granularitySpecs[segment].lowest);
        }
      }
      return results;
    };

    Time._getStringPart = function(s, segment) {
      var l, st, sub;
      spec = Time._granularitySpecs[segment];
      l = spec.segmentLength;
      st = spec.segmentStart;
      sub = s.substr(st, l);
      return sub;
    };

    Time.prototype._setFromRDN = function(rdn, granularity) {
      var J, a, afterCT, afterRDN, b, beforeCT, beforeRDN, c, config, d, da, db, dc, dg, granularitySpec, j, k, len, m, n, ref1, segment, specForLowest, w, x, y, z;
      config = {
        granularity: granularity
      };
      utils.assert(granularity != null, "Must provide a granularity when constructing with a Rata Die Number.");
      switch (granularity) {
        case 'week':
        case 'week_day':
          w = Math.floor((rdn - 1) / 7);
          d = (rdn - 1) % 7;
          n = Math.floor(w / 20871);
          w = w % 20871;
          z = w + (w >= 10435 ? 1 : 0);
          c = Math.floor(z / 5218);
          w = z % 5218;
          x = w * 28 + [15, 23, 3, 11][c];
          y = Math.floor(x / 1461);
          w = x % 1461;
          config['year'] = y + n * 400 + c * 100 + 1;
          config['week'] = Math.floor(w / 28) + 1;
          config['week_day'] = d + 1;
          return this._setFromConfig(config);
        case 'year':
        case 'month':
        case 'day':
        case 'hour':
        case 'minute':
        case 'second':
        case 'millisecond':
        case 'quarter':
          J = rdn + 1721425;
          j = J + 32044;
          g = Math.floor(j / 146097);
          dg = j % 146097;
          c = Math.floor((Math.floor(dg / 36524) + 1) * 3 / 4);
          dc = dg - c * 36524;
          b = Math.floor(dc / 1461);
          db = dc % 1461;
          a = Math.floor((Math.floor(db / 365) + 1) * 3 / 4);
          da = db - a * 365;
          y = g * 400 + c * 100 + b * 4 + a;
          m = Math.floor((da * 5 + 308) / 153) - 2;
          d = da - Math.floor((m + 4) * 153 / 5) + 122;
          config['year'] = y - 4800 + Math.floor((m + 2) / 12);
          config['month'] = (m + 2) % 12 + 1;
          config['day'] = Math.floor(d) + 1;
          config['quarter'] = Math.floor((config.month - 1) / 3) + 1;
          return this._setFromConfig(config);
        default:
          granularitySpec = Time._granularitySpecs[granularity];
          specForLowest = {
            granularity: granularity
          };
          ref1 = granularitySpec.segments;
          for (k = 0, len = ref1.length; k < len; k++) {
            segment = ref1[k];
            specForLowest[segment] = Time._granularitySpecs[segment].lowest;
          }
          beforeCT = new Time(specForLowest);
          beforeRDN = beforeCT.rataDieNumber();
          afterCT = beforeCT.add(1);
          afterRDN = afterCT.rataDieNumber();
          if (rdn < beforeRDN) {
            this.beforePastFlag = 'BEFORE_FIRST';
            return;
          }
          while (true) {
            if (rdn < afterRDN && rdn >= beforeRDN) {
              this._setFromConfig(beforeCT);
              return;
            }
            beforeCT = afterCT;
            beforeRDN = afterRDN;
            afterCT = beforeCT.add(1);
            afterRDN = afterCT.rataDieNumber();
            if (afterCT.beforePastFlag === 'PAST_LAST') {
              if (rdn >= Time._granularitySpecs[beforeCT.granularity].endBeforeDay.rataDieNumber()) {
                this._setFromConfig(afterCT);
                this.beforePastFlag === 'PAST_LAST';
                return;
              } else if (rdn >= beforeRDN) {
                this._setFromConfig(beforeCT);
                return;
              } else {
                throw new Error("RDN: " + rdn + " seems to be out of range for " + granularity);
              }
            }
          }
          throw new Error("Something went badly wrong setting custom granularity " + granularity + " for RDN: " + rdn);
      }
    };

    Time.prototype._isGranularityCoarserThanDay = function() {

      /*
      @method granularityAboveDay
      @private
      @return {Boolean} true if the Time Object's granularity is above (coarser than) "day" level
       */
      var k, len, ref1, segment;
      ref1 = Time._granularitySpecs[this.granularity].segments;
      for (k = 0, len = ref1.length; k < len; k++) {
        segment = ref1[k];
        if (segment.indexOf('day') >= 0) {
          return false;
        }
      }
      return true;
    };

    Time.prototype.getJSDate = function(tz) {

      /*
      @method getJSDate
      @param {String} tz
      @return {Date}
      
      Returns a JavaScript Date Object properly shifted. This Date Object can be compared to other Date Objects that you know
      are already in the desired timezone. If you have data that comes from an API in GMT. You can first create a Time object from
      it and then (using this getJSDate() function) you can compare it to JavaScript Date Objects created in local time.
      
      The full name of this function should be getJSDateInGMTasummingThisCTDateIsInTimezone(tz). It converts **TO** GMT 
      (actually something that can be compared to GMT). It does **NOT** convert **FROM** GMT. Use getJSDateFromGMTInTZ()
      if you want to go in the other direction.
        
      ## Usage ##
      
          ct = new Time('2011-01-01')
          d = new Date(Date.UTC(2011, 0, 1))
          
          console.log(ct.getJSDate('GMT').getTime() == d.getTime())
           * true
          
          console.log(ct.inGranularity(Time.HOUR).add(-5).getJSDate('America/New_York').getTime() == d.getTime())
           * true
       */
      var ct, newDate, offset, utcMilliseconds;
      if (this.beforePastFlag === 'PAST_LAST') {
        return new Date(9999, 0, 1);
      }
      if (this.beforePastFlag === 'BEFORE_FIRST') {
        return new Date('0001-01-01');
      }
      utils.assert(tz != null, 'Must provide a timezone when calling getJSDate');
      ct = this.inGranularity('millisecond');
      utcMilliseconds = Date.UTC(ct.year, ct.month - 1, ct.day, ct.hour, ct.minute, ct.second, ct.millisecond);
      offset = timezoneJS.timezone.getTzInfo(new Date(utcMilliseconds), tz).tzOffset;
      utcMilliseconds += offset * 1000 * 60;
      newDate = new Date(utcMilliseconds);
      return newDate;
    };

    Time.prototype.getISOStringInTZ = function(tz) {

      /*
      @method getISOStringInTZ
      @param {String} tz
      @return {String} The canonical ISO-8601 date in zulu representation but shifted to the specified tz
      
          console.log(new Time('2012-01-01').getISOStringInTZ('Europe/Berlin'))
           * 2011-12-31T23:00:00.000Z
       */
      var jsDate;
      utils.assert(tz != null, 'Must provide a timezone when calling getShiftedISOString');
      jsDate = this.getJSDate(tz);
      return Time.getISOStringFromJSDate(jsDate);
    };

    Time.getISOStringFromJSDate = function(jsDate) {

      /*
      @method getISOStringFromJSDate
      @static
      @param {Date} jsDate
      @return {String}
      
      Given a JavaScript Date() Object, this will return the canonical ISO-8601 form.
      
      If you don't provide any parameters, it will return now, like `new Date()` except this is a zulu string.
      
          console.log(Time.getISOStringFromJSDate(new Date(0)))
           * 1970-01-01T00:00:00.000Z
       */
      var day, hour, millisecond, minute, month, s, second, year;
      if (jsDate == null) {
        jsDate = new Date();
      }
      year = jsDate.getUTCFullYear();
      month = jsDate.getUTCMonth() + 1;
      day = jsDate.getUTCDate();
      hour = jsDate.getUTCHours();
      minute = jsDate.getUTCMinutes();
      second = jsDate.getUTCSeconds();
      millisecond = jsDate.getUTCMilliseconds();
      s = Time._pad(year, 4) + '-' + Time._pad(month, 2) + '-' + Time._pad(day, 2) + 'T' + Time._pad(hour, 2) + ':' + Time._pad(minute, 2) + ':' + Time._pad(second, 2) + '.' + Time._pad(millisecond, 3) + 'Z';
      return s;
    };

    Time.prototype.getJSDateFromGMTInTZ = function(tz) {

      /*
      @method getJSDateInTZfromGMT
      @param {String} tz
      @return {Date}
      
      This assumes that the Time is an actual GMT date/time as opposed to some abstract day like Christmas and shifts
      it into the specified timezone.
      
      Note, this function will be off by an hour for the times near midnight on the days where there is a shift to/from daylight 
      savings time. The tz rules engine is designed to go in the other direction so we're mis-using it. This means we are using the wrong
      moment in rules-space for that hour. The cost of fixing this issue was deemed to high for chart applications.
      
          console.log(new Time('2012-01-01').getJSDateFromGMTInTZ('Europe/Berlin').toISOString())
           * 2012-01-01T01:00:00.000Z
       */
      var ct, newDate, offset, utcMilliseconds;
      if (this.beforePastFlag === 'PAST_LAST') {
        return new Date(9999, 0, 1);
      }
      if (this.beforePastFlag === 'BEFORE_FIRST') {
        return new Date('0001-01-01');
      }
      utils.assert(tz != null, 'Must provide a timezone when calling getJSDate');
      ct = this.inGranularity('millisecond');
      utcMilliseconds = Date.UTC(ct.year, ct.month - 1, ct.day, ct.hour, ct.minute, ct.second, ct.millisecond);
      offset = timezoneJS.timezone.getTzInfo(new Date(utcMilliseconds), tz).tzOffset;
      utcMilliseconds -= offset * 1000 * 60;
      newDate = new Date(utcMilliseconds);
      return newDate;
    };

    Time.prototype.getSegmentsAsObject = function() {

      /*
      @method getSegmentsAsObject
      @return {Object} Returns a simple JavaScript Object containing the segments. This is useful when using utils.match
      for holiday comparison
      
          t = new Time('2011-01-10')
          console.log(t.getSegmentsAsObject())
           * { year: 2011, month: 1, day: 10 }
       */
      var k, len, rawObject, segment, segments;
      segments = Time._granularitySpecs[this.granularity].segments;
      rawObject = {};
      for (k = 0, len = segments.length; k < len; k++) {
        segment = segments[k];
        rawObject[segment] = this[segment];
      }
      return rawObject;
    };

    Time.prototype.getSegmentsAsArray = function() {

      /*
      @method getSegmentsAsArray
      @return {Array} Returns a simple JavaScript Array containing the segments. This is useful for doing hierarchical
        aggregations using Lumenize.OLAPCube.
      
          t = new Time('2011-01-10')
          console.log(t.getSegmentsAsArray())
           * [ 2011, 1, 10 ]
       */
      var a, k, len, segment, segments;
      segments = Time._granularitySpecs[this.granularity].segments;
      a = [];
      for (k = 0, len = segments.length; k < len; k++) {
        segment = segments[k];
        a.push(this[segment]);
      }
      return a;
    };

    Time.prototype.toString = function() {

      /*
      @method toString
      @return {String} Uses granularity `mask` in _granularitySpecs to generate the string representation.
      
          t = new Time({year: 2012, month: 1, day: 1, granularity: Time.MINUTE}).toString()
          console.log(t.toString())
          console.log(t)
           * 2012-01-01T00:00
           * 2012-01-01T00:00
       */
      var after, before, granularitySpec, k, l, len, ref1, s, segment, segments, start;
      if ((ref1 = this.beforePastFlag) === 'BEFORE_FIRST' || ref1 === 'PAST_LAST') {
        s = "" + this.beforePastFlag;
      } else {
        s = Time._granularitySpecs[this.granularity].mask;
        segments = Time._granularitySpecs[this.granularity].segments;
        for (k = 0, len = segments.length; k < len; k++) {
          segment = segments[k];
          granularitySpec = Time._granularitySpecs[segment];
          l = granularitySpec.segmentLength;
          start = granularitySpec.segmentStart;
          before = s.slice(0, start);
          after = s.slice(start + l);
          s = before + Time._pad(this[segment], l) + after;
        }
      }
      return s;
    };

    Time._pad = function(n, l) {
      var result;
      result = n.toString();
      while (result.length < l) {
        result = '0' + result;
      }
      return result;
    };

    Time.DOW_N_TO_S_MAP = {
      0: 'Sunday',
      1: 'Monday',
      2: 'Tuesday',
      3: 'Wednesday',
      4: 'Thursday',
      5: 'Friday',
      6: 'Saturday',
      7: 'Sunday'
    };

    Time.MONTH_TO_S_MAP = {
      1: 'January',
      2: 'February',
      3: 'March',
      4: 'April',
      5: 'May',
      6: 'June',
      7: 'July',
      8: 'August',
      9: 'September',
      10: 'October',
      11: 'November',
      12: 'December'
    };

    Time.DOW_MONTH_TABLE = [0, 3, 2, 5, 0, 3, 5, 1, 4, 6, 2, 4];

    Time.prototype.dowNumber = function() {

      /*
      @method dowNumber
      @return {Number}
      Returns the day of the week as a number. Monday = 1, Sunday = 7
      
          console.log(new Time('2012-01-01').dowNumber())
           * 7
       */
      var dayNumber, ref1, y;
      if (this.granularity === 'week_day') {
        return this.week_day;
      }
      if ((ref1 = this.granularity) === 'day' || ref1 === 'hour' || ref1 === 'minute' || ref1 === 'second' || ref1 === 'millisecond') {
        y = this.year;
        if (this.month < 3) {
          y--;
        }
        dayNumber = (y + Math.floor(y / 4) - Math.floor(y / 100) + Math.floor(y / 400) + Time.DOW_MONTH_TABLE[this.month - 1] + this.day) % 7;
        if (dayNumber === 0) {
          return 7;
        } else {
          return dayNumber;
        }
      } else {
        return this.inGranularity('day').dowNumber();
      }
    };

    Time.prototype.dowString = function() {

      /*
      @method dowString
      @return {String} Returns the day of the week as a String (e.g. "Monday")
      
          console.log(new Time('2012-01-01').dowString())
           * Sunday
       */
      return Time.DOW_N_TO_S_MAP[this.dowNumber()];
    };

    Time.prototype.monthString = function() {

      /*
      @method monthString
      @return {String} Returns the month as a String (e.g. "January")
      
          console.log(new Time('2012-01-01').monthString())
           * January
       */
      return Time.MONTH_TO_S_MAP[this.month];
    };

    Time.prototype.rataDieNumber = function() {

      /*
      @method rataDieNumber
      @return {Number} Returns the counting number for days starting with 0001-01-01 (i.e. 0 AD). Note, this differs
      from the Unix Epoch which starts on 1970-01-01. This function works for
      granularities finer than day (hour, minute, second, millisecond) but ignores the segments of finer granularity than
      day. Also called common era days.
      
          console.log(new Time('0001-01-01').rataDieNumber())
           * 1
      
          rdn2012 = new Time('2012-01-01').rataDieNumber()
          rdn1970 = new Time('1970-01-01').rataDieNumber()
          ms1970To2012 = (rdn2012 - rdn1970) * 24 * 60 * 60 * 1000
          msJSDate2012 = Number(new Date('2012-01-01'))
          console.log(ms1970To2012 == msJSDate2012)
           * true
       */
      var ew, monthDays, y, yearDays;
      if (this.beforePastFlag === 'BEFORE_FIRST') {
        return -1;
      } else if (this.beforePastFlag === 'PAST_LAST') {
        return utils.MAX_INT;
      } else if (Time._granularitySpecs[this.granularity].rataDieNumber != null) {
        return Time._granularitySpecs[this.granularity].rataDieNumber(this);
      } else {
        y = this.year - 1;
        yearDays = y * 365 + Math.floor(y / 4) - Math.floor(y / 100) + Math.floor(y / 400);
        ew = Math.floor((yearDays + 3) / 7);
        if (this.month != null) {
          monthDays = [0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334][this.month - 1];
          if (this.isLeapYear() && this.month >= 3) {
            monthDays++;
          }
        } else if (this.quarter != null) {
          monthDays = [0, 90, 181, 273][this.quarter - 1];
          if (this.isLeapYear() && this.quarter >= 2) {
            monthDays++;
          }
        } else {
          monthDays = 0;
        }
        switch (this.granularity) {
          case 'year':
            return yearDays + 1;
          case 'month':
          case 'quarter':
            return yearDays + monthDays + 1;
          case 'day':
          case 'hour':
          case 'minute':
          case 'second':
          case 'millisecond':
            return yearDays + monthDays + this.day;
          case 'week':
            return (ew + this.week - 1) * 7 + 1;
          case 'week_day':
            return (ew + this.week - 1) * 7 + this.week_day;
        }
      }
    };

    Time.prototype.inGranularity = function(granularity) {

      /*
      @method inGranularity
      @param {String} granularity
      @return {Time} Returns a new Time object for the same date-time as this object but in the specified granularity.
      Fills in missing finer granularity segments with `lowest` values. Drops segments when convernting to a coarser
      granularity.
      
          console.log(new Time('2012W01-1').inGranularity(Time.DAY).toString())
           * 2012-01-02
      
          console.log(new Time('2012Q3').inGranularity(Time.MONTH).toString())
           * 2012-07
       */
      var newTime, ref1, tempGranularity;
      if ((ref1 = this.granularity) === 'year' || ref1 === 'month' || ref1 === 'day' || ref1 === 'hour' || ref1 === 'minute' || ref1 === 'second' || ref1 === 'millisecond') {
        if (granularity === 'year' || granularity === 'month' || granularity === 'day' || granularity === 'hour' || granularity === 'minute' || granularity === 'second' || granularity === 'millisecond') {
          tempGranularity = this.granularity;
          this.granularity = granularity;
          newTime = new Time(this);
          this.granularity = tempGranularity;
          return newTime;
        }
      }
      return new Time(this.rataDieNumber(), granularity);
    };

    Time.prototype.daysInMonth = function() {

      /*
      @method daysInMonth
      @return {Number} Returns the number of days in the current month for this Time
      
          console.log(new Time('2012-02').daysInMonth())
           * 29
       */
      switch (this.month) {
        case 4:
        case 6:
        case 9:
        case 11:
          return 30;
        case 1:
        case 3:
        case 5:
        case 7:
        case 8:
        case 10:
        case 12:
        case 0:
          return 31;
        case 2:
          if (this.isLeapYear()) {
            return 29;
          } else {
            return 28;
          }
      }
    };

    Time.prototype.isLeapYear = function() {

      /*
      @method isLeapYear
      @return {Boolean} true if this is a leap year
      
          console.log(new Time('2012').isLeapYear())
           * true
       */
      if (this.year % 4 === 0) {
        if (this.year % 100 === 0) {
          if (this.year % 400 === 0) {
            return true;
          } else {
            return false;
          }
        } else {
          return true;
        }
      } else {
        return false;
      }
    };

    Time.YEARS_WITH_53_WEEKS = [4, 9, 15, 20, 26, 32, 37, 43, 48, 54, 60, 65, 71, 76, 82, 88, 93, 99, 105, 111, 116, 122, 128, 133, 139, 144, 150, 156, 161, 167, 172, 178, 184, 189, 195, 201, 207, 212, 218, 224, 229, 235, 240, 246, 252, 257, 263, 268, 274, 280, 285, 291, 296, 303, 308, 314, 320, 325, 331, 336, 342, 348, 353, 359, 364, 370, 376, 381, 387, 392, 398];

    Time.prototype.is53WeekYear = function() {

      /*
      @method is53WeekYear
      @return {Boolean} true if this is a 53-week year
      
          console.log(new Time('2015').is53WeekYear())
           * true
       */
      var lookup;
      lookup = this.year % 400;
      return indexOf.call(Time.YEARS_WITH_53_WEEKS, lookup) >= 0;
    };

    Time.prototype.equal = function(other) {

      /*
      @method equal
      @param {Time} other
      @return {Boolean} Returns true if this equals other. Throws an error if the granularities don't match.
      
          d3 = new Time({granularity: Time.DAY, year: 2011, month: 12, day: 31})
          d4 = new Time('2012-01-01').add(-1)
          console.log(d3.equal(d4))
           * true
       */
      var k, len, segment, segments;
      utils.assert(this.granularity === other.granularity, "Granulary of " + this + " does not match granularity of " + other + " on equality/inequality test");
      if (this.beforePastFlag === 'PAST_LAST' && other.beforePastFlag === 'PAST_LAST') {
        return true;
      }
      if (this.beforePastFlag === 'BEFORE_FIRST' && other.beforePastFlag === 'BEFORE_FIRST') {
        return true;
      }
      if (this.beforePastFlag === 'PAST_LAST' && other.beforePastFlag !== 'PAST_LAST') {
        return false;
      }
      if (this.beforePastFlag === 'BEFORE_FIRST' && other.beforePastFlag !== 'BEFORE_FIRST') {
        return false;
      }
      if (other.beforePastFlag === 'PAST_LAST' && this.beforePastFlag !== 'PAST_LAST') {
        return false;
      }
      if (other.beforePastFlag === 'BEFORE_FIRST' && this.beforePastFlag !== 'BEFORE_FIRST') {
        return false;
      }
      segments = Time._granularitySpecs[this.granularity].segments;
      for (k = 0, len = segments.length; k < len; k++) {
        segment = segments[k];
        if (this[segment] !== other[segment]) {
          return false;
        }
      }
      return true;
    };

    Time.prototype.greaterThan = function(other) {

      /*
      @method greaterThan
      @param {Time} other
      @return {Boolean} Returns true if this is greater than other. Throws an error if the granularities don't match
      
          d1 = new Time({granularity: Time.DAY, year: 2011, month: 2, day: 28})
          d2 = new Time({granularity: Time.DAY, year: 2011, month: 3, day: 1})
          console.log(d1.greaterThan(d2))
           * false
          console.log(d2.greaterThan(d1))
           * true
       */
      var k, len, segment, segments;
      utils.assert(this.granularity === other.granularity, "Granulary of " + this + " does not match granularity of " + other + " on equality/inequality test");
      if (this.beforePastFlag === 'PAST_LAST' && other.beforePastFlag === 'PAST_LAST') {
        return false;
      }
      if (this.beforePastFlag === 'BEFORE_FIRST' && other.beforePastFlag === 'BEFORE_FIRST') {
        return false;
      }
      if (this.beforePastFlag === 'PAST_LAST' && other.beforePastFlag !== 'PAST_LAST') {
        return true;
      }
      if (this.beforePastFlag === 'BEFORE_FIRST' && other.beforePastFlag !== 'BEFORE_FIRST') {
        return false;
      }
      if (other.beforePastFlag === 'PAST_LAST' && this.beforePastFlag !== 'PAST_LAST') {
        return false;
      }
      if (other.beforePastFlag === 'BEFORE_FIRST' && this.beforePastFlag !== 'BEFORE_FIRST') {
        return true;
      }
      segments = Time._granularitySpecs[this.granularity].segments;
      for (k = 0, len = segments.length; k < len; k++) {
        segment = segments[k];
        if (this[segment] > other[segment]) {
          return true;
        }
        if (this[segment] < other[segment]) {
          return false;
        }
      }
      return false;
    };

    Time.prototype.greaterThanOrEqual = function(other) {

      /*
      @method greaterThanOrEqual
      @param {Time} other
      @return {Boolean} Returns true if this is greater than or equal to other
      
          console.log(new Time('2012').greaterThanOrEqual(new Time('2012')))
           * true
       */
      var gt;
      gt = this.greaterThan(other);
      if (gt) {
        return true;
      }
      return this.equal(other);
    };

    Time.prototype.lessThan = function(other) {

      /*
      @method lessThan
      @param {Time} other
      @return {Boolean} Returns true if this is less than other
      
          console.log(new Time(1000, Time.DAY).lessThan(new Time(999, Time.DAY)))  # Using RDN constructor
           * false
       */
      return other.greaterThan(this);
    };

    Time.prototype.lessThanOrEqual = function(other) {

      /*
      @method lessThanOrEqual
      @param {Time} other
      @return {Boolean} Returns true if this is less than or equal to other
      
          console.log(new Time('this day').lessThanOrEqual(new Time('next day')))  # Using relative constructor
           * true
       */
      return other.greaterThanOrEqual(this);
    };

    Time.prototype._overUnderFlow = function() {
      var granularitySpec, highestLevel, highestLevelSpec, lowest, ref1, rolloverValue, value;
      if ((ref1 = this.beforePastFlag) === 'BEFORE_FIRST' || ref1 === 'PAST_LAST') {
        return true;
      } else {
        granularitySpec = Time._granularitySpecs[this.granularity];
        highestLevel = granularitySpec.segments[0];
        highestLevelSpec = Time._granularitySpecs[highestLevel];
        value = this[highestLevel];
        rolloverValue = highestLevelSpec.rolloverValue(this);
        lowest = highestLevelSpec.lowest;
        if (value >= rolloverValue) {
          this.beforePastFlag = 'PAST_LAST';
          return true;
        } else if (value < lowest) {
          this.beforePastFlag = 'BEFORE_FIRST';
          return true;
        } else {
          return false;
        }
      }
    };

    Time.prototype.decrement = function(granularity) {

      /*
      @method decrement
      @param {String} [granularity]
      @chainable
      @return {Time}
      Decrements this by 1 in the granularity of the Time or the granularity specified if it was specified
      
          console.log(new Time('2016W01').decrement().toString())
           * 2015W53
       */
      var granularitySpec, gs, i, k, lastDayInMonthFlag, len, results, segment, segments;
      if (this.beforePastFlag === 'PAST_LAST') {
        this.beforePastFlag = '';
        granularitySpec = Time._granularitySpecs[this.granularity];
        segments = granularitySpec.segments;
        results = [];
        for (k = 0, len = segments.length; k < len; k++) {
          segment = segments[k];
          gs = Time._granularitySpecs[segment];
          results.push(this[segment] = gs.rolloverValue(this) - 1);
        }
        return results;
      } else {
        lastDayInMonthFlag = this.day === this.daysInMonth();
        if (granularity == null) {
          granularity = this.granularity;
        }
        granularitySpec = Time._granularitySpecs[granularity];
        segments = granularitySpec.segments;
        this[granularity]--;
        if (granularity === 'year') {
          if (this.day > this.daysInMonth()) {
            this.day = this.daysInMonth();
          }
        } else {
          i = segments.length - 1;
          segment = segments[i];
          granularitySpec = Time._granularitySpecs[segment];
          while ((i > 0) && (this[segment] < granularitySpec.lowest)) {
            this[segments[i - 1]]--;
            this[segment] = granularitySpec.rolloverValue(this) - 1;
            i--;
            segment = segments[i];
            granularitySpec = Time._granularitySpecs[segment];
          }
          if (granularity === 'month' && (this.granularity !== 'month')) {
            if (lastDayInMonthFlag || (this.day > this.daysInMonth())) {
              this.day = this.daysInMonth();
            }
          }
        }
        this._overUnderFlow();
        return this;
      }
    };

    Time.prototype.increment = function(granularity) {

      /*
      @method increment
      @param {String} [granularity]
      @chainable
      @return {Time}
      Increments this by 1 in the granularity of the Time or the granularity specified if it was specified
      
          console.log(new Time('2012Q4').increment().toString())
           * 2013Q1
       */
      var granularitySpec, gs, i, k, lastDayInMonthFlag, len, results, segment, segments;
      if (this.beforePastFlag === 'BEFORE_FIRST') {
        this.beforePastFlag = '';
        granularitySpec = Time._granularitySpecs[this.granularity];
        segments = granularitySpec.segments;
        results = [];
        for (k = 0, len = segments.length; k < len; k++) {
          segment = segments[k];
          gs = Time._granularitySpecs[segment];
          results.push(this[segment] = gs.lowest);
        }
        return results;
      } else {
        lastDayInMonthFlag = this.day === this.daysInMonth();
        if (granularity == null) {
          granularity = this.granularity;
        }
        granularitySpec = Time._granularitySpecs[granularity];
        segments = granularitySpec.segments;
        this[granularity]++;
        if (granularity === 'year') {
          if (this.day > this.daysInMonth()) {
            this.day = this.daysInMonth();
          }
        } else {
          i = segments.length - 1;
          segment = segments[i];
          granularitySpec = Time._granularitySpecs[segment];
          while ((i > 0) && (this[segment] >= granularitySpec.rolloverValue(this))) {
            this[segment] = granularitySpec.lowest;
            this[segments[i - 1]]++;
            i--;
            segment = segments[i];
            granularitySpec = Time._granularitySpecs[segment];
          }
          if ((granularity === 'month') && (this.granularity !== 'month')) {
            if (lastDayInMonthFlag || (this.day > this.daysInMonth())) {
              this.day = this.daysInMonth();
            }
          }
        }
        this._overUnderFlow();
        return this;
      }
    };

    Time.prototype.addInPlace = function(qty, granularity) {

      /*
      @method addInPlace
      @chainable
      @param {Number} qty Can be negative for subtraction
      @param {String} [granularity]
      @return {Time} Adds qty to the Time object. It uses increment and decrement so it's not going to be efficient for large values
      of qty, but it should be fine for charts where we'll increment/decrement small values of qty.
      
          console.log(new Time('2011-11-01').addInPlace(3, Time.MONTH).toString())
           * 2012-02-01
       */
      if (granularity == null) {
        granularity = this.granularity;
      }
      if (qty === 0) {
        return this;
      }
      if (qty === 1) {
        this.increment(granularity);
      } else if (qty > 1) {
        this.increment(granularity);
        this.addInPlace(qty - 1, granularity);
      } else if (qty === -1) {
        this.decrement(granularity);
      } else {
        this.decrement(granularity);
        this.addInPlace(qty + 1, granularity);
      }
      return this;
    };

    Time.prototype.add = function(qty, granularity) {

      /*
      @method add
      @param {Number} qty
      @param {String} [granularity]
      @return {Time}
      Adds (or subtracts) quantity (negative quantity) and returns a new Time. Not efficient for large qty.
      
         console.log(new Time('2012-01-01').add(-10, Time.MONTH))
          * 2011-03-01
       */
      var newTime;
      newTime = new Time(this);
      newTime.addInPlace(qty, granularity);
      return newTime;
    };

    Time.addGranularity = function(granularitySpec) {

      /*
      @method addGranularity
      @static
      @param {Object} granularitySpec see {@link Time#_granularitySpecs} for existing _granularitySpecs
      @cfg {String[]} segments an Array identifying the ancestry (e.g. for 'day', it is: `['year', 'month', 'day']`)
      @cfg {String} mask a String used to identify when this granularity is passed in and to serialize it on the way out.
      @cfg {Number} lowest the lowest possible value for this granularity. 0 for millisecond but 1 for day.
      @cfg {Function} rolloverValue a callback function that will say when to rollover the next coarser granularity.
      
      addGranularity allows you to add your own hierarchical granularities to Time. Once you add a granularity to Time
      you can then instantiate Time objects in your newly specified granularity. You specify new granularities with
      granularitySpec object like this:
          
          granularitySpec = {
            release: {
              segments: ['release'],
              mask: 'R##',
              lowest: 1,
              endBeforeDay: new Time('2011-07-01')
              rolloverValue: (ct) ->
                return Time._granularitySpecs.iteration.timeBoxes.length + 1  # Yes, it's correct to use the length of iteration.timeBoxes
              rataDieNumber: (ct) ->
                return Time._granularitySpecs.iteration.timeBoxes[ct.release-1][1-1].startOn.rataDieNumber()
            },
            iteration: {
              segments: ['release', 'iteration'],
              mask: 'R##I##',
              lowest: 1,
              endBeforeDay: new Time('2011-07-01')
              timeBoxes: [
                [
                  {startOn: new Time('2011-01-01'), label: 'R1 Iteration 1'},
                  {startOn: new Time('2011-02-01'), label: 'R1 Iteration 2'},
                  {startOn: new Time('2011-03-01'), label: 'R1 Iteration 3'},
                ],
                [
                  {startOn: new Time('2011-04-01'), label: 'R2 Iteration 1'},
                  {startOn: new Time('2011-05-01'), label: 'R2 Iteration 2'},
                  {startOn: new Time('2011-06-01'), label: 'R2 Iteration 3'},
                ]
              ]
              rolloverValue: (ct) ->
                temp = Time._granularitySpecs.iteration.timeBoxes[ct.release-1]?.length + 1
                if temp? and not isNaN(temp) and ct.beforePastFlag != 'PAST_LAST'
                  return temp
                else
                  numberOfReleases = Time._granularitySpecs.iteration.timeBoxes.length
                  return Time._granularitySpecs.iteration.timeBoxes[numberOfReleases-1].length + 1
      
              rataDieNumber: (ct) ->
                return Time._granularitySpecs.iteration.timeBoxes[ct.release-1][ct.iteration-1].startOn.rataDieNumber()
            },
            iteration_day: {  # By convention, it knows to use day functions on it. This is the lowest allowed custom granularity
              segments: ['release', 'iteration', 'iteration_day'],
              mask: 'R##I##-##',
              lowest: 1,
              endBeforeDay: new Time('2011-07-01'),
              rolloverValue: (ct) ->
                iterationTimeBox = Time._granularitySpecs.iteration.timeBoxes[ct.release-1]?[ct.iteration-1]
                if !iterationTimeBox? or ct.beforePastFlag == 'PAST_LAST'
                  numberOfReleases = Time._granularitySpecs.iteration.timeBoxes.length
                  numberOfIterationsInLastRelease = Time._granularitySpecs.iteration.timeBoxes[numberOfReleases-1].length
                  iterationTimeBox = Time._granularitySpecs.iteration.timeBoxes[numberOfReleases-1][numberOfIterationsInLastRelease-1]
                  
                thisIteration = iterationTimeBox.startOn.inGranularity('iteration')
                nextIteration = thisIteration.add(1)
                if nextIteration.beforePastFlag == 'PAST_LAST'
                  return Time._granularitySpecs.iteration_day.endBeforeDay.rataDieNumber() - iterationTimeBox.startOn.rataDieNumber() + 1
                else
                  return nextIteration.rataDieNumber() - iterationTimeBox.startOn.rataDieNumber() + 1
                 
              rataDieNumber: (ct) ->
                return Time._granularitySpecs.iteration.timeBoxes[ct.release-1][ct.iteration-1].startOn.rataDieNumber() + ct.iteration_day - 1
            }
          }    
          Time.addGranularity(granularitySpec)
      
      
      The `mask` must cover all of the segments to get down to the granularity being specified. The digits of the granularity segments
      are represented with `#`. Any other characters can be used as a delimeter, but it should always be one character to comply with 
      the expectations of the Lumenize hierarchy visualizations. All of the standard granularities start with a 4-digit year to
      distinguish your custom granularity, your highest level must start with some number of digits other than 4 or a prefix letter 
      (`R` in the example above).
      
      In order for the TimelineIterator to work, you must provide `rolloverValue` and `rataDieNumber` callback functions. You should
      be able to mimic (or use as-is) the example above for most use cases. Notice how the `rataDieNumber` function simply leverages
      `rataDieNumber` functions for the standard granularities.
      
      In order to convert into this granularity from some other granularity, you must provide an `inGranularity` callback [NOT YET IMPLEMENTED].
      But Time will convert to any of the standard granularities from even custom granularities as long as a `rataDieNumber()` function
      is provided.
      
      **The `timeBoxes` property in the `granularitySpec` Object above has no special meaning** to Time or TimelineIterator. It's simply used
      by the `rolloverValue` and `rataDieNumber` functions. The boundaries could come from where ever you want and even have been encoded as
      literals in the `rolloverValue` and `rataDieNumber` callback functions.
      
      The convention of naming the lowest order granularity with `_day` at the end IS signficant. Time knows to treat that as a day-level
      granularity. If there is a use-case for it, Time could be upgraded to allow you to drill down into hours, minutes, etc. from any
      `_day` granularity but right now those lower order time granularities are only supported for the canonical ISO-6801 form.
       */
      var results;
      results = [];
      for (g in granularitySpec) {
        spec = granularitySpec[g];
        Time._expandMask(spec);
        this._granularitySpecs[g] = spec;
        results.push(Time[g.toUpperCase()] = g);
      }
      return results;
    };

    return Time;

  })();

  exports.Time = Time;

}).call(this);

});

require.define("/node_modules/tztime/src/utils.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3
(function() {
  var AssertException, ErrorBase, assert, clone, compare, decodeUtf8, encodeUtf8, exactMatch, filterMatch, isArray, keys, log, lzwDecode, lzwEncode, match, startsWith, trim, type, values,
    extend = function(child, parent) { for (var key in parent) { if (hasProp.call(parent, key)) child[key] = parent[key]; } function ctor() { this.constructor = child; } ctor.prototype = parent.prototype; child.prototype = new ctor(); child.__super__ = parent.prototype; return child; },
    hasProp = {}.hasOwnProperty;

  exports.MAX_INT = 2147483647;

  exports.MIN_INT = -2147483648;

  ErrorBase = (function(superClass) {
    extend(ErrorBase, superClass);

    function ErrorBase(message1) {
      this.message = message1 != null ? message1 : 'Unknown error.';
      if (Error.captureStackTrace != null) {
        Error.captureStackTrace(this, this.constructor);
      }
      this.name = this.constructor.name;
    }

    ErrorBase.prototype.toString = function() {
      return this.name + ": " + this.message;
    };

    return ErrorBase;

  })(Error);

  AssertException = (function(superClass) {
    extend(AssertException, superClass);

    function AssertException() {
      return AssertException.__super__.constructor.apply(this, arguments);
    }

    return AssertException;

  })(ErrorBase);

  assert = function(exp, message) {
    if (!exp) {
      throw new exports.AssertException(message);
    }
  };

  match = function(obj1, obj2) {
    var key, value;
    for (key in obj1) {
      value = obj1[key];
      if (value !== obj2[key]) {
        return false;
      }
    }
    return true;
  };

  exactMatch = function(a, b) {
    var atype, btype, key, val;
    if (a === b) {
      return true;
    }
    atype = typeof a;
    btype = typeof b;
    if (atype !== btype) {
      return false;
    }
    if ((!a && b) || (a && !b)) {
      return false;
    }
    if (atype !== 'object') {
      return false;
    }
    if (a.length && (a.length !== b.length)) {
      return false;
    }
    for (key in a) {
      val = a[key];
      if (!(key in b) || !exactMatch(val, b[key])) {
        return false;
      }
    }
    return true;
  };

  filterMatch = function(obj1, obj2) {
    var key, value;
    if (!(type(obj1) === 'object' && type(obj2) === 'object')) {
      throw new Error('obj1 and obj2 must both be objects when calling filterMatch');
    }
    for (key in obj1) {
      value = obj1[key];
      if (!exactMatch(value, obj2[key])) {
        return false;
      }
    }
    return true;
  };

  trim = function(val) {
    if (String.prototype.trim != null) {
      return val.trim();
    } else {
      return val.replace(/^\s+|\s+$/g, "");
    }
  };

  startsWith = function(bigString, potentialStartString) {
    return bigString.substring(0, potentialStartString.length) === potentialStartString;
  };

  isArray = function(a) {
    return Object.prototype.toString.apply(a) === '[object Array]';
  };

  type = (function() {
    var classToType, j, len, name, ref;
    classToType = {};
    ref = "Boolean Number String Function Array Date RegExp Undefined Null".split(" ");
    for (j = 0, len = ref.length; j < len; j++) {
      name = ref[j];
      classToType["[object " + name + "]"] = name.toLowerCase();
    }
    return function(obj) {
      var strType;
      strType = Object.prototype.toString.call(obj);
      return classToType[strType] || "object";
    };
  })();

  clone = function(obj) {
    var flags, key, newInstance;
    if ((obj == null) || typeof obj !== 'object') {
      return obj;
    }
    if (obj instanceof Date) {
      return new Date(obj.getTime());
    }
    if (obj instanceof RegExp) {
      flags = '';
      if (obj.global != null) {
        flags += 'g';
      }
      if (obj.ignoreCase != null) {
        flags += 'i';
      }
      if (obj.multiline != null) {
        flags += 'm';
      }
      if (obj.sticky != null) {
        flags += 'y';
      }
      return new RegExp(obj.source, flags);
    }
    newInstance = new obj.constructor();
    for (key in obj) {
      newInstance[key] = clone(obj[key]);
    }
    return newInstance;
  };

  keys = Object.keys || function(obj) {
    var key, val;
    return (function() {
      var results;
      results = [];
      for (key in obj) {
        val = obj[key];
        results.push(key);
      }
      return results;
    })();
  };

  values = function(obj) {
    var key, val;
    return (function() {
      var results;
      results = [];
      for (key in obj) {
        val = obj[key];
        results.push(val);
      }
      return results;
    })();
  };

  log = function(s) {
    var pre;
    if ((typeof document !== "undefined" && document !== null ? document.createElement : void 0) != null) {
      pre = document.createElement('pre');
      pre.innerHTML = s;
      return document.body.appendChild(pre);
    } else {
      return console.log(s);
    }
  };

  compare = function(a, b) {
    var aString, bString, index, j, len, value;
    if (a === null) {
      return 1;
    }
    if (b === null) {
      return -1;
    }
    switch (type(a)) {
      case 'number':
      case 'boolean':
      case 'date':
        return b - a;
      case 'array':
        for (index = j = 0, len = a.length; j < len; index = ++j) {
          value = a[index];
          if (b.length - 1 >= index && value < b[index]) {
            return 1;
          }
          if (b.length - 1 >= index && value > b[index]) {
            return -1;
          }
        }
        if (a.length < b.length) {
          return 1;
        } else if (a.length > b.length) {
          return -1;
        } else {
          return 0;
        }
        break;
      case 'object':
      case 'string':
        aString = JSON.stringify(a);
        bString = JSON.stringify(b);
        if (aString < bString) {
          return 1;
        } else if (aString > bString) {
          return -1;
        } else {
          return 0;
        }
        break;
      default:
        throw new Error("Do not know how to sort objects of type " + (utils.type(a)) + ".");
    }
  };

  encodeUtf8 = function(s) {
    return unescape(encodeURIComponent(s));
  };

  decodeUtf8 = function(s) {
    return decodeURIComponent(escape(s));
  };

  lzwEncode = function(s) {
    var code, currChar, data, dict, i, out, phrase;
    s = encodeUtf8(s);
    dict = {};
    data = (s + "").split("");
    out = [];
    currChar = void 0;
    phrase = data[0];
    code = 256;
    i = 1;
    while (i < data.length) {
      currChar = data[i];
      if (dict[phrase + currChar] != null) {
        phrase += currChar;
      } else {
        out.push((phrase.length > 1 ? dict[phrase] : phrase.charCodeAt(0)));
        dict[phrase + currChar] = code;
        code++;
        phrase = currChar;
      }
      i++;
    }
    out.push((phrase.length > 1 ? dict[phrase] : phrase.charCodeAt(0)));
    i = 0;
    while (i < out.length) {
      out[i] = String.fromCharCode(out[i]);
      i++;
    }
    return out.join("");
  };

  lzwDecode = function(s) {
    var code, currChar, currCode, data, dict, i, oldPhrase, out, outS, phrase;
    dict = {};
    data = (s + "").split("");
    currChar = data[0];
    oldPhrase = currChar;
    out = [currChar];
    code = 256;
    phrase = void 0;
    i = 1;
    while (i < data.length) {
      currCode = data[i].charCodeAt(0);
      if (currCode < 256) {
        phrase = data[i];
      } else {
        phrase = (dict[currCode] ? dict[currCode] : oldPhrase + currChar);
      }
      out.push(phrase);
      currChar = phrase.charAt(0);
      dict[code] = oldPhrase + currChar;
      code++;
      oldPhrase = phrase;
      i++;
    }
    outS = out.join("");
    return decodeUtf8(outS);
  };

  exports.log = log;

  exports.AssertException = AssertException;

  exports.assert = assert;

  exports.match = match;

  exports.filterMatch = filterMatch;

  exports.trim = trim;

  exports.startsWith = startsWith;

  exports.isArray = isArray;

  exports.type = type;

  exports.clone = clone;

  exports.keys = keys;

  exports.values = values;

  exports.compare = compare;

  exports.lzwEncode = lzwEncode;

  exports.lzwDecode = lzwDecode;

  exports._ = require('underscore');

}).call(this);

});

require.define("/node_modules/tztime/node_modules/underscore/package.json",function(require,module,exports,__dirname,__filename,process,global){module.exports = {"main":"underscore.js"}
});

require.define("/node_modules/tztime/node_modules/underscore/underscore.js",function(require,module,exports,__dirname,__filename,process,global){//     Underscore.js 1.8.3
//     http://underscorejs.org
//     (c) 2009-2015 Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors
//     Underscore may be freely distributed under the MIT license.

(function() {

  // Baseline setup
  // --------------

  // Establish the root object, `window` in the browser, or `exports` on the server.
  var root = this;

  // Save the previous value of the `_` variable.
  var previousUnderscore = root._;

  // Save bytes in the minified (but not gzipped) version:
  var ArrayProto = Array.prototype, ObjProto = Object.prototype, FuncProto = Function.prototype;

  // Create quick reference variables for speed access to core prototypes.
  var
    push             = ArrayProto.push,
    slice            = ArrayProto.slice,
    toString         = ObjProto.toString,
    hasOwnProperty   = ObjProto.hasOwnProperty;

  // All **ECMAScript 5** native function implementations that we hope to use
  // are declared here.
  var
    nativeIsArray      = Array.isArray,
    nativeKeys         = Object.keys,
    nativeBind         = FuncProto.bind,
    nativeCreate       = Object.create;

  // Naked function reference for surrogate-prototype-swapping.
  var Ctor = function(){};

  // Create a safe reference to the Underscore object for use below.
  var _ = function(obj) {
    if (obj instanceof _) return obj;
    if (!(this instanceof _)) return new _(obj);
    this._wrapped = obj;
  };

  // Export the Underscore object for **Node.js**, with
  // backwards-compatibility for the old `require()` API. If we're in
  // the browser, add `_` as a global object.
  if (typeof exports !== 'undefined') {
    if (typeof module !== 'undefined' && module.exports) {
      exports = module.exports = _;
    }
    exports._ = _;
  } else {
    root._ = _;
  }

  // Current version.
  _.VERSION = '1.8.3';

  // Internal function that returns an efficient (for current engines) version
  // of the passed-in callback, to be repeatedly applied in other Underscore
  // functions.
  var optimizeCb = function(func, context, argCount) {
    if (context === void 0) return func;
    switch (argCount == null ? 3 : argCount) {
      case 1: return function(value) {
        return func.call(context, value);
      };
      case 2: return function(value, other) {
        return func.call(context, value, other);
      };
      case 3: return function(value, index, collection) {
        return func.call(context, value, index, collection);
      };
      case 4: return function(accumulator, value, index, collection) {
        return func.call(context, accumulator, value, index, collection);
      };
    }
    return function() {
      return func.apply(context, arguments);
    };
  };

  // A mostly-internal function to generate callbacks that can be applied
  // to each element in a collection, returning the desired result — either
  // identity, an arbitrary callback, a property matcher, or a property accessor.
  var cb = function(value, context, argCount) {
    if (value == null) return _.identity;
    if (_.isFunction(value)) return optimizeCb(value, context, argCount);
    if (_.isObject(value)) return _.matcher(value);
    return _.property(value);
  };
  _.iteratee = function(value, context) {
    return cb(value, context, Infinity);
  };

  // An internal function for creating assigner functions.
  var createAssigner = function(keysFunc, undefinedOnly) {
    return function(obj) {
      var length = arguments.length;
      if (length < 2 || obj == null) return obj;
      for (var index = 1; index < length; index++) {
        var source = arguments[index],
            keys = keysFunc(source),
            l = keys.length;
        for (var i = 0; i < l; i++) {
          var key = keys[i];
          if (!undefinedOnly || obj[key] === void 0) obj[key] = source[key];
        }
      }
      return obj;
    };
  };

  // An internal function for creating a new object that inherits from another.
  var baseCreate = function(prototype) {
    if (!_.isObject(prototype)) return {};
    if (nativeCreate) return nativeCreate(prototype);
    Ctor.prototype = prototype;
    var result = new Ctor;
    Ctor.prototype = null;
    return result;
  };

  var property = function(key) {
    return function(obj) {
      return obj == null ? void 0 : obj[key];
    };
  };

  // Helper for collection methods to determine whether a collection
  // should be iterated as an array or as an object
  // Related: http://people.mozilla.org/~jorendorff/es6-draft.html#sec-tolength
  // Avoids a very nasty iOS 8 JIT bug on ARM-64. #2094
  var MAX_ARRAY_INDEX = Math.pow(2, 53) - 1;
  var getLength = property('length');
  var isArrayLike = function(collection) {
    var length = getLength(collection);
    return typeof length == 'number' && length >= 0 && length <= MAX_ARRAY_INDEX;
  };

  // Collection Functions
  // --------------------

  // The cornerstone, an `each` implementation, aka `forEach`.
  // Handles raw objects in addition to array-likes. Treats all
  // sparse array-likes as if they were dense.
  _.each = _.forEach = function(obj, iteratee, context) {
    iteratee = optimizeCb(iteratee, context);
    var i, length;
    if (isArrayLike(obj)) {
      for (i = 0, length = obj.length; i < length; i++) {
        iteratee(obj[i], i, obj);
      }
    } else {
      var keys = _.keys(obj);
      for (i = 0, length = keys.length; i < length; i++) {
        iteratee(obj[keys[i]], keys[i], obj);
      }
    }
    return obj;
  };

  // Return the results of applying the iteratee to each element.
  _.map = _.collect = function(obj, iteratee, context) {
    iteratee = cb(iteratee, context);
    var keys = !isArrayLike(obj) && _.keys(obj),
        length = (keys || obj).length,
        results = Array(length);
    for (var index = 0; index < length; index++) {
      var currentKey = keys ? keys[index] : index;
      results[index] = iteratee(obj[currentKey], currentKey, obj);
    }
    return results;
  };

  // Create a reducing function iterating left or right.
  function createReduce(dir) {
    // Optimized iterator function as using arguments.length
    // in the main function will deoptimize the, see #1991.
    function iterator(obj, iteratee, memo, keys, index, length) {
      for (; index >= 0 && index < length; index += dir) {
        var currentKey = keys ? keys[index] : index;
        memo = iteratee(memo, obj[currentKey], currentKey, obj);
      }
      return memo;
    }

    return function(obj, iteratee, memo, context) {
      iteratee = optimizeCb(iteratee, context, 4);
      var keys = !isArrayLike(obj) && _.keys(obj),
          length = (keys || obj).length,
          index = dir > 0 ? 0 : length - 1;
      // Determine the initial value if none is provided.
      if (arguments.length < 3) {
        memo = obj[keys ? keys[index] : index];
        index += dir;
      }
      return iterator(obj, iteratee, memo, keys, index, length);
    };
  }

  // **Reduce** builds up a single result from a list of values, aka `inject`,
  // or `foldl`.
  _.reduce = _.foldl = _.inject = createReduce(1);

  // The right-associative version of reduce, also known as `foldr`.
  _.reduceRight = _.foldr = createReduce(-1);

  // Return the first value which passes a truth test. Aliased as `detect`.
  _.find = _.detect = function(obj, predicate, context) {
    var key;
    if (isArrayLike(obj)) {
      key = _.findIndex(obj, predicate, context);
    } else {
      key = _.findKey(obj, predicate, context);
    }
    if (key !== void 0 && key !== -1) return obj[key];
  };

  // Return all the elements that pass a truth test.
  // Aliased as `select`.
  _.filter = _.select = function(obj, predicate, context) {
    var results = [];
    predicate = cb(predicate, context);
    _.each(obj, function(value, index, list) {
      if (predicate(value, index, list)) results.push(value);
    });
    return results;
  };

  // Return all the elements for which a truth test fails.
  _.reject = function(obj, predicate, context) {
    return _.filter(obj, _.negate(cb(predicate)), context);
  };

  // Determine whether all of the elements match a truth test.
  // Aliased as `all`.
  _.every = _.all = function(obj, predicate, context) {
    predicate = cb(predicate, context);
    var keys = !isArrayLike(obj) && _.keys(obj),
        length = (keys || obj).length;
    for (var index = 0; index < length; index++) {
      var currentKey = keys ? keys[index] : index;
      if (!predicate(obj[currentKey], currentKey, obj)) return false;
    }
    return true;
  };

  // Determine if at least one element in the object matches a truth test.
  // Aliased as `any`.
  _.some = _.any = function(obj, predicate, context) {
    predicate = cb(predicate, context);
    var keys = !isArrayLike(obj) && _.keys(obj),
        length = (keys || obj).length;
    for (var index = 0; index < length; index++) {
      var currentKey = keys ? keys[index] : index;
      if (predicate(obj[currentKey], currentKey, obj)) return true;
    }
    return false;
  };

  // Determine if the array or object contains a given item (using `===`).
  // Aliased as `includes` and `include`.
  _.contains = _.includes = _.include = function(obj, item, fromIndex, guard) {
    if (!isArrayLike(obj)) obj = _.values(obj);
    if (typeof fromIndex != 'number' || guard) fromIndex = 0;
    return _.indexOf(obj, item, fromIndex) >= 0;
  };

  // Invoke a method (with arguments) on every item in a collection.
  _.invoke = function(obj, method) {
    var args = slice.call(arguments, 2);
    var isFunc = _.isFunction(method);
    return _.map(obj, function(value) {
      var func = isFunc ? method : value[method];
      return func == null ? func : func.apply(value, args);
    });
  };

  // Convenience version of a common use case of `map`: fetching a property.
  _.pluck = function(obj, key) {
    return _.map(obj, _.property(key));
  };

  // Convenience version of a common use case of `filter`: selecting only objects
  // containing specific `key:value` pairs.
  _.where = function(obj, attrs) {
    return _.filter(obj, _.matcher(attrs));
  };

  // Convenience version of a common use case of `find`: getting the first object
  // containing specific `key:value` pairs.
  _.findWhere = function(obj, attrs) {
    return _.find(obj, _.matcher(attrs));
  };

  // Return the maximum element (or element-based computation).
  _.max = function(obj, iteratee, context) {
    var result = -Infinity, lastComputed = -Infinity,
        value, computed;
    if (iteratee == null && obj != null) {
      obj = isArrayLike(obj) ? obj : _.values(obj);
      for (var i = 0, length = obj.length; i < length; i++) {
        value = obj[i];
        if (value > result) {
          result = value;
        }
      }
    } else {
      iteratee = cb(iteratee, context);
      _.each(obj, function(value, index, list) {
        computed = iteratee(value, index, list);
        if (computed > lastComputed || computed === -Infinity && result === -Infinity) {
          result = value;
          lastComputed = computed;
        }
      });
    }
    return result;
  };

  // Return the minimum element (or element-based computation).
  _.min = function(obj, iteratee, context) {
    var result = Infinity, lastComputed = Infinity,
        value, computed;
    if (iteratee == null && obj != null) {
      obj = isArrayLike(obj) ? obj : _.values(obj);
      for (var i = 0, length = obj.length; i < length; i++) {
        value = obj[i];
        if (value < result) {
          result = value;
        }
      }
    } else {
      iteratee = cb(iteratee, context);
      _.each(obj, function(value, index, list) {
        computed = iteratee(value, index, list);
        if (computed < lastComputed || computed === Infinity && result === Infinity) {
          result = value;
          lastComputed = computed;
        }
      });
    }
    return result;
  };

  // Shuffle a collection, using the modern version of the
  // [Fisher-Yates shuffle](http://en.wikipedia.org/wiki/Fisher–Yates_shuffle).
  _.shuffle = function(obj) {
    var set = isArrayLike(obj) ? obj : _.values(obj);
    var length = set.length;
    var shuffled = Array(length);
    for (var index = 0, rand; index < length; index++) {
      rand = _.random(0, index);
      if (rand !== index) shuffled[index] = shuffled[rand];
      shuffled[rand] = set[index];
    }
    return shuffled;
  };

  // Sample **n** random values from a collection.
  // If **n** is not specified, returns a single random element.
  // The internal `guard` argument allows it to work with `map`.
  _.sample = function(obj, n, guard) {
    if (n == null || guard) {
      if (!isArrayLike(obj)) obj = _.values(obj);
      return obj[_.random(obj.length - 1)];
    }
    return _.shuffle(obj).slice(0, Math.max(0, n));
  };

  // Sort the object's values by a criterion produced by an iteratee.
  _.sortBy = function(obj, iteratee, context) {
    iteratee = cb(iteratee, context);
    return _.pluck(_.map(obj, function(value, index, list) {
      return {
        value: value,
        index: index,
        criteria: iteratee(value, index, list)
      };
    }).sort(function(left, right) {
      var a = left.criteria;
      var b = right.criteria;
      if (a !== b) {
        if (a > b || a === void 0) return 1;
        if (a < b || b === void 0) return -1;
      }
      return left.index - right.index;
    }), 'value');
  };

  // An internal function used for aggregate "group by" operations.
  var group = function(behavior) {
    return function(obj, iteratee, context) {
      var result = {};
      iteratee = cb(iteratee, context);
      _.each(obj, function(value, index) {
        var key = iteratee(value, index, obj);
        behavior(result, value, key);
      });
      return result;
    };
  };

  // Groups the object's values by a criterion. Pass either a string attribute
  // to group by, or a function that returns the criterion.
  _.groupBy = group(function(result, value, key) {
    if (_.has(result, key)) result[key].push(value); else result[key] = [value];
  });

  // Indexes the object's values by a criterion, similar to `groupBy`, but for
  // when you know that your index values will be unique.
  _.indexBy = group(function(result, value, key) {
    result[key] = value;
  });

  // Counts instances of an object that group by a certain criterion. Pass
  // either a string attribute to count by, or a function that returns the
  // criterion.
  _.countBy = group(function(result, value, key) {
    if (_.has(result, key)) result[key]++; else result[key] = 1;
  });

  // Safely create a real, live array from anything iterable.
  _.toArray = function(obj) {
    if (!obj) return [];
    if (_.isArray(obj)) return slice.call(obj);
    if (isArrayLike(obj)) return _.map(obj, _.identity);
    return _.values(obj);
  };

  // Return the number of elements in an object.
  _.size = function(obj) {
    if (obj == null) return 0;
    return isArrayLike(obj) ? obj.length : _.keys(obj).length;
  };

  // Split a collection into two arrays: one whose elements all satisfy the given
  // predicate, and one whose elements all do not satisfy the predicate.
  _.partition = function(obj, predicate, context) {
    predicate = cb(predicate, context);
    var pass = [], fail = [];
    _.each(obj, function(value, key, obj) {
      (predicate(value, key, obj) ? pass : fail).push(value);
    });
    return [pass, fail];
  };

  // Array Functions
  // ---------------

  // Get the first element of an array. Passing **n** will return the first N
  // values in the array. Aliased as `head` and `take`. The **guard** check
  // allows it to work with `_.map`.
  _.first = _.head = _.take = function(array, n, guard) {
    if (array == null) return void 0;
    if (n == null || guard) return array[0];
    return _.initial(array, array.length - n);
  };

  // Returns everything but the last entry of the array. Especially useful on
  // the arguments object. Passing **n** will return all the values in
  // the array, excluding the last N.
  _.initial = function(array, n, guard) {
    return slice.call(array, 0, Math.max(0, array.length - (n == null || guard ? 1 : n)));
  };

  // Get the last element of an array. Passing **n** will return the last N
  // values in the array.
  _.last = function(array, n, guard) {
    if (array == null) return void 0;
    if (n == null || guard) return array[array.length - 1];
    return _.rest(array, Math.max(0, array.length - n));
  };

  // Returns everything but the first entry of the array. Aliased as `tail` and `drop`.
  // Especially useful on the arguments object. Passing an **n** will return
  // the rest N values in the array.
  _.rest = _.tail = _.drop = function(array, n, guard) {
    return slice.call(array, n == null || guard ? 1 : n);
  };

  // Trim out all falsy values from an array.
  _.compact = function(array) {
    return _.filter(array, _.identity);
  };

  // Internal implementation of a recursive `flatten` function.
  var flatten = function(input, shallow, strict, startIndex) {
    var output = [], idx = 0;
    for (var i = startIndex || 0, length = getLength(input); i < length; i++) {
      var value = input[i];
      if (isArrayLike(value) && (_.isArray(value) || _.isArguments(value))) {
        //flatten current level of array or arguments object
        if (!shallow) value = flatten(value, shallow, strict);
        var j = 0, len = value.length;
        output.length += len;
        while (j < len) {
          output[idx++] = value[j++];
        }
      } else if (!strict) {
        output[idx++] = value;
      }
    }
    return output;
  };

  // Flatten out an array, either recursively (by default), or just one level.
  _.flatten = function(array, shallow) {
    return flatten(array, shallow, false);
  };

  // Return a version of the array that does not contain the specified value(s).
  _.without = function(array) {
    return _.difference(array, slice.call(arguments, 1));
  };

  // Produce a duplicate-free version of the array. If the array has already
  // been sorted, you have the option of using a faster algorithm.
  // Aliased as `unique`.
  _.uniq = _.unique = function(array, isSorted, iteratee, context) {
    if (!_.isBoolean(isSorted)) {
      context = iteratee;
      iteratee = isSorted;
      isSorted = false;
    }
    if (iteratee != null) iteratee = cb(iteratee, context);
    var result = [];
    var seen = [];
    for (var i = 0, length = getLength(array); i < length; i++) {
      var value = array[i],
          computed = iteratee ? iteratee(value, i, array) : value;
      if (isSorted) {
        if (!i || seen !== computed) result.push(value);
        seen = computed;
      } else if (iteratee) {
        if (!_.contains(seen, computed)) {
          seen.push(computed);
          result.push(value);
        }
      } else if (!_.contains(result, value)) {
        result.push(value);
      }
    }
    return result;
  };

  // Produce an array that contains the union: each distinct element from all of
  // the passed-in arrays.
  _.union = function() {
    return _.uniq(flatten(arguments, true, true));
  };

  // Produce an array that contains every item shared between all the
  // passed-in arrays.
  _.intersection = function(array) {
    var result = [];
    var argsLength = arguments.length;
    for (var i = 0, length = getLength(array); i < length; i++) {
      var item = array[i];
      if (_.contains(result, item)) continue;
      for (var j = 1; j < argsLength; j++) {
        if (!_.contains(arguments[j], item)) break;
      }
      if (j === argsLength) result.push(item);
    }
    return result;
  };

  // Take the difference between one array and a number of other arrays.
  // Only the elements present in just the first array will remain.
  _.difference = function(array) {
    var rest = flatten(arguments, true, true, 1);
    return _.filter(array, function(value){
      return !_.contains(rest, value);
    });
  };

  // Zip together multiple lists into a single array -- elements that share
  // an index go together.
  _.zip = function() {
    return _.unzip(arguments);
  };

  // Complement of _.zip. Unzip accepts an array of arrays and groups
  // each array's elements on shared indices
  _.unzip = function(array) {
    var length = array && _.max(array, getLength).length || 0;
    var result = Array(length);

    for (var index = 0; index < length; index++) {
      result[index] = _.pluck(array, index);
    }
    return result;
  };

  // Converts lists into objects. Pass either a single array of `[key, value]`
  // pairs, or two parallel arrays of the same length -- one of keys, and one of
  // the corresponding values.
  _.object = function(list, values) {
    var result = {};
    for (var i = 0, length = getLength(list); i < length; i++) {
      if (values) {
        result[list[i]] = values[i];
      } else {
        result[list[i][0]] = list[i][1];
      }
    }
    return result;
  };

  // Generator function to create the findIndex and findLastIndex functions
  function createPredicateIndexFinder(dir) {
    return function(array, predicate, context) {
      predicate = cb(predicate, context);
      var length = getLength(array);
      var index = dir > 0 ? 0 : length - 1;
      for (; index >= 0 && index < length; index += dir) {
        if (predicate(array[index], index, array)) return index;
      }
      return -1;
    };
  }

  // Returns the first index on an array-like that passes a predicate test
  _.findIndex = createPredicateIndexFinder(1);
  _.findLastIndex = createPredicateIndexFinder(-1);

  // Use a comparator function to figure out the smallest index at which
  // an object should be inserted so as to maintain order. Uses binary search.
  _.sortedIndex = function(array, obj, iteratee, context) {
    iteratee = cb(iteratee, context, 1);
    var value = iteratee(obj);
    var low = 0, high = getLength(array);
    while (low < high) {
      var mid = Math.floor((low + high) / 2);
      if (iteratee(array[mid]) < value) low = mid + 1; else high = mid;
    }
    return low;
  };

  // Generator function to create the indexOf and lastIndexOf functions
  function createIndexFinder(dir, predicateFind, sortedIndex) {
    return function(array, item, idx) {
      var i = 0, length = getLength(array);
      if (typeof idx == 'number') {
        if (dir > 0) {
            i = idx >= 0 ? idx : Math.max(idx + length, i);
        } else {
            length = idx >= 0 ? Math.min(idx + 1, length) : idx + length + 1;
        }
      } else if (sortedIndex && idx && length) {
        idx = sortedIndex(array, item);
        return array[idx] === item ? idx : -1;
      }
      if (item !== item) {
        idx = predicateFind(slice.call(array, i, length), _.isNaN);
        return idx >= 0 ? idx + i : -1;
      }
      for (idx = dir > 0 ? i : length - 1; idx >= 0 && idx < length; idx += dir) {
        if (array[idx] === item) return idx;
      }
      return -1;
    };
  }

  // Return the position of the first occurrence of an item in an array,
  // or -1 if the item is not included in the array.
  // If the array is large and already in sort order, pass `true`
  // for **isSorted** to use binary search.
  _.indexOf = createIndexFinder(1, _.findIndex, _.sortedIndex);
  _.lastIndexOf = createIndexFinder(-1, _.findLastIndex);

  // Generate an integer Array containing an arithmetic progression. A port of
  // the native Python `range()` function. See
  // [the Python documentation](http://docs.python.org/library/functions.html#range).
  _.range = function(start, stop, step) {
    if (stop == null) {
      stop = start || 0;
      start = 0;
    }
    step = step || 1;

    var length = Math.max(Math.ceil((stop - start) / step), 0);
    var range = Array(length);

    for (var idx = 0; idx < length; idx++, start += step) {
      range[idx] = start;
    }

    return range;
  };

  // Function (ahem) Functions
  // ------------------

  // Determines whether to execute a function as a constructor
  // or a normal function with the provided arguments
  var executeBound = function(sourceFunc, boundFunc, context, callingContext, args) {
    if (!(callingContext instanceof boundFunc)) return sourceFunc.apply(context, args);
    var self = baseCreate(sourceFunc.prototype);
    var result = sourceFunc.apply(self, args);
    if (_.isObject(result)) return result;
    return self;
  };

  // Create a function bound to a given object (assigning `this`, and arguments,
  // optionally). Delegates to **ECMAScript 5**'s native `Function.bind` if
  // available.
  _.bind = function(func, context) {
    if (nativeBind && func.bind === nativeBind) return nativeBind.apply(func, slice.call(arguments, 1));
    if (!_.isFunction(func)) throw new TypeError('Bind must be called on a function');
    var args = slice.call(arguments, 2);
    var bound = function() {
      return executeBound(func, bound, context, this, args.concat(slice.call(arguments)));
    };
    return bound;
  };

  // Partially apply a function by creating a version that has had some of its
  // arguments pre-filled, without changing its dynamic `this` context. _ acts
  // as a placeholder, allowing any combination of arguments to be pre-filled.
  _.partial = function(func) {
    var boundArgs = slice.call(arguments, 1);
    var bound = function() {
      var position = 0, length = boundArgs.length;
      var args = Array(length);
      for (var i = 0; i < length; i++) {
        args[i] = boundArgs[i] === _ ? arguments[position++] : boundArgs[i];
      }
      while (position < arguments.length) args.push(arguments[position++]);
      return executeBound(func, bound, this, this, args);
    };
    return bound;
  };

  // Bind a number of an object's methods to that object. Remaining arguments
  // are the method names to be bound. Useful for ensuring that all callbacks
  // defined on an object belong to it.
  _.bindAll = function(obj) {
    var i, length = arguments.length, key;
    if (length <= 1) throw new Error('bindAll must be passed function names');
    for (i = 1; i < length; i++) {
      key = arguments[i];
      obj[key] = _.bind(obj[key], obj);
    }
    return obj;
  };

  // Memoize an expensive function by storing its results.
  _.memoize = function(func, hasher) {
    var memoize = function(key) {
      var cache = memoize.cache;
      var address = '' + (hasher ? hasher.apply(this, arguments) : key);
      if (!_.has(cache, address)) cache[address] = func.apply(this, arguments);
      return cache[address];
    };
    memoize.cache = {};
    return memoize;
  };

  // Delays a function for the given number of milliseconds, and then calls
  // it with the arguments supplied.
  _.delay = function(func, wait) {
    var args = slice.call(arguments, 2);
    return setTimeout(function(){
      return func.apply(null, args);
    }, wait);
  };

  // Defers a function, scheduling it to run after the current call stack has
  // cleared.
  _.defer = _.partial(_.delay, _, 1);

  // Returns a function, that, when invoked, will only be triggered at most once
  // during a given window of time. Normally, the throttled function will run
  // as much as it can, without ever going more than once per `wait` duration;
  // but if you'd like to disable the execution on the leading edge, pass
  // `{leading: false}`. To disable execution on the trailing edge, ditto.
  _.throttle = function(func, wait, options) {
    var context, args, result;
    var timeout = null;
    var previous = 0;
    if (!options) options = {};
    var later = function() {
      previous = options.leading === false ? 0 : _.now();
      timeout = null;
      result = func.apply(context, args);
      if (!timeout) context = args = null;
    };
    return function() {
      var now = _.now();
      if (!previous && options.leading === false) previous = now;
      var remaining = wait - (now - previous);
      context = this;
      args = arguments;
      if (remaining <= 0 || remaining > wait) {
        if (timeout) {
          clearTimeout(timeout);
          timeout = null;
        }
        previous = now;
        result = func.apply(context, args);
        if (!timeout) context = args = null;
      } else if (!timeout && options.trailing !== false) {
        timeout = setTimeout(later, remaining);
      }
      return result;
    };
  };

  // Returns a function, that, as long as it continues to be invoked, will not
  // be triggered. The function will be called after it stops being called for
  // N milliseconds. If `immediate` is passed, trigger the function on the
  // leading edge, instead of the trailing.
  _.debounce = function(func, wait, immediate) {
    var timeout, args, context, timestamp, result;

    var later = function() {
      var last = _.now() - timestamp;

      if (last < wait && last >= 0) {
        timeout = setTimeout(later, wait - last);
      } else {
        timeout = null;
        if (!immediate) {
          result = func.apply(context, args);
          if (!timeout) context = args = null;
        }
      }
    };

    return function() {
      context = this;
      args = arguments;
      timestamp = _.now();
      var callNow = immediate && !timeout;
      if (!timeout) timeout = setTimeout(later, wait);
      if (callNow) {
        result = func.apply(context, args);
        context = args = null;
      }

      return result;
    };
  };

  // Returns the first function passed as an argument to the second,
  // allowing you to adjust arguments, run code before and after, and
  // conditionally execute the original function.
  _.wrap = function(func, wrapper) {
    return _.partial(wrapper, func);
  };

  // Returns a negated version of the passed-in predicate.
  _.negate = function(predicate) {
    return function() {
      return !predicate.apply(this, arguments);
    };
  };

  // Returns a function that is the composition of a list of functions, each
  // consuming the return value of the function that follows.
  _.compose = function() {
    var args = arguments;
    var start = args.length - 1;
    return function() {
      var i = start;
      var result = args[start].apply(this, arguments);
      while (i--) result = args[i].call(this, result);
      return result;
    };
  };

  // Returns a function that will only be executed on and after the Nth call.
  _.after = function(times, func) {
    return function() {
      if (--times < 1) {
        return func.apply(this, arguments);
      }
    };
  };

  // Returns a function that will only be executed up to (but not including) the Nth call.
  _.before = function(times, func) {
    var memo;
    return function() {
      if (--times > 0) {
        memo = func.apply(this, arguments);
      }
      if (times <= 1) func = null;
      return memo;
    };
  };

  // Returns a function that will be executed at most one time, no matter how
  // often you call it. Useful for lazy initialization.
  _.once = _.partial(_.before, 2);

  // Object Functions
  // ----------------

  // Keys in IE < 9 that won't be iterated by `for key in ...` and thus missed.
  var hasEnumBug = !{toString: null}.propertyIsEnumerable('toString');
  var nonEnumerableProps = ['valueOf', 'isPrototypeOf', 'toString',
                      'propertyIsEnumerable', 'hasOwnProperty', 'toLocaleString'];

  function collectNonEnumProps(obj, keys) {
    var nonEnumIdx = nonEnumerableProps.length;
    var constructor = obj.constructor;
    var proto = (_.isFunction(constructor) && constructor.prototype) || ObjProto;

    // Constructor is a special case.
    var prop = 'constructor';
    if (_.has(obj, prop) && !_.contains(keys, prop)) keys.push(prop);

    while (nonEnumIdx--) {
      prop = nonEnumerableProps[nonEnumIdx];
      if (prop in obj && obj[prop] !== proto[prop] && !_.contains(keys, prop)) {
        keys.push(prop);
      }
    }
  }

  // Retrieve the names of an object's own properties.
  // Delegates to **ECMAScript 5**'s native `Object.keys`
  _.keys = function(obj) {
    if (!_.isObject(obj)) return [];
    if (nativeKeys) return nativeKeys(obj);
    var keys = [];
    for (var key in obj) if (_.has(obj, key)) keys.push(key);
    // Ahem, IE < 9.
    if (hasEnumBug) collectNonEnumProps(obj, keys);
    return keys;
  };

  // Retrieve all the property names of an object.
  _.allKeys = function(obj) {
    if (!_.isObject(obj)) return [];
    var keys = [];
    for (var key in obj) keys.push(key);
    // Ahem, IE < 9.
    if (hasEnumBug) collectNonEnumProps(obj, keys);
    return keys;
  };

  // Retrieve the values of an object's properties.
  _.values = function(obj) {
    var keys = _.keys(obj);
    var length = keys.length;
    var values = Array(length);
    for (var i = 0; i < length; i++) {
      values[i] = obj[keys[i]];
    }
    return values;
  };

  // Returns the results of applying the iteratee to each element of the object
  // In contrast to _.map it returns an object
  _.mapObject = function(obj, iteratee, context) {
    iteratee = cb(iteratee, context);
    var keys =  _.keys(obj),
          length = keys.length,
          results = {},
          currentKey;
      for (var index = 0; index < length; index++) {
        currentKey = keys[index];
        results[currentKey] = iteratee(obj[currentKey], currentKey, obj);
      }
      return results;
  };

  // Convert an object into a list of `[key, value]` pairs.
  _.pairs = function(obj) {
    var keys = _.keys(obj);
    var length = keys.length;
    var pairs = Array(length);
    for (var i = 0; i < length; i++) {
      pairs[i] = [keys[i], obj[keys[i]]];
    }
    return pairs;
  };

  // Invert the keys and values of an object. The values must be serializable.
  _.invert = function(obj) {
    var result = {};
    var keys = _.keys(obj);
    for (var i = 0, length = keys.length; i < length; i++) {
      result[obj[keys[i]]] = keys[i];
    }
    return result;
  };

  // Return a sorted list of the function names available on the object.
  // Aliased as `methods`
  _.functions = _.methods = function(obj) {
    var names = [];
    for (var key in obj) {
      if (_.isFunction(obj[key])) names.push(key);
    }
    return names.sort();
  };

  // Extend a given object with all the properties in passed-in object(s).
  _.extend = createAssigner(_.allKeys);

  // Assigns a given object with all the own properties in the passed-in object(s)
  // (https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object/assign)
  _.extendOwn = _.assign = createAssigner(_.keys);

  // Returns the first key on an object that passes a predicate test
  _.findKey = function(obj, predicate, context) {
    predicate = cb(predicate, context);
    var keys = _.keys(obj), key;
    for (var i = 0, length = keys.length; i < length; i++) {
      key = keys[i];
      if (predicate(obj[key], key, obj)) return key;
    }
  };

  // Return a copy of the object only containing the whitelisted properties.
  _.pick = function(object, oiteratee, context) {
    var result = {}, obj = object, iteratee, keys;
    if (obj == null) return result;
    if (_.isFunction(oiteratee)) {
      keys = _.allKeys(obj);
      iteratee = optimizeCb(oiteratee, context);
    } else {
      keys = flatten(arguments, false, false, 1);
      iteratee = function(value, key, obj) { return key in obj; };
      obj = Object(obj);
    }
    for (var i = 0, length = keys.length; i < length; i++) {
      var key = keys[i];
      var value = obj[key];
      if (iteratee(value, key, obj)) result[key] = value;
    }
    return result;
  };

   // Return a copy of the object without the blacklisted properties.
  _.omit = function(obj, iteratee, context) {
    if (_.isFunction(iteratee)) {
      iteratee = _.negate(iteratee);
    } else {
      var keys = _.map(flatten(arguments, false, false, 1), String);
      iteratee = function(value, key) {
        return !_.contains(keys, key);
      };
    }
    return _.pick(obj, iteratee, context);
  };

  // Fill in a given object with default properties.
  _.defaults = createAssigner(_.allKeys, true);

  // Creates an object that inherits from the given prototype object.
  // If additional properties are provided then they will be added to the
  // created object.
  _.create = function(prototype, props) {
    var result = baseCreate(prototype);
    if (props) _.extendOwn(result, props);
    return result;
  };

  // Create a (shallow-cloned) duplicate of an object.
  _.clone = function(obj) {
    if (!_.isObject(obj)) return obj;
    return _.isArray(obj) ? obj.slice() : _.extend({}, obj);
  };

  // Invokes interceptor with the obj, and then returns obj.
  // The primary purpose of this method is to "tap into" a method chain, in
  // order to perform operations on intermediate results within the chain.
  _.tap = function(obj, interceptor) {
    interceptor(obj);
    return obj;
  };

  // Returns whether an object has a given set of `key:value` pairs.
  _.isMatch = function(object, attrs) {
    var keys = _.keys(attrs), length = keys.length;
    if (object == null) return !length;
    var obj = Object(object);
    for (var i = 0; i < length; i++) {
      var key = keys[i];
      if (attrs[key] !== obj[key] || !(key in obj)) return false;
    }
    return true;
  };


  // Internal recursive comparison function for `isEqual`.
  var eq = function(a, b, aStack, bStack) {
    // Identical objects are equal. `0 === -0`, but they aren't identical.
    // See the [Harmony `egal` proposal](http://wiki.ecmascript.org/doku.php?id=harmony:egal).
    if (a === b) return a !== 0 || 1 / a === 1 / b;
    // A strict comparison is necessary because `null == undefined`.
    if (a == null || b == null) return a === b;
    // Unwrap any wrapped objects.
    if (a instanceof _) a = a._wrapped;
    if (b instanceof _) b = b._wrapped;
    // Compare `[[Class]]` names.
    var className = toString.call(a);
    if (className !== toString.call(b)) return false;
    switch (className) {
      // Strings, numbers, regular expressions, dates, and booleans are compared by value.
      case '[object RegExp]':
      // RegExps are coerced to strings for comparison (Note: '' + /a/i === '/a/i')
      case '[object String]':
        // Primitives and their corresponding object wrappers are equivalent; thus, `"5"` is
        // equivalent to `new String("5")`.
        return '' + a === '' + b;
      case '[object Number]':
        // `NaN`s are equivalent, but non-reflexive.
        // Object(NaN) is equivalent to NaN
        if (+a !== +a) return +b !== +b;
        // An `egal` comparison is performed for other numeric values.
        return +a === 0 ? 1 / +a === 1 / b : +a === +b;
      case '[object Date]':
      case '[object Boolean]':
        // Coerce dates and booleans to numeric primitive values. Dates are compared by their
        // millisecond representations. Note that invalid dates with millisecond representations
        // of `NaN` are not equivalent.
        return +a === +b;
    }

    var areArrays = className === '[object Array]';
    if (!areArrays) {
      if (typeof a != 'object' || typeof b != 'object') return false;

      // Objects with different constructors are not equivalent, but `Object`s or `Array`s
      // from different frames are.
      var aCtor = a.constructor, bCtor = b.constructor;
      if (aCtor !== bCtor && !(_.isFunction(aCtor) && aCtor instanceof aCtor &&
                               _.isFunction(bCtor) && bCtor instanceof bCtor)
                          && ('constructor' in a && 'constructor' in b)) {
        return false;
      }
    }
    // Assume equality for cyclic structures. The algorithm for detecting cyclic
    // structures is adapted from ES 5.1 section 15.12.3, abstract operation `JO`.

    // Initializing stack of traversed objects.
    // It's done here since we only need them for objects and arrays comparison.
    aStack = aStack || [];
    bStack = bStack || [];
    var length = aStack.length;
    while (length--) {
      // Linear search. Performance is inversely proportional to the number of
      // unique nested structures.
      if (aStack[length] === a) return bStack[length] === b;
    }

    // Add the first object to the stack of traversed objects.
    aStack.push(a);
    bStack.push(b);

    // Recursively compare objects and arrays.
    if (areArrays) {
      // Compare array lengths to determine if a deep comparison is necessary.
      length = a.length;
      if (length !== b.length) return false;
      // Deep compare the contents, ignoring non-numeric properties.
      while (length--) {
        if (!eq(a[length], b[length], aStack, bStack)) return false;
      }
    } else {
      // Deep compare objects.
      var keys = _.keys(a), key;
      length = keys.length;
      // Ensure that both objects contain the same number of properties before comparing deep equality.
      if (_.keys(b).length !== length) return false;
      while (length--) {
        // Deep compare each member
        key = keys[length];
        if (!(_.has(b, key) && eq(a[key], b[key], aStack, bStack))) return false;
      }
    }
    // Remove the first object from the stack of traversed objects.
    aStack.pop();
    bStack.pop();
    return true;
  };

  // Perform a deep comparison to check if two objects are equal.
  _.isEqual = function(a, b) {
    return eq(a, b);
  };

  // Is a given array, string, or object empty?
  // An "empty" object has no enumerable own-properties.
  _.isEmpty = function(obj) {
    if (obj == null) return true;
    if (isArrayLike(obj) && (_.isArray(obj) || _.isString(obj) || _.isArguments(obj))) return obj.length === 0;
    return _.keys(obj).length === 0;
  };

  // Is a given value a DOM element?
  _.isElement = function(obj) {
    return !!(obj && obj.nodeType === 1);
  };

  // Is a given value an array?
  // Delegates to ECMA5's native Array.isArray
  _.isArray = nativeIsArray || function(obj) {
    return toString.call(obj) === '[object Array]';
  };

  // Is a given variable an object?
  _.isObject = function(obj) {
    var type = typeof obj;
    return type === 'function' || type === 'object' && !!obj;
  };

  // Add some isType methods: isArguments, isFunction, isString, isNumber, isDate, isRegExp, isError.
  _.each(['Arguments', 'Function', 'String', 'Number', 'Date', 'RegExp', 'Error'], function(name) {
    _['is' + name] = function(obj) {
      return toString.call(obj) === '[object ' + name + ']';
    };
  });

  // Define a fallback version of the method in browsers (ahem, IE < 9), where
  // there isn't any inspectable "Arguments" type.
  if (!_.isArguments(arguments)) {
    _.isArguments = function(obj) {
      return _.has(obj, 'callee');
    };
  }

  // Optimize `isFunction` if appropriate. Work around some typeof bugs in old v8,
  // IE 11 (#1621), and in Safari 8 (#1929).
  if (typeof /./ != 'function' && typeof Int8Array != 'object') {
    _.isFunction = function(obj) {
      return typeof obj == 'function' || false;
    };
  }

  // Is a given object a finite number?
  _.isFinite = function(obj) {
    return isFinite(obj) && !isNaN(parseFloat(obj));
  };

  // Is the given value `NaN`? (NaN is the only number which does not equal itself).
  _.isNaN = function(obj) {
    return _.isNumber(obj) && obj !== +obj;
  };

  // Is a given value a boolean?
  _.isBoolean = function(obj) {
    return obj === true || obj === false || toString.call(obj) === '[object Boolean]';
  };

  // Is a given value equal to null?
  _.isNull = function(obj) {
    return obj === null;
  };

  // Is a given variable undefined?
  _.isUndefined = function(obj) {
    return obj === void 0;
  };

  // Shortcut function for checking if an object has a given property directly
  // on itself (in other words, not on a prototype).
  _.has = function(obj, key) {
    return obj != null && hasOwnProperty.call(obj, key);
  };

  // Utility Functions
  // -----------------

  // Run Underscore.js in *noConflict* mode, returning the `_` variable to its
  // previous owner. Returns a reference to the Underscore object.
  _.noConflict = function() {
    root._ = previousUnderscore;
    return this;
  };

  // Keep the identity function around for default iteratees.
  _.identity = function(value) {
    return value;
  };

  // Predicate-generating functions. Often useful outside of Underscore.
  _.constant = function(value) {
    return function() {
      return value;
    };
  };

  _.noop = function(){};

  _.property = property;

  // Generates a function for a given object that returns a given property.
  _.propertyOf = function(obj) {
    return obj == null ? function(){} : function(key) {
      return obj[key];
    };
  };

  // Returns a predicate for checking whether an object has a given set of
  // `key:value` pairs.
  _.matcher = _.matches = function(attrs) {
    attrs = _.extendOwn({}, attrs);
    return function(obj) {
      return _.isMatch(obj, attrs);
    };
  };

  // Run a function **n** times.
  _.times = function(n, iteratee, context) {
    var accum = Array(Math.max(0, n));
    iteratee = optimizeCb(iteratee, context, 1);
    for (var i = 0; i < n; i++) accum[i] = iteratee(i);
    return accum;
  };

  // Return a random integer between min and max (inclusive).
  _.random = function(min, max) {
    if (max == null) {
      max = min;
      min = 0;
    }
    return min + Math.floor(Math.random() * (max - min + 1));
  };

  // A (possibly faster) way to get the current timestamp as an integer.
  _.now = Date.now || function() {
    return new Date().getTime();
  };

   // List of HTML entities for escaping.
  var escapeMap = {
    '&': '&amp;',
    '<': '&lt;',
    '>': '&gt;',
    '"': '&quot;',
    "'": '&#x27;',
    '`': '&#x60;'
  };
  var unescapeMap = _.invert(escapeMap);

  // Functions for escaping and unescaping strings to/from HTML interpolation.
  var createEscaper = function(map) {
    var escaper = function(match) {
      return map[match];
    };
    // Regexes for identifying a key that needs to be escaped
    var source = '(?:' + _.keys(map).join('|') + ')';
    var testRegexp = RegExp(source);
    var replaceRegexp = RegExp(source, 'g');
    return function(string) {
      string = string == null ? '' : '' + string;
      return testRegexp.test(string) ? string.replace(replaceRegexp, escaper) : string;
    };
  };
  _.escape = createEscaper(escapeMap);
  _.unescape = createEscaper(unescapeMap);

  // If the value of the named `property` is a function then invoke it with the
  // `object` as context; otherwise, return it.
  _.result = function(object, property, fallback) {
    var value = object == null ? void 0 : object[property];
    if (value === void 0) {
      value = fallback;
    }
    return _.isFunction(value) ? value.call(object) : value;
  };

  // Generate a unique integer id (unique within the entire client session).
  // Useful for temporary DOM ids.
  var idCounter = 0;
  _.uniqueId = function(prefix) {
    var id = ++idCounter + '';
    return prefix ? prefix + id : id;
  };

  // By default, Underscore uses ERB-style template delimiters, change the
  // following template settings to use alternative delimiters.
  _.templateSettings = {
    evaluate    : /<%([\s\S]+?)%>/g,
    interpolate : /<%=([\s\S]+?)%>/g,
    escape      : /<%-([\s\S]+?)%>/g
  };

  // When customizing `templateSettings`, if you don't want to define an
  // interpolation, evaluation or escaping regex, we need one that is
  // guaranteed not to match.
  var noMatch = /(.)^/;

  // Certain characters need to be escaped so that they can be put into a
  // string literal.
  var escapes = {
    "'":      "'",
    '\\':     '\\',
    '\r':     'r',
    '\n':     'n',
    '\u2028': 'u2028',
    '\u2029': 'u2029'
  };

  var escaper = /\\|'|\r|\n|\u2028|\u2029/g;

  var escapeChar = function(match) {
    return '\\' + escapes[match];
  };

  // JavaScript micro-templating, similar to John Resig's implementation.
  // Underscore templating handles arbitrary delimiters, preserves whitespace,
  // and correctly escapes quotes within interpolated code.
  // NB: `oldSettings` only exists for backwards compatibility.
  _.template = function(text, settings, oldSettings) {
    if (!settings && oldSettings) settings = oldSettings;
    settings = _.defaults({}, settings, _.templateSettings);

    // Combine delimiters into one regular expression via alternation.
    var matcher = RegExp([
      (settings.escape || noMatch).source,
      (settings.interpolate || noMatch).source,
      (settings.evaluate || noMatch).source
    ].join('|') + '|$', 'g');

    // Compile the template source, escaping string literals appropriately.
    var index = 0;
    var source = "__p+='";
    text.replace(matcher, function(match, escape, interpolate, evaluate, offset) {
      source += text.slice(index, offset).replace(escaper, escapeChar);
      index = offset + match.length;

      if (escape) {
        source += "'+\n((__t=(" + escape + "))==null?'':_.escape(__t))+\n'";
      } else if (interpolate) {
        source += "'+\n((__t=(" + interpolate + "))==null?'':__t)+\n'";
      } else if (evaluate) {
        source += "';\n" + evaluate + "\n__p+='";
      }

      // Adobe VMs need the match returned to produce the correct offest.
      return match;
    });
    source += "';\n";

    // If a variable is not specified, place data values in local scope.
    if (!settings.variable) source = 'with(obj||{}){\n' + source + '}\n';

    source = "var __t,__p='',__j=Array.prototype.join," +
      "print=function(){__p+=__j.call(arguments,'');};\n" +
      source + 'return __p;\n';

    try {
      var render = new Function(settings.variable || 'obj', '_', source);
    } catch (e) {
      e.source = source;
      throw e;
    }

    var template = function(data) {
      return render.call(this, data, _);
    };

    // Provide the compiled source as a convenience for precompilation.
    var argument = settings.variable || 'obj';
    template.source = 'function(' + argument + '){\n' + source + '}';

    return template;
  };

  // Add a "chain" function. Start chaining a wrapped Underscore object.
  _.chain = function(obj) {
    var instance = _(obj);
    instance._chain = true;
    return instance;
  };

  // OOP
  // ---------------
  // If Underscore is called as a function, it returns a wrapped object that
  // can be used OO-style. This wrapper holds altered versions of all the
  // underscore functions. Wrapped objects may be chained.

  // Helper function to continue chaining intermediate results.
  var result = function(instance, obj) {
    return instance._chain ? _(obj).chain() : obj;
  };

  // Add your own custom functions to the Underscore object.
  _.mixin = function(obj) {
    _.each(_.functions(obj), function(name) {
      var func = _[name] = obj[name];
      _.prototype[name] = function() {
        var args = [this._wrapped];
        push.apply(args, arguments);
        return result(this, func.apply(_, args));
      };
    });
  };

  // Add all of the Underscore functions to the wrapper object.
  _.mixin(_);

  // Add all mutator Array functions to the wrapper.
  _.each(['pop', 'push', 'reverse', 'shift', 'sort', 'splice', 'unshift'], function(name) {
    var method = ArrayProto[name];
    _.prototype[name] = function() {
      var obj = this._wrapped;
      method.apply(obj, arguments);
      if ((name === 'shift' || name === 'splice') && obj.length === 0) delete obj[0];
      return result(this, obj);
    };
  });

  // Add all accessor Array functions to the wrapper.
  _.each(['concat', 'join', 'slice'], function(name) {
    var method = ArrayProto[name];
    _.prototype[name] = function() {
      return result(this, method.apply(this._wrapped, arguments));
    };
  });

  // Extracts the result from a wrapped and chained object.
  _.prototype.value = function() {
    return this._wrapped;
  };

  // Provide unwrapping proxy for some methods used in engine operations
  // such as arithmetic and JSON stringification.
  _.prototype.valueOf = _.prototype.toJSON = _.prototype.value;

  _.prototype.toString = function() {
    return '' + this._wrapped;
  };

  // AMD registration happens at the end for compatibility with AMD loaders
  // that may not enforce next-turn semantics on modules. Even though general
  // practice for AMD registration is to be anonymous, underscore registers
  // as a named module because, like jQuery, it is a base library that is
  // popular enough to be bundled in a third party lib, but not be part of
  // an AMD load request. Those cases could generate an error when an
  // anonymous define() is called outside of a loader request.
  if (typeof define === 'function' && define.amd) {
    define('underscore', [], function() {
      return _;
    });
  }
}.call(this));

});

require.define("/node_modules/tztime/lib/timezone-js.js",function(require,module,exports,__dirname,__filename,process,global){/*
 * Copyright 2010 Matthew Eernisse (mde@fleegix.org)
 * and Open Source Applications Foundation
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 * Credits: Ideas included from incomplete JS implementation of Olson
 * parser, "XMLDAte" by Philippe Goetz (philippe.goetz@wanadoo.fr)
 *
 * Contributions:
 * Jan Niehusmann
 * Ricky Romero
 * Preston Hunt (prestonhunt@gmail.com),
 * Dov. B Katz (dov.katz@morganstanley.com),
 * Peter Bergström (pbergstr@mac.com)
*/
if (typeof fleegix == 'undefined') { var fleegix = {}; }
if (typeof exports.timezoneJS == 'undefined') { exports.timezoneJS = {}; }

fs = require('fs');
path = require('path');
utils = require('../src/utils');

exports.timezoneJS.timezone = new function() {
  var _this = this;
  var monthMap = { 'jan': 0, 'feb': 1, 'mar': 2, 'apr': 3,'may': 4, 'jun': 5,
    'jul': 6, 'aug': 7, 'sep': 8, 'oct': 9, 'nov': 10, 'dec': 11 };
  var dayMap = {'sun': 0,'mon' :1, 'tue': 2, 'wed': 3, 'thu': 4, 'fri': 5, 'sat': 6 };
  var regionMap = {'EST':'northamerica','MST':'northamerica','HST':'northamerica','EST5EDT':'northamerica','CST6CDT':'northamerica','MST7MDT':'northamerica','PST8PDT':'northamerica','America':'northamerica','Pacific':'australasia','Atlantic':'europe','Africa':'africa','Indian':'africa','Antarctica':'antarctica','Asia':'asia','Australia':'australasia','Europe':'europe','WET':'europe','CET':'europe','MET':'europe','EET':'europe'};
  var regionExceptions = {'Pacific/Honolulu':'northamerica','Atlantic/Bermuda':'northamerica','Atlantic/Cape_Verde':'africa','Atlantic/St_Helena':'africa','Indian/Kerguelen':'antarctica','Indian/Chagos':'asia','Indian/Maldives':'asia','Indian/Christmas':'australasia','Indian/Cocos':'australasia','America/Danmarkshavn':'europe','America/Scoresbysund':'europe','America/Godthab':'europe','America/Thule':'europe','Asia/Yekaterinburg':'europe','Asia/Omsk':'europe','Asia/Novosibirsk':'europe','Asia/Krasnoyarsk':'europe','Asia/Irkutsk':'europe','Asia/Yakutsk':'europe','Asia/Vladivostok':'europe','Asia/Sakhalin':'europe','Asia/Magadan':'europe','Asia/Kamchatka':'europe','Asia/Anadyr':'europe','Africa/Ceuta':'europe','America/Argentina/Buenos_Aires':'southamerica','America/Argentina/Cordoba':'southamerica','America/Argentina/Tucuman':'southamerica','America/Argentina/La_Rioja':'southamerica','America/Argentina/San_Juan':'southamerica','America/Argentina/Jujuy':'southamerica','America/Argentina/Catamarca':'southamerica','America/Argentina/Mendoza':'southamerica','America/Argentina/Rio_Gallegos':'southamerica','America/Argentina/Ushuaia':'southamerica','America/Aruba':'southamerica','America/La_Paz':'southamerica','America/Noronha':'southamerica','America/Belem':'southamerica','America/Fortaleza':'southamerica','America/Recife':'southamerica','America/Araguaina':'southamerica','America/Maceio':'southamerica','America/Bahia':'southamerica','America/Sao_Paulo':'southamerica','America/Campo_Grande':'southamerica','America/Cuiaba':'southamerica','America/Porto_Velho':'southamerica','America/Boa_Vista':'southamerica','America/Manaus':'southamerica','America/Eirunepe':'southamerica','America/Rio_Branco':'southamerica','America/Santiago':'southamerica','Pacific/Easter':'southamerica','America/Bogota':'southamerica','America/Curacao':'southamerica','America/Guayaquil':'southamerica','Pacific/Galapagos':'southamerica','Atlantic/Stanley':'southamerica','America/Cayenne':'southamerica','America/Guyana':'southamerica','America/Asuncion':'southamerica','America/Lima':'southamerica','Atlantic/South_Georgia':'southamerica','America/Paramaribo':'southamerica','America/Port_of_Spain':'southamerica','America/Montevideo':'southamerica','America/Caracas':'southamerica'};

  function invalidTZError(t) {
    throw new Error('Timezone "' + t + '" is either incorrect, or not loaded in the timezone registry.');
  }
  function builtInLoadZoneFile(fileName, opts) {
    if (typeof fleegix.xhr == 'undefined') {
      throw new Error('Please use the Fleegix.js XHR module, or define your own transport mechanism for downloading zone files.');
    }
    var url = _this.zoneFileBasePath + '/' + fileName;
    if (!opts.async) {
      var ret = fleegix.xhr.doReq({
        url: url,
        async: false
      });
      return _this.parseZones(ret);
    }
    else {
      return fleegix.xhr.send({
        url: url,
        method: 'get',
        handleSuccess: function (str) {
          if (_this.parseZones(str)) {
            if (typeof opts.callback == 'function') {
              opts.callback();
            }
          }
          return true;
        },
        handleErr: function () {
          throw new Error('Error retrieving "' + url + '" zoneinfo file.');
        }
      });
    }
  }
  
  
  function myLoadZoneFile(fileName, opts) {
    var url = path.join(_this.zoneFileBasePath, fileName) + '.lzw';
    
    // If running in node.js
    if (fs.readFileSync) {
      url = path.join(__dirname, url);

      var ret
      if (fs.existsSync(url)) {
        ret = utils.lzwDecode(fs.readFileSync(url, 'utf8'));
      } else {
        throw new Error('Cannot find ' + url + ' from directory ' + __dirname);
      }
      return _this.parseZones(ret);
    }
    
    // If running in the browser assume tz files are "fileified" into the source and can be "require"d
    var files = require('files');
    var filesName = 'tz/' + fileName + '.lzw'
    if (files[filesName]) {
        return _this.parseZones(utils.lzwDecode(files[filesName]));
    } else {
        throw new Error(filesName + ' not found embedded in this package.');
    };

  }
  
  
  function getRegionForTimezone(tz) {
    var exc = regionExceptions[tz];
    var ret;
    if (exc) {
      return exc;
    }
    else {
      reg = tz.split('/')[0];
      ret = regionMap[reg];
      // If there's nothing listed in the main regions for
      // this TZ, check the 'backward' links
      if (!ret) {
        var link = _this.zones[tz];
        if (typeof link == 'string') {
          return getRegionForTimezone(link);
        }
        else {
          // Backward-compat file hasn't loaded yet, try looking in there
          if (!_this.loadedZones.backward) {
            // This is for obvious legacy zones (e.g., Iceland) that
            // don't even have a prefix like "America/" that look like
            // normal zones
            var parsed = _this.loadZoneFile('backward', true);
            return getRegionForTimezone(tz);
          }
          else {
            invalidTZError(tz);
          }
        }
      }
      return ret;
    }
  }
  function parseTimeString(str) {
    var pat = /(\d+)(?::0*(\d*))?(?::0*(\d*))?([wsugz])?$/;
    var hms = str.match(pat);
    hms[1] = parseInt(hms[1], 10);
    hms[2] = hms[2] ? parseInt(hms[2], 10) : 0;
    hms[3] = hms[3] ? parseInt(hms[3], 10) : 0;
    return hms;
  }
  function getZone(dt, tz) {
    var t = tz;
    var zoneList = _this.zones[t];
    // Follow links to get to an acutal zone
    while (typeof zoneList == "string") {
      t = zoneList;
      zoneList = _this.zones[t];
    }
    if (!zoneList) {
      // Backward-compat file hasn't loaded yet, try looking in there
      if (!_this.loadedZones.backward) {
        // This is for backward entries like "America/Fort_Wayne" that
        // getRegionForTimezone *thinks* it has a region file and zone
        // for (e.g., America => 'northamerica'), but in reality it's a
        // legacy zone we need the backward file for
        var parsed = _this.loadZoneFile('backward', true);
        return getZone(dt, tz);
      }
      invalidTZError(t);
    }
    for(var i = 0; i < zoneList.length; i++) {
      var z = zoneList[i];
      if (!z[3]) { break; }
      var yea = parseInt(z[3], 10);
      var mon = 11;
      var dat = 31;
      if (z[4]) {
        mon = monthMap[z[4].substr(0, 3).toLowerCase()];
        dat = parseInt(z[5], 10);
      }
      var t = z[6] ? z[6] : '23:59:59';
      t = parseTimeString(t);
      var d = Date.UTC(yea, mon, dat, t[1], t[2], t[3]);
      if (dt.getTime() < d) { break; }
    }
    if (i == zoneList.length) { throw new Error('No Zone found for "' + timezone + '" on ' + dt); }
    return zoneList[i];

  }
  function getBasicOffset(z) {
    var off = parseTimeString(z[0]);
    var adj = z[0].indexOf('-') == 0 ? -1 : 1
    off = adj * (((off[1] * 60 + off[2]) *60 + off[3]) * 1000);
    return -off/60/1000;
  }

  // if isUTC is true, date is given in UTC, otherwise it's given
  // in local time (ie. date.getUTC*() returns local time components)
  function getRule( date, zone, isUTC ) {
    var ruleset = zone[1];
    var basicOffset = getBasicOffset( zone );

    // Convert a date to UTC. Depending on the 'type' parameter, the date
    // parameter may be:
    // 'u', 'g', 'z': already UTC (no adjustment)
    // 's': standard time (adjust for time zone offset but not for DST)
    // 'w': wall clock time (adjust for both time zone and DST offset)
    //
    // DST adjustment is done using the rule given as third argument
    var convertDateToUTC = function( date, type, rule ) {
      var offset = 0;

      if(type == 'u' || type == 'g' || type == 'z') { // UTC
          offset = 0;
      } else if(type == 's') { // Standard Time
          offset = basicOffset;
      } else if(type == 'w' || !type ) { // Wall Clock Time
          offset = getAdjustedOffset(basicOffset,rule);
      } else {
          throw("unknown type "+type);
      }
      offset *= 60*1000; // to millis

      return new Date( date.getTime() + offset );
    }

    // Step 1:  Find applicable rules for this year.
    // Step 2:  Sort the rules by effective date.
    // Step 3:  Check requested date to see if a rule has yet taken effect this year.  If not,
    // Step 4:  Get the rules for the previous year.  If there isn't an applicable rule for last year, then
    //      there probably is no current time offset since they seem to explicitly turn off the offset
    //      when someone stops observing DST.
    //      FIXME if this is not the case and we'll walk all the way back (ugh).
    // Step 5:  Sort the rules by effective date.
    // Step 6:  Apply the most recent rule before the current time.

    var convertRuleToExactDateAndTime = function( yearAndRule, prevRule )
    {
      var year = yearAndRule[0];
      var rule = yearAndRule[1];

      // Assume that the rule applies to the year of the given date.
      var months = {
        "Jan": 0, "Feb": 1, "Mar": 2, "Apr": 3, "May": 4, "Jun": 5,
        "Jul": 6, "Aug": 7, "Sep": 8, "Oct": 9, "Nov": 10, "Dec": 11
      };

      var days = {
        "sun": 0, "mon": 1, "tue": 2, "wed": 3, "thu": 4, "fri": 5, "sat": 6
      }

      var hms = parseTimeString( rule[ 5 ] );
      var effectiveDate;

      if ( !isNaN( rule[ 4 ] ) ) // If we have a specific date, use that!
      {
        effectiveDate = new Date( Date.UTC( year, months[ rule[ 3 ] ], rule[ 4 ], hms[ 1 ], hms[ 2 ], hms[ 3 ], 0 ) );
      }
      else // Let's hunt for the date.
      {
        var targetDay,
          operator;

        if ( rule[ 4 ].substr( 0, 4 ) === "last" ) // Example: lastThu
        {
          // Start at the last day of the month and work backward.
          effectiveDate = new Date( Date.UTC( year, months[ rule[ 3 ] ] + 1, 1, hms[ 1 ] - 24, hms[ 2 ], hms[ 3 ], 0 ) );
          targetDay = days[ rule[ 4 ].substr( 4, 3 ).toLowerCase( ) ];
          operator = "<=";
        }
        else // Example: Sun>=15
        {
          // Start at the specified date.
          effectiveDate = new Date( Date.UTC( year, months[ rule[ 3 ] ], rule[ 4 ].substr( 5 ), hms[ 1 ], hms[ 2 ], hms[ 3 ], 0 ) );
          targetDay = days[ rule[ 4 ].substr( 0, 3 ).toLowerCase( ) ];
          operator = rule[ 4 ].substr( 3, 2 );
        }

        var ourDay = effectiveDate.getUTCDay( );

        if ( operator === ">=" ) // Go forwards.
        {
          effectiveDate.setUTCDate( effectiveDate.getUTCDate( ) + ( targetDay - ourDay + ( ( targetDay < ourDay ) ? 7 : 0 ) ) );
        }
        else // Go backwards.  Looking for the last of a certain day, or operator is "<=" (less likely).
        {
          effectiveDate.setUTCDate( effectiveDate.getUTCDate( ) + ( targetDay - ourDay - ( ( targetDay > ourDay ) ? 7 : 0 ) ) );
        }
      }

      // if previous rule is given, correct for the fact that the starting time of the current
      // rule may be specified in local time
      if(prevRule) {
        effectiveDate = convertDateToUTC(effectiveDate, hms[4], prevRule);
      }

      return effectiveDate;
    }

    var findApplicableRules = function( year, ruleset )
    {
      var applicableRules = [];

      for ( var i in ruleset )
      {
        if ( Number( ruleset[ i ][ 0 ] ) <= year ) // Exclude future rules.
        {
          if (
            Number( ruleset[ i ][ 1 ] ) >= year                                            // Date is in a set range.
            || ( Number( ruleset[ i ][ 0 ] ) === year && ruleset[ i ][ 1 ] === "only" )    // Date is in an "only" year.
            || ruleset[ i ][ 1 ] === "max"                                                 // We're in a range from the start year to infinity.
          )
          {
            // It's completely okay to have any number of matches here.
            // Normally we should only see two, but that doesn't preclude other numbers of matches.
            // These matches are applicable to this year.
            applicableRules.push( [year, ruleset[ i ]] );
          }
        }
      }

      return applicableRules;
    }

    var compareDates = function( a, b, prev )
    {
      if ( a.constructor !== Date ) {
        a = convertRuleToExactDateAndTime( a, prev );
      } else if(prev) {
        a = convertDateToUTC(a, isUTC?'u':'w', prev);
      }
      if ( b.constructor !== Date ) {
        b = convertRuleToExactDateAndTime( b, prev );
      } else if(prev) {
        b = convertDateToUTC(b, isUTC?'u':'w', prev);
      }

      a = Number( a );
      b = Number( b );

      return a - b;
    }

    var year = date.getUTCFullYear( );
    var applicableRules;

    applicableRules = findApplicableRules( year, _this.rules[ ruleset ] );
    applicableRules.push( date );
    // While sorting, the time zone in which the rule starting time is specified
    // is ignored. This is ok as long as the timespan between two DST changes is
    // larger than the DST offset, which is probably always true.
    // As the given date may indeed be close to a DST change, it may get sorted
    // to a wrong position (off by one), which is corrected below.
    applicableRules.sort( compareDates );

    if ( applicableRules.indexOf( date ) < 2 ) { // If there are not enough past DST rules...
      applicableRules = applicableRules.concat(findApplicableRules( year-1, _this.rules[ ruleset ] ));
      applicableRules.sort( compareDates );
    }

    var pinpoint = applicableRules.indexOf( date );
    if ( pinpoint > 1 && compareDates( date, applicableRules[pinpoint-1], applicableRules[pinpoint-2][1] ) < 0 ) {
      // the previous rule does not really apply, take the one before that
      return applicableRules[ pinpoint - 2 ][1];
    } else if ( pinpoint > 0 && pinpoint < applicableRules.length - 1 && compareDates( date, applicableRules[pinpoint+1], applicableRules[pinpoint-1][1] ) > 0) {
      // the next rule does already apply, take that one
      return applicableRules[ pinpoint + 1 ][1];
    } else if ( pinpoint === 0 ) {
      // no applicable rule found in this and in previous year
      return null;
    } else {
      return applicableRules[ pinpoint - 1 ][1];
    }
  }
  function getAdjustedOffset(off, rule) {
    var save = rule[6];
    var t = parseTimeString(save);
    var adj = save.indexOf('-') == 0 ? -1 : 1;
    var ret = (adj*(((t[1] *60 + t[2]) * 60 + t[3]) * 1000));
    ret = ret/60/1000;
    ret -= off
    ret = -Math.ceil(ret);
    return ret;
  }
  function getAbbreviation(zone, rule) {
    var res;
    var base = zone[2];
    if (base.indexOf('%s') > -1) {
      var repl;
      if (rule) {
        repl = rule[7]=='-'?'':rule[7];
      }
      // FIXME: Right now just falling back to Standard --
      // apparently ought to use the last valid rule,
      // although in practice that always ought to be Standard
      else {
        repl = 'S';
      }
      res = base.replace('%s', repl);
    }
    else if (base.indexOf('/') > -1) {
      // chose one of two alternative strings
      var t = parseTimeString(rule[6]);
      var isDst = (t[1])||(t[2])||(t[3]);
      res = base.split("/",2)[isDst?1:0];
    } else {
      res = base;
    }
    return res;
  }

  this.zoneFileBasePath;
  this.zoneFiles = ['africa', 'antarctica', 'asia',
    'australasia', 'backward', 'etcetera', 'europe',
    'northamerica', 'pacificnew', 'southamerica'];
  this.loadingSchemes = {
    PRELOAD_ALL: 'preloadAll',
    LAZY_LOAD: 'lazyLoad',
    MANUAL_LOAD: 'manualLoad'
  }
  this.loadingScheme = this.loadingSchemes.PRELOAD_ALL;
  this.defaultZoneFile =
    this.loadingScheme == this.loadingSchemes.PRELOAD_ALL ?
      this.zoneFiles : 'northamerica';
  this.loadedZones = {};
  this.zones = {};
  this.rules = {};

  this.init = function (o) {
    var opts = { async: true };
    var sync = false;
    var def = this.defaultZoneFile;
    var parsed;
    // Override default with any passed-in opts
    for (var p in o) {
      opts[p] = o[p];
    }
    if (typeof def == 'string') {
      parsed = this.loadZoneFile(def, opts);
    }
    else {
      if (opts.callback) {
        throw new Error('Async load with callback is not supported for multiple default zonefiles.');
      }
      for (var i = 0; i < def.length; i++) {
        parsed = this.loadZoneFile(def[i], opts);
      }
    }
  };
  // Get the zone files via XHR -- if the sync flag
  // is set to true, it's being called by the lazy-loading
  // mechanism, so the result needs to be returned inline
  this.loadZoneFile = function (fileName, opts) {
    if (typeof this.zoneFileBasePath == 'undefined') {
      throw new Error('Please define a base path to your zone file directory -- timezoneJS.timezone.zoneFileBasePath.');
    }
    // ========================
    // Define your own transport mechanism here
    // and comment out the default below
    // ========================
    if (! this.loadedZones[fileName]) {
      this.loadedZones[fileName] = true;
      // return builtInLoadZoneFile(fileName, opts);
      return myLoadZoneFile(fileName, opts);
    }
  };
  this.loadZoneJSONData = function (url, sync) {
    var processData = function (data) {
      data = eval('('+ data +')');
      for (var z in data.zones) {
        _this.zones[z] = data.zones[z];
      }
      for (var r in data.rules) {
        _this.rules[r] = data.rules[r];
      }
    }
    if (sync) {
      var data = fleegix.xhr.doGet(url);
      processData(data);
    }
    else {
      fleegix.xhr.doGet(processData, url);
    }
  };
  this.loadZoneDataFromObject = function (data) {
    if (!data) { return; }
    for (var z in data.zones) {
      _this.zones[z] = data.zones[z];
    }
    for (var r in data.rules) {
      _this.rules[r] = data.rules[r];
    }
  };
  this.getAllZones = function() {
    var arr = [];
    for (z in this.zones) { arr.push(z); }
    return arr.sort();
  };
  this.parseZones = function(str) {
    var s = '';
    var lines = str.split('\n');
    var arr = [];
    var chunk = '';
    var zone = null;
    var rule = null;
    for (var i = 0; i < lines.length; i++) {
      l = lines[i];
      if (l.match(/^\s/)) {
        l = "Zone " + zone + l;
      }
      l = l.split("#")[0];
      if (l.length > 3) {
        arr = l.split(/\s+/);
        chunk = arr.shift();
        switch(chunk) {
          case 'Zone':
            zone = arr.shift();
            if (!_this.zones[zone]) { _this.zones[zone] = [] }
            _this.zones[zone].push(arr);
            break;
          case 'Rule':
            rule = arr.shift();
            if (!_this.rules[rule]) { _this.rules[rule] = [] }
            _this.rules[rule].push(arr);
            break;
          case 'Link':
            // No zones for these should already exist
            if (_this.zones[arr[1]]) {
              throw new Error('Error with Link ' + arr[1]);
            }
            // Create the link
            _this.zones[arr[1]] = arr[0];
            break;
          case 'Leap':
            break;
          default:
            // Fail silently
            break;
        }
      }
    }
    return true;
  };
  this.getTzInfo = function(dt, tz, isUTC) {
    // Lazy-load any zones not yet loaded
    if (this.loadingScheme == this.loadingSchemes.LAZY_LOAD) {
      // Get the correct region for the zone
      var zoneFile = getRegionForTimezone(tz);
      if (!zoneFile) {
        throw new Error('Not a valid timezone ID.');
      }
      else {
        if (!this.loadedZones[zoneFile]) {
          // Get the file and parse it -- use synchronous XHR
          var parsed = this.loadZoneFile(zoneFile, true);
        }
      }
    }
    var zone = getZone(dt, tz);
    var off = getBasicOffset(zone);
    // See if the offset needs adjustment
    var rule = getRule(dt, zone, isUTC);
    if (rule) {
      off = getAdjustedOffset(off, rule);
    }
    var abbr = getAbbreviation(zone, rule);
    return { tzOffset: off, tzAbbr: abbr };
  }
};
  
exports.timezoneJS.parseISO = function (timestring) {
  var pat = '^(?:([+-]?[0-9]{4,})(?:-([0-9]{2})(?:-([0-9]{2}))?)?)?' +
    '(?:T(?:([0-9]{2})(?::([0-9]{2})(?::([0-9]{2})(?:\\.' +
    '([0-9]{3}))?)?)?)?(Z|[-+][0-9]{2}:[0-9]{2})?)?$';
  var match = timestring.match(pat);
  if (match) {
    var parts = {
      year: match[1] || 0,
      month:  match[2] || 1,
      day:  match[3] || 1,
      hour:  match[4] || 0,
      minute:  match[5] || 0,
      second:  match[6] || 0,
      milli:  match[7] || 0,
      offset:  match[8] || "Z"
    };

    var utcDate = Date.UTC(parts.year, parts.month-1, parts.day,
      parts.hour, parts.minute, parts.second, parts.milli);

    if (parts.offset !== "Z") {
      match = parts.offset.match('([-+][0-9]{2})(?::([0-9]{2}))?');
      if (!match) {
        return NaN;
      }
      var offset = match[1]*60*60*1000+(match[2] || 0)*60*1000;
      utcDate -= offset;
    }
    
    return new Date(utcDate);
  }
  else {
    return null;
  }
};





});

require.define("fs",function(require,module,exports,__dirname,__filename,process,global){// nothing to see here... no file methods for the browser

});

require.define("/node_modules/tztime/src/Timeline.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3
(function() {
  var Time, Timeline, TimelineIterator, timezoneJS, utils,
    indexOf = [].indexOf || function(item) { for (var i = 0, l = this.length; i < l; i++) { if (i in this && this[i] === item) return i; } return -1; };

  Time = require('./Time').Time;

  timezoneJS = require('./../lib/timezone-js.js').timezoneJS;

  utils = require('./utils');

  Timeline = (function() {

    /*
    @class Timeline
    
    Allows you to specify a timeline with weekend, holiday and non-work hours knocked out and timezone precision.
    
    ## Basic usage ##
    
        {TimelineIterator, Timeline, Time} = require('../')
    
        tl = new Timeline({
          startOn: '2011-01-03',
          endBefore: '2011-01-05',
        })
    
        console.log(t.toString() for t in tl.getAll())
         * [ '2011-01-03', '2011-01-04' ]
    
    Notice how the endBefore, '2011-01-05', is excluded. Timelines are inclusive of the startOn and exclusive of the
    endBefore. This allows the endBefore to be the startOn of the next with no overlap or gap. This focus on precision
    pervades the design of the Time library.
    
    Perhaps the most common use of Timeline is to return a Timeline of ISOStrings shifted to the correct timezone.
    Since ISOString comparisons give the expected chronological results and many APIs return their date/time stamps as
    ISOStrings, it's convenient and surprisingly fast to do your own bucketing operations after you've gotten a Timeline
    of ISOStrings.
    
        console.log(tl.getAll('ISOString', 'America/New_York'))
         * [ '2011-01-03T05:00:00.000Z', '2011-01-04T05:00:00.000Z' ]
    
    ## More advanced usage ##
     
    Now let's poke at Timeline behavior a little more. Let's start by creating a more advanced Timeline:
    
        tl = new Timeline({
          startOn: '2011-01-02',
          endBefore: '2011-01-07',
          holidays: [
            {month: 1, day: 1},  # Notice the lack of a year specification
            '2011-01-04'  # Got January 4 off also in 2011. Allows ISO strings.
          ]
        })
        
    `workDays` is already defaulted but you could have overridden it.
    
        console.log(tl.workDays)
         * [ 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday' ]
        
    Another common use case is to get a Timeline to return child Timelines. You see, Timelines can be thought of as
    time boxes with a startOn and an endBefore. You might have a big time box for the entire x-axis for a chart
    but if you want to bucket raw data into each tick on the x-axis, you'll need to know where each sub-time box starts
    and ends.
    
        subTimelines = tl.getAll('Timeline')
        console.log((t.startOn.toString() + ' to ' + t.endBefore.toString() for t in subTimelines))
         * [ '2011-01-03 to 2011-01-05',
         *   '2011-01-05 to 2011-01-06',
         *   '2011-01-06 to 2011-01-07' ]
    
    Notice how the first subTimeline went all the way from 03 to 05. That's because we specified 04 as a holiday.
    Timelines are contiguous without gaps or overlap. You can see that the endBefore of one subTimeline is always the startOn
    of the next.
    
    Now, let's create a Timeline with `hour` granularity and show of the concept that Timelines also serve as time boxes by
    learning about the contains() method.
        
        tl2 = new Timeline({
          startOn: '2011-01-02T00',
          endBefore: '2011-01-07T00',
        })
        
    `startOn` is inclusive.
    
        console.log(tl2.contains('2011-01-02T00'))
         * true
        
    But `endBefore` is exclusive
    
        console.log(tl2.contains('2011-01-07T00'))
         * false
    
    But just before `endBefore` is OK
    
        console.log(tl2.contains('2011-01-06T23'))
         * true
    
    All of the above comparisons assume that the `startOn`/`endBefore` boundaries are in the same timezone as the contains date.
    
    ## Timezone sensitive comparisions ##
    
    Now, let's look at how you do timezone sensitive comparisions.
    
    If you pass in a timezone, then it will shift the Timeline boundaries to that timezone to compare to the 
    date/timestamp that you pass in. This system is optimized to the pattern where you first define your boundaries without regard 
    to timezone. Christmas day is a holiday in any timezone. Saturday and Sunday are non work days in any timezone. The iteration
    starts on July 10th; etc. THEN you have a bunch of data that you have stored in a database in GMT. Maybe you've pulled
    it down from an API but the data is represented with ISOString. You then want to decide if the ISOString
    is contained within the iteration as defined by a particular timezone, or is a Saturday, or is during workhours, etc. 
    The key concept to remember is that the timebox boundaries are shifted NOT the other way around. It says at what moment
    in time July 10th starts on in a particular timezone and internally represents that in a way that can be compared to
    an ISOString.
    
    So, when it's 3am in GMT on 2011-01-02, it's still 2011-01-01 in New York. Using the above `tl2` timeline, we say:
    
        console.log(tl2.contains('2011-01-02T03:00:00.000Z', 'America/New_York'))
         * false
        
    But it's still 2011-01-06 in New York, when it's 3am in GMT on 2011-01-07
        
        console.log(tl2.contains('2011-01-07T03:00:00.000Z', 'America/New_York'))
         * true
     */
    function Timeline(config) {

      /*
      @constructor
      @param {Object} config
      
      @cfg {Time/ISOString} [startOn] Unless it falls on a knocked out moment, this is the first value in the resulting Timeline
        If it falls on a knocked out moment, it will advance to the first appropriate moment after startOn.
        You must specify 2 out of 3 of startOn, endBefore, and limit.
      @cfg {Time/ISOString} [endBefore] Must match granularity of startOn. Timeline will stop before returning this value.
        You must specify 2 out of 3 of startOn, endBefore, and limit.
      @cfg {Number} [limit] You can specify limit and either startOn or endBefore and only get back this many.
        You must specify 2 out of 3 of startOn, endBefore, and limit.
      @cfg {Number} [step = 1 or -1] Use -1 to march backwards from endBefore - 1. Currently any
         values other than 1 and -1 are not well tested.
      @cfg {String} [granularity = granularity of startOn or endBefore] Used to determine the granularity of the ticks.
        Note, this can be different from the granularity of startOn and endBefore. For example:
      
          {
            startOn: '2012-01', # Month Granularity
            endBefore: '2012-02', # Month Granularity
            granularity: Time.DAY # Day granularity
          }
      
      @cfg {String[]/String} [workDays =  ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']] List of days of the
        week that you work on. You can specify this as an Array of Strings (['Monday', 'Tuesday', ...]) or a single comma
        seperated String ("Monday,Tuesday,...").
      @cfg {Array} [holidays] An optional Array of either ISOStrings or JavaScript Objects (and you can mix and match). Example:
      
          [{month: 12, day: 25}, {year: 2011, month: 11, day: 24}, "2012-12-24"]
      
         Notice how you can leave off the year if the holiday falls on the same day every year.
      @cfg {Object} [workDayStartOn = {hour: 0, minute: 0}] An optional object in the form {hour: 8, minute: 15}.
        If minute is zero it can be omitted. If workDayStartOn is later than workDayEndBefore, then it assumes that you
        work the night shift and your work  hours span midnight.
      
        The use of workDayStartOn and workDayEndBefore only make sense when the granularity is "hour" or finer.
      
        Note: If the business closes at 5:00pm, you'll want to leave workDayEndBefore to 17:00, rather
        than 17:01. Think about it, you'll be open 4:59:59.999pm, but you'll be closed at 5:00pm. This also makes all of
        the math work. 9am to 5pm means 17 - 9 = an 8 hour work day.
      @cfg {Object} [workDayEndBefore = {hour: 24, minute: 60}] An optional object in the form {hour: 17, minute: 0}.
        If minute is zero it can be omitted.
       */
      var h, holiday, idx, j, len, m, ref, ref1, s;
      this.memoizedTicks = {};
      if (config.endBefore != null) {
        this.endBefore = config.endBefore;
        if (this.endBefore !== 'PAST_LAST') {
          if (utils.type(this.endBefore) === 'string') {
            this.endBefore = new Time(this.endBefore);
          }
          this.granularity = this.endBefore.granularity;
        }
      }
      if (config.startOn != null) {
        this.startOn = config.startOn;
        if (this.startOn !== 'BEFORE_FIRST') {
          if (utils.type(this.startOn) === 'string') {
            this.startOn = new Time(this.startOn);
          }
          this.granularity = this.startOn.granularity;
        }
      }
      if (config.granularity != null) {
        this.granularity = config.granularity;
        if (this.startOn != null) {
          this.startOn = this.startOn.inGranularity(this.granularity);
        }
        if (this.endBefore != null) {
          this.endBefore = this.endBefore.inGranularity(this.granularity);
        }
      }
      if (!this.granularity) {
        throw new Error('Cannot determine granularity for Timeline.');
      }
      if (this.startOn === 'BEFORE_FIRST') {
        this.startOn = new Time(this.startOn, this.granularity);
      }
      if (this.endBefore === 'PAST_LAST') {
        this.endBefore === new Time(this.endBefore, this.granularity);
      }
      if (!this.endBefore) {
        this.endBefore = new Time('PAST_LAST', this.granularity);
      }
      if (!this.startOn) {
        this.startOn = new Time('BEFORE_FIRST', this.granularity);
      }
      this.limit = config.limit != null ? config.limit : utils.MAX_INT;
      if (config.workDays != null) {
        this.workDays = config.workDays;
      } else if (config.workdays != null) {
        this.workDays = config.workdays;
      } else {
        this.workDays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'];
      }
      if (utils.type(this.workDays) === 'string') {
        this.workDays = (function() {
          var j, len, ref, results;
          ref = this.workDays.split(',');
          results = [];
          for (j = 0, len = ref.length; j < len; j++) {
            s = ref[j];
            results.push(utils.trim(s));
          }
          return results;
        }).call(this);
      }
      this.holidays = config.holidays != null ? config.holidays : [];
      ref = this.holidays;
      for (idx = j = 0, len = ref.length; j < len; idx = ++j) {
        holiday = ref[idx];
        if (utils.type(holiday) === 'string') {
          this.holidays[idx] = new Time(holiday).getSegmentsAsObject();
        }
      }
      this.workDayStartOn = config.workDayStartOn != null ? config.workDayStartOn : void 0;
      if (this.workDayStartOn != null) {
        h = this.workDayStartOn.hour != null ? this.workDayStartOn.hour : 0;
        m = this.workDayStartOn.minute != null ? this.workDayStartOn.minute : 0;
        this.startOnWorkMinutes = h * 60 + m;
        if (this.startOnWorkMinutes < 0) {
          this.startOnWorkMinutes = 0;
        }
      } else {
        this.startOnWorkMinutes = 0;
      }
      this.workDayEndBefore = config.workDayEndBefore != null ? config.workDayEndBefore : void 0;
      if (this.workDayEndBefore != null) {
        h = this.workDayEndBefore.hour != null ? this.workDayEndBefore.hour : 24;
        m = this.workDayEndBefore.minute != null ? this.workDayEndBefore.minute : 0;
        this.endBeforeWorkMinutes = h * 60 + m;
        if (this.endBeforeWorkMinutes > 24 * 60) {
          this.endBeforeWorkMinutes = 24 * 60;
        }
      } else {
        this.endBeforeWorkMinutes = 24 * 60;
      }
      if (config.step != null) {
        this.step = config.step;
      } else if ((config.endBefore != null) && ((ref1 = this.startOn) != null ? ref1.greaterThan(this.endBefore) : void 0)) {
        this.step = -1;
      } else if ((config.endBefore != null) && (config.startOn == null) && (config.limit != null)) {
        this.step = -1;
      } else {
        this.step = 1;
      }
      utils.assert(((config.startOn != null) && (config.endBefore != null)) || ((config.startOn != null) && (config.limit != null) && this.step > 0) || ((config.endBefore != null) && (config.limit != null) && this.step < 0), 'Must provide two out of "startOn", "endBefore", or "limit" and the sign of step must match.');
    }

    Timeline.prototype.getIterator = function(tickType, tz, childGranularity) {
      if (tickType == null) {
        tickType = 'Time';
      }

      /*
      @method getIterator
      @param {String} [tickType] An optional String that specifies what type should be returned on each call to next().
        Possible values are 'Time' (default), 'Timeline', 'Date' (javascript Date Object), and 'ISOString'.
      @param {String} [tz] A Sting specifying the timezone in the standard form,`America/New_York` for example. This is
        required if `tickType` is 'Date' or 'ISOString'.
      @param {String} [childGranularity] When tickType is 'Timeline', this is the granularity for the startOn and endBefore of the
        Timeline that is returned.
      @return {TimelineIterator}
      
      Returns a new TimelineIterator using this Timeline as the boundaries.
       */
      return new TimelineIterator(this, tickType, tz, childGranularity);
    };

    Timeline.prototype.getAllRaw = function(tickType, tz, childGranularity) {
      var temp, tli;
      if (tickType == null) {
        tickType = 'Time';
      }

      /*
      @method getAllRaw
      @param {String} [tickType] An optional String that specifies the type should be returned. Possible values are 'Time' (default),
         'Timeline', 'Date' (javascript Date Object), and 'ISOString'.
      @param {String} [tz] A Sting specifying the timezone in the standard form,`America/New_York` for example. This is
         required if `tickType` is 'Date' or 'ISOString'.
      @param {String} [childGranularity] When tickType is 'Timeline', this is the granularity for the startOn and endBefore of the
         Timeline that is returned.
      @return {Time[]/Date[]/Timeline[]/String[]}
      
      Returns all of the points in the timeline. Note, this will come back in the order specified
      by step so they could be out of chronological order. Use getAll() if they must be in chronological order.
       */
      tli = this.getIterator(tickType, tz, childGranularity);
      temp = [];
      while (tli.hasNext()) {
        temp.push(tli.next());
      }
      return temp;
    };

    Timeline.prototype.getAll = function(tickType, tz, childGranularity) {
      var parameterKey, parameterKeyObject, ticks;
      if (tickType == null) {
        tickType = 'Time';
      }

      /*
      @method getAll
      @param {String} [tickType] An optional String that specifies what should be returned. Possible values are 'Time' (default),
         'Timeline', 'Date' (javascript Date Object), and 'ISOString'.
      @param {String} [tz] A Sting specifying the timezone in the standard form,`America/New_York` for example. This is
         required if `tickType` is 'Date' or 'ISOString'.
      @param {String} [childGranularity] When tickType is 'Timeline', this is the granularity for the startOn and endBefore of the
         Timeline object that is returned.
      @return {Time[]/Date[]/Timeline[]/String[]}
      
      Returns all of the points in the timeline in chronological order. If you want them in the order specified by `step`
      then use getAllRaw(). Note, the output of this function is memoized so that subsequent calls to getAll() for the
      same Timeline instance with the same parameters will return the previously calculated values. This makes it safe
      to call it repeatedly within loops and means you don't need to worry about holding onto the result on the client
      side.
       */
      parameterKeyObject = {
        tickType: tickType
      };
      if (tz != null) {
        parameterKeyObject.tz = tz;
      }
      if (childGranularity != null) {
        parameterKeyObject.childGranularity = childGranularity;
      }
      parameterKey = JSON.stringify(parameterKeyObject);
      ticks = this.memoizedTicks[parameterKey];
      if (ticks == null) {
        ticks = this.getAllRaw(tickType, tz, childGranularity);
        if (ticks.length > 1) {
          if ((ticks[0] instanceof Time && ticks[0].greaterThan(ticks[1])) || (utils.type(ticks[0]) === 'string' && ticks[0] > ticks[1])) {
            ticks.reverse();
          }
        }
        this.memoizedTicks[parameterKey] = ticks;
      }
      return ticks;
    };

    Timeline.prototype.ticksThatIntersect = function(startOn, endBefore, tz) {

      /*
      @method ticksThatIntersect
      @param {Time/ISOString} startOn The start of the time period of interest
      @param {Time/ISOString} endBefore The moment just past the end of the time period of interest
      @param {String} tz The timezone you want to use for the comparison
      @return {Array}
      
      Returns the list of ticks from this Timeline that intersect with the time period specified by the parameters
      startOn and endBefore. This is a convenient way to "tag" a timebox as overlaping with particular moments on
      your Timeline. A common pattern for Lumenize calculators is to use ticksThatIntersect to "tag" each snapshot
      and then do groupBy operations with an OLAPCube.
       */
      var en, i, isoDateRegExp, out, st, ticks, ticksLength;
      utils.assert(this.limit === utils.MAX_INT, 'Cannot call `ticksThatIntersect()` on Timelines specified with `limit`.');
      out = [];
      if (utils.type(startOn) === 'string') {
        utils.assert(utils.type(endBefore) === 'string', 'The type for startOn and endBefore must match.');
        isoDateRegExp = /\d\d\d\d-\d\d-\d\dT\d\d:\d\d:\d\d.\d\d\dZ/;
        utils.assert(isoDateRegExp.test(startOn), 'startOn must be in form ####-##-##T##:##:##.###Z');
        utils.assert(isoDateRegExp.test(endBefore), 'endBefore must be in form ####-##-##T##:##:##.###Z');
        utils.assert(tz != null, "Must specify parameter tz when submitting ISO string boundaries.");
        ticks = this.getAll('ISOString', tz);
        if (ticks[0] >= endBefore || ticks[ticks.length - 1] < startOn) {
          out = [];
        } else {
          i = 0;
          ticksLength = ticks.length;
          while (i < ticksLength && ticks[i] < startOn) {
            i++;
          }
          while (i < ticksLength && ticks[i] < endBefore) {
            out.push(ticks[i]);
            i++;
          }
        }
      } else if (startOn instanceof Time) {
        utils.assert(endBefore instanceof Time, 'The type for startOn and endBefore must match.');
        startOn = startOn.inGranularity(this.granularity);
        endBefore = endBefore.inGranularity(this.granularity);
        if (this.endBefore.lessThan(this.startOn)) {
          st = this.endBefore;
          en = this.startOn;
        } else {
          st = this.startOn;
          en = this.endBefore;
        }
        if (st.greaterThanOrEqual(endBefore) || en.lessThan(startOn)) {
          out = [];
        } else {
          ticks = this.getAll();
          i = 0;
          ticksLength = ticks.length;
          while (i < ticksLength && ticks[i].lessThan(startOn)) {
            i++;
          }
          while (i < ticksLength && ticks[i].lessThan(endBefore)) {
            out.push(ticks[i]);
            i++;
          }
        }
      } else {
        throw new Error("startOn must be a String or a Time object.");
      }
      return out;
    };

    Timeline.prototype.contains = function(date, tz) {

      /*
      @method contains
      @param {Time/Date/String} date can be either a JavaScript date object or an ISO-8601 formatted string
      @param {String} [tz]
      @return {Boolean} true if the date provided is within this Timeline.
      
      ## Usage: ##
      
      We can create a Timeline from May to just before July.
      
          tl = new Timeline({
            startOn: '2011-05',
            endBefore: '2011-07'
          })
      
          console.log(tl.contains('2011-06-15T12:00:00.000Z', 'America/New_York'))
           * true
       */
      var endBefore, startOn, target;
      utils.assert(this.limit === utils.MAX_INT, 'Cannot call `contains()` on Timelines specified with `limit`.');
      if (date instanceof Time) {
        return date.lessThan(this.endBefore) && date.greaterThanOrEqual(this.startOn);
      }
      utils.assert((tz != null) || utils.type(date) !== 'date', 'Timeline.contains() requires a second parameter (timezone) when the first parameter is a Date()');
      switch (utils.type(date)) {
        case 'string':
          if (tz != null) {
            target = timezoneJS.parseISO(date);
          } else {
            target = new Time(date);
            return target.lessThan(this.endBefore) && target.greaterThanOrEqual(this.startOn);
          }
          break;
        case 'date':
          target = date.getTime();
          break;
        default:
          throw new Error('Timeline.contains() requires that the first parameter be of type Time, String, or Date');
      }
      startOn = this.startOn.getJSDate(tz);
      endBefore = this.endBefore.getJSDate(tz);
      return target < endBefore && target >= startOn;
    };

    return Timeline;

  })();

  TimelineIterator = (function() {

    /*
    @class TimelineIterator
    
    In most cases you'll want to call getAll() on Timeline. TimelineIterator is for use cases where you want to get the
    values in the Timeline one at a time.
    
    You usually get a TimelineIterator by calling getIterator() on a Timeline object.
    
    Iterate through days, months, years, etc. skipping weekends and holidays that you
    specify. It will also iterate over hours, minutes, seconds, etc. and skip times that are not
    between the specified work hours.
    
    ## Usage ##
    
        {TimelineIterator, Timeline, Time} = require('../')
    
        tl = new Timeline({
          startOn:new Time({granularity: 'day', year: 2009, month:1, day: 1}),
          endBefore:new Time({granularity: 'day', year: 2009, month:1, day: 8}),
          workDays: 'Monday, Tuesday, Wednesday, Thursday, Friday',
          holidays: [
            {month: 1, day: 1},  # New Years day was a Thursday in 2009
            {year: 2009, month: 1, day: 2}  # Also got Friday off in 2009
          ]
        })
    
        tli = tl.getIterator()
    
        while (tli.hasNext())
          console.log(tli.next().toString())
    
         * 2009-01-05
         * 2009-01-06
         * 2009-01-07
    
    Now, let's explore how Timelines and TimelineIterators are used together.
    
        tl3 = new Timeline({
          startOn:new Time('2011-01-06'),
          endBefore:new Time('2011-01-11'),
          workDayStartOn: {hour: 9, minute: 0},
          workDayEndBefore: {hour: 11, minute: 0}  # Very short work day for demo purposes
        })
    
    You can specify that the tickType be Timelines rather than Time values. On each call to `next()`, the
    iterator will give you a new Timeline with the `startOn` value set to what you would have gotten had you
    requested that the tickType be Times. The `endBefore' of the returned Timeline will be set to the next value.
    This is how you drill-down from one granularity into a lower granularity.
    
    By default, the granularity of the iterator will equal the `startOn`/`endBefore` of the original Timeline.
    However, you can provide a different granularity (`hour` in the example below) for the iterator if you want
    to drill-down at a lower granularity.
    
        tli3 = tl3.getIterator('Timeline', undefined, 'hour')
    
        while tli3.hasNext()
          subTimeline = tli3.next()
          console.log("Sub Timeline goes from #{subTimeline.startOn.toString()} to #{subTimeline.endBefore.toString()}")
          subIterator = subTimeline.getIterator('Time')
          while subIterator.hasNext()
            console.log('    Hour: ' + subIterator.next().hour)
    
         * Sub Timeline goes from 2011-01-06T00 to 2011-01-07T00
         *     Hour: 9
         *     Hour: 10
         * Sub Timeline goes from 2011-01-07T00 to 2011-01-10T00
         *     Hour: 9
         *     Hour: 10
         * Sub Timeline goes from 2011-01-10T00 to 2011-01-11T00
         *     Hour: 9
         *     Hour: 10
    
    There is a lot going on here, so let's poke at it a bit. First, notice how the second sub-Timeline goes from the 7th to the
    10th. That's because there was a weekend in there. We didn't get hours for the Saturday and Sunday.
    
    The above approach (`tl3`/`tli3`) is useful for some forms of hand generated analysis, but if you are using Time with
    Lumenize, it's overkill because Lumenize is smart enough to do rollups based upon the segments that are returned from the
    lowest granularity Time. So you can just iterate over the lower granularity and Lumenize will automatically manage
    the drill up/down to day/month/year levels automatically.
    
        tl4 = new Timeline({
          startOn:'2011-01-06T00',  # Notice how we include the hour now
          endBefore:'2011-01-11T00',
          workDayStartOn: {hour: 9, minute: 0},
          workDayEndBefore: {hour: 11, minute: 0}  # Very short work day for demo purposes
        })
    
        tli4 = tl4.getIterator('ISOString', 'GMT')
    
        while tli4.hasNext()
          console.log(tli4.next())
    
         * 2011-01-06T09:00:00.000Z
         * 2011-01-06T10:00:00.000Z
         * 2011-01-07T09:00:00.000Z
         * 2011-01-07T10:00:00.000Z
         * 2011-01-10T09:00:00.000Z
         * 2011-01-10T10:00:00.000Z
    
    `tl4`/`tli4` covers the same ground as `tl3`/`tli3` but without the explicit nesting.
     */
    var StopIteration, _contains;

    function TimelineIterator(timeline, tickType1, tz, childGranularity1) {
      var ref;
      this.tickType = tickType1 != null ? tickType1 : 'Time';
      this.childGranularity = childGranularity1;

      /*
      @constructor
      @param {Timeline} timeline A Timeline object
      @param {String} [tickType] An optional String that specifies the type for the returned ticks. Possible values are 'Time' (default),
         'Timeline', 'Date' (javascript Date Object), and 'ISOString'.
      @param {String} [childGranularity=granularity of timeline] When tickType is 'Timeline', this is the granularity for the startOn and endBefore of the
         Timeline that is returned.
      @param {String} [tz] A Sting specifying the timezone in the standard form,`America/New_York` for example. This is
         required if `tickType` is 'Date' or 'ISOString'.
       */
      utils.assert((ref = this.tickType) === 'Time' || ref === 'Timeline' || ref === 'Date' || ref === 'ISOString', "tickType must be 'Time', 'Timeline', 'Date', or 'ISOString'. You provided " + this.tickType + ".");
      utils.assert(this.tickType !== 'Date' || (tz != null), 'Must provide a tz (timezone) parameter when tickType is Date.');
      utils.assert(this.tickType !== 'ISOString' || (tz != null), 'Must provide a tz (timezone) parameter when returning ISOStrings.');
      if (this.tz == null) {
        this.tz = tz;
      }
      if (timeline instanceof Timeline) {
        this.timeline = timeline;
      } else {
        this.timeline = new Timeline(timeline);
      }
      if (this.childGranularity == null) {
        this.childGranularity = timeline.granularity;
      }
      this.reset();
    }

    StopIteration = typeof StopIteration === 'undefined' ? utils.StopIteration : StopIteration;

    TimelineIterator.prototype.reset = function() {

      /*
      @method reset
      
      Will go back to the where the iterator started.
       */
      if (this.timeline.step > 0) {
        this.current = new Time(this.timeline.startOn);
      } else {
        this.current = new Time(this.timeline.endBefore);
        this.current.decrement();
      }
      this.count = 0;
      return this._proceedToNextValid();
    };

    _contains = function(t, startOn, endBefore) {
      return t.lessThan(endBefore) && t.greaterThanOrEqual(startOn);
    };

    TimelineIterator.prototype.hasNext = function() {

      /*
      @method hasNext
      @return {Boolean} Returns true if there are still things left to iterator over. Note that if there are holidays,
         weekends or non-workhours to skip, then hasNext() will take that into account.
       */
      return _contains(this.current, this.timeline.startOn, this.timeline.endBefore) && (this.count < this.timeline.limit);
    };

    TimelineIterator.prototype._shouldBeExcluded = function() {
      var currentInDay, currentMinutes, holiday, j, len, ref, ref1, ref2;
      if (this.current._isGranularityCoarserThanDay()) {
        return false;
      }
      currentInDay = this.current.inGranularity('day');
      if (ref = this.current.dowString(), indexOf.call(this.timeline.workDays, ref) < 0) {
        return true;
      }
      ref1 = this.timeline.holidays;
      for (j = 0, len = ref1.length; j < len; j++) {
        holiday = ref1[j];
        if (utils.match(holiday, currentInDay)) {
          return true;
        }
      }
      if ((ref2 = this.timeline.granularity) === 'hour' || ref2 === 'minute' || ref2 === ' second' || ref2 === 'millisecond') {
        currentMinutes = this.current.hour * 60;
        if (this.current.minute != null) {
          currentMinutes += this.current.minute;
        }
        if (this.timeline.startOnWorkMinutes <= this.timeline.endBeforeWorkMinutes) {
          if ((currentMinutes < this.timeline.startOnWorkMinutes) || (currentMinutes >= this.timeline.endBeforeWorkMinutes)) {
            return true;
          }
        } else {
          if ((this.timeline.startOnWorkMinutes >= currentMinutes && currentMinutes > this.timeline.endBeforeWorkMinutes)) {
            return true;
          }
        }
      }
      return false;
    };

    TimelineIterator.prototype._proceedToNextValid = function() {
      var results;
      results = [];
      while (this.hasNext() && this._shouldBeExcluded()) {
        if (this.timeline.step > 0) {
          results.push(this.current.increment());
        } else {
          results.push(this.current.decrement());
        }
      }
      return results;
    };

    TimelineIterator.prototype.next = function() {

      /*
      @method next
      @return {Time/Timeline/Date/String} Returns the next value of the iterator. The start will be the first value returned unless it should
         be skipped due to holiday, weekend, or workhour knockouts.
       */
      var childtimeline, config, currentCopy, i, j, ref;
      if (!this.hasNext()) {
        throw new StopIteration('Cannot call next() past end.');
      }
      currentCopy = new Time(this.current);
      this.count++;
      for (i = j = ref = Math.abs(this.timeline.step); ref <= 1 ? j <= 1 : j >= 1; i = ref <= 1 ? ++j : --j) {
        if (this.timeline.step > 0) {
          this.current.increment();
        } else {
          this.current.decrement();
        }
        this._proceedToNextValid();
      }
      switch (this.tickType) {
        case 'Time':
          return currentCopy;
        case 'Date':
          return currentCopy.getJSDate(this.tz);
        case 'ISOString':
          return currentCopy.getISOStringInTZ(this.tz);
        case 'Timeline':
          config = {
            startOn: currentCopy.inGranularity(this.childGranularity),
            endBefore: this.current.inGranularity(this.childGranularity),
            workDays: this.timeline.workDays,
            holidays: this.timeline.holidays,
            workDayStartOn: this.timeline.workDayStartOn,
            workDayEndBefore: this.timeline.workDayEndBefore
          };
          childtimeline = new Timeline(config);
          return childtimeline;
        default:
          throw new Error("You asked for tickType " + this.tickType + ". Only 'Time', 'Date', 'ISOString', and 'Timeline' are allowed.");
      }
    };

    return TimelineIterator;

  })();

  exports.Timeline = Timeline;

  exports.TimelineIterator = TimelineIterator;

}).call(this);

});

require.define("/src/TimeInStateCalculator.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3
(function() {
  var OLAPCube, Time, TimeInStateCalculator, Timeline, ref, utils;

  OLAPCube = require('./OLAPCube').OLAPCube;

  ref = require('tztime'), utils = ref.utils, Time = ref.Time, Timeline = ref.Timeline;

  TimeInStateCalculator = (function() {

    /*
    @class TimeInStateCalculator
    
    Used to calculate how much time each uniqueID spent "in-state". You use this by querying a temporal data
    model (like Rally's Lookback API) with a predicate indicating the "state" of interest. You'll then have a list of
    snapshots where that predicate was true. You pass this in to the addSnapshots method of this previously instantiated
    TimeInStateCalculator class.
    
    Usage:
    
        {TimeInStateCalculator} = require('../')
    
        snapshots = [ 
          { id: 1, from: '2011-01-06T15:10:00.000Z', to: '2011-01-06T15:30:00.000Z', Name: 'Item A' }, # 20 minutes all within an hour
          { id: 2, from: '2011-01-06T15:50:00.000Z', to: '2011-01-06T16:10:00.000Z', Name: 'Item B' }, # 20 minutes spanning an hour
          { id: 3, from: '2011-01-07T13:00:00.000Z', to: '2011-01-07T15:20:00.000Z', Name: 'Item C' }, # start 2 hours before but overlap by 20 minutes of start
          { id: 4, from: '2011-01-06T16:40:00.000Z', to: '2011-01-06T19:00:00.000Z', Name: 'Item D' }, # 20 minutes before end of day
          { id: 5, from: '2011-01-06T16:50:00.000Z', to: '2011-01-07T15:10:00.000Z', Name: 'Item E' }, # 10 minutes before end of one day and 10 before the start of next
          { id: 6, from: '2011-01-06T16:55:00.000Z', to: '2011-01-07T15:05:00.000Z', Name: 'Item F' }, # multiple cycles over several days for a total of 20 minutes of work time
          { id: 6, from: '2011-01-07T16:55:00.000Z', to: '2011-01-10T15:05:00.000Z', Name: 'Item F modified' },
          { id: 7, from: '2011-01-06T16:40:00.000Z', to: '9999-01-01T00:00:00.000Z', Name: 'Item G' }  # continues past the range of consideration in this test
        ]
        
        granularity = 'minute'
        tz = 'America/Chicago'
    
        config =  # default work days and holidays
          granularity: granularity
          tz: tz
          endBefore: '2011-01-11T00:00:00.000'
          workDayStartOn: {hour: 9, minute: 0}  # 09:00 in Chicago is 15:00 in GMT
          workDayEndBefore: {hour: 11, minute: 0}  # 11:00 in Chicago is 17:00 in GMT  # !TODO: Change this to 5pm when I change the samples above
          validFromField: 'from'
          validToField: 'to'
          uniqueIDField: 'id'
          trackLastValueForTheseFields: ['to', 'Name']
    
        startOn = '2011-01-05T00:00:00.000Z'
        endBefore = '2011-01-11T00:00:00.000Z'
    
        tisc = new TimeInStateCalculator(config)
        tisc.addSnapshots(snapshots, startOn, endBefore)
    
        console.log(tisc.getResults())
         * [ { id: 1,
         *     ticks: 20,
         *     to_lastValue: '2011-01-06T15:30:00.000Z',
         *     Name_lastValue: 'Item A' },
         *   { id: 2,
         *     ticks: 20,
         *     to_lastValue: '2011-01-06T16:10:00.000Z',
         *     Name_lastValue: 'Item B' },
         *   { id: 3,
         *     ticks: 20,
         *     to_lastValue: '2011-01-07T15:20:00.000Z',
         *     Name_lastValue: 'Item C' },
         *   { id: 4,
         *     ticks: 20,
         *     to_lastValue: '2011-01-06T19:00:00.000Z',
         *     Name_lastValue: 'Item D' },
         *   { id: 5,
         *     ticks: 20,
         *     to_lastValue: '2011-01-07T15:10:00.000Z',
         *     Name_lastValue: 'Item E' },
         *   { id: 6,
         *     ticks: 20,
         *     to_lastValue: '2011-01-10T15:05:00.000Z',
         *     Name_lastValue: 'Item F modified' },
         *   { id: 7,
         *     ticks: 260,
         *     to_lastValue: '9999-01-01T00:00:00.000Z',
         *     Name_lastValue: 'Item G' } ]
    
    But we are not done yet. We can serialize the state of this calculator and later restore it.
    
        savedState = tisc.getStateForSaving({somekey: 'some value'})
    
    Let's incrementally update the original.
    
        snapshots = [
          { id: 7, from: '2011-01-06T16:40:00.000Z', to: '9999-01-01T00:00:00.000Z', Name: 'Item G modified' },  # same snapshot as before still going
          { id: 3, from: '2011-01-11T15:00:00.000Z', to: '2011-01-11T15:20:00.000Z', Name: 'Item C modified' },  # 20 more minutes for id 3
          { id: 8, from: '2011-01-11T15:00:00.000Z', to: '9999-01-01T00:00:00.000Z', Name: 'Item H' }   # 20 minutes in scope for new id 8
        ]
    
        startOn = '2011-01-11T00:00:00.000Z'  # must match endBefore of prior call
        endBefore = '2011-01-11T15:20:00.000Z'
    
        tisc.addSnapshots(snapshots, startOn, endBefore)
    
    Now, let's restore from saved state into tisc2 and give it the same updates and confirm that they match.
    
        tisc2 = TimeInStateCalculator.newFromSavedState(savedState)
        tisc2.addSnapshots(snapshots, startOn, endBefore)
    
        console.log(tisc2.meta.somekey)
         * some value
    
        console.log(JSON.stringify(tisc.getResults()) == JSON.stringify(tisc2.getResults()))
         * true
    
    Note, it's common to calculate time in state at granularity of hour and convert it to fractional days. Since it knocks
    out non-work hours, this conversion is not as simple as dividing by 24. This code calculates the conversion factor
    (workHours) for whatever workDayStartOn and workDayEndBefore you have specified even if your "workday" spans midnight.
    
        startOnInMinutes = config.workDayStartOn.hour * 60
        if config.workDayStartOn?.minute
          startOnInMinutes += config.workDayStartOn.minute
        endBeforeInMinutes = config.workDayEndBefore.hour * 60
        if config.workDayEndBefore?.minute
          endBeforeInMinutes += config.workDayEndBefore.minute
        if startOnInMinutes < endBeforeInMinutes
          workMinutes = endBeforeInMinutes - startOnInMinutes
        else
          workMinutes = 24 * 60 - startOnInMinutes
          workMinutes += endBeforeInMinutes
        workHours = workMinutes / 60
    
        console.log(workHours)  # Should say 2 because our work day was from 9am to 11am
         * 2
    
    You would simply divide the ticks by this `workHours` value to convert from ticks (in hours) to fractional days.
     */
    function TimeInStateCalculator(config) {

      /*
      @constructor
      @param {Object} config
      @cfg {String} tz The timezone for analysis
      @cfg {String} [validFromField = "_ValidFrom"]
      @cfg {String} [validToField = "_ValidTo"]
      @cfg {String} [uniqueIDField = "ObjectID"]
      @cfg {String} granularity This calculator will tell you how many ticks fall within the snapshots you feed in.
        This configuration value indicates the granularity of the ticks (i.e. Time.MINUTE, Time.HOUR, Time.DAY, etc.)
      @cfg {String[]/String} [workDays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']] List of days of the week that you work on. You can specify this as an Array of Strings
        (['Monday', 'Tuesday', ...]) or a single comma seperated String ("Monday,Tuesday,...").
      @cfg {Object[]} [holidays] An optional Array containing rows that are either ISOStrings or JavaScript Objects
        (mix and match). Example: `[{month: 12, day: 25}, {year: 2011, month: 11, day: 24}, "2012-12-24"]`
         Notice how you can leave off the year if the holiday falls on the same day every year.
      @cfg {Object} [workDayStartOn] An optional object in the form {hour: 8, minute: 15}. If minute is zero it can be omitted.
        If workDayStartOn is later than workDayEndBefore, then it assumes that you work the night shift and your work
        hours span midnight. If tickGranularity is "hour" or finer, you probably want to set this; if tickGranularity is
        "day" or coarser, probably not.
      @cfg {Object} [workDayEndBefore] An optional object in the form {hour: 17, minute: 0}. If minute is zero it can be omitted.
        The use of workDayStartOn and workDayEndBefore only make sense when the granularity is "hour" or finer.
        Note: If the business closes at 5:00pm, you'll want to leave workDayEndBefore to 17:00, rather
        than 17:01. Think about it, you'll be open 4:59:59.999pm, but you'll be closed at 5:00pm. This also makes all of
        the math work. 9am to 5pm means 17 - 9 = an 8 hour work day.
      @cfg {String[]} [trackLastValueForTheseFields] If provided, the last value of these fields will appear in the results.
         This is useful if you want to filter the result by where the ended or if you want information to fill in the tooltip
         for a chart.
       */
      var cubeConfig, dimensions, fieldName, i, len, metricObject, metrics, ref1;
      this.config = utils.clone(config);
      if (this.config.validFromField == null) {
        this.config.validFromField = "_ValidFrom";
      }
      if (this.config.validToField == null) {
        this.config.validToField = "_ValidTo";
      }
      if (this.config.uniqueIDField == null) {
        this.config.uniqueIDField = "ObjectID";
      }
      utils.assert(this.config.tz != null, "Must provide a timezone to this calculator.");
      utils.assert(this.config.granularity != null, "Must provide a granularity to this calculator.");
      dimensions = [
        {
          field: this.config.uniqueIDField
        }
      ];
      metrics = [
        {
          field: 'ticks',
          as: 'ticks',
          f: 'sum'
        }
      ];
      if (this.config.trackLastValueForTheseFields != null) {
        ref1 = this.config.trackLastValueForTheseFields;
        for (i = 0, len = ref1.length; i < len; i++) {
          fieldName = ref1[i];
          metricObject = {
            f: 'lastValue',
            field: fieldName
          };
          metrics.push(metricObject);
        }
      }
      cubeConfig = {
        dimensions: dimensions,
        metrics: metrics
      };
      this.cube = new OLAPCube(cubeConfig);
      this.upToDateISOString = null;
    }

    TimeInStateCalculator.prototype.addSnapshots = function(snapshots, startOn, endBefore) {

      /*
      @method addSnapshots
        Allows you to incrementally add snapshots to this calculator.
      @chainable
      @param {Object[]} snapshots An array of temporal data model snapshots.
      @param {String} startOn A ISOString (e.g. '2012-01-01T12:34:56.789Z') indicating the time start of the period of
        interest. On the second through nth call, this should equal the previous endBefore.
      @param {String} endBefore A ISOString (e.g. '2012-01-01T12:34:56.789Z') indicating the moment just past the time
        period of interest.
      @return {TimeInStateCalculator}
       */
      var i, len, s, ticks, timeline, timelineConfig;
      if (this.upToDateISOString != null) {
        utils.assert(this.upToDateISOString === startOn, "startOn (" + startOn + ") parameter should equal endBefore of previous call (" + this.upToDateISOString + ") to addSnapshots.");
      }
      this.upToDateISOString = endBefore;
      timelineConfig = utils.clone(this.config);
      timelineConfig.startOn = new Time(startOn, Time.MILLISECOND, this.config.tz);
      timelineConfig.endBefore = new Time(endBefore, Time.MILLISECOND, this.config.tz);
      timeline = new Timeline(timelineConfig);
      for (i = 0, len = snapshots.length; i < len; i++) {
        s = snapshots[i];
        ticks = timeline.ticksThatIntersect(s[this.config.validFromField], s[this.config.validToField], this.config.tz);
        s.ticks = ticks.length;
      }
      this.cube.addFacts(snapshots);
      return this;
    };

    TimeInStateCalculator.prototype.getResults = function() {

      /*
      @method getResults
        Returns the current state of the calculator
      @return {Object[]} Returns an Array of Maps like `{<uniqueIDField>: <id>, ticks: <ticks>, lastValidTo: <lastValidTo>}`
       */
      var cell, fieldName, filter, i, id, j, len, len1, out, outRow, ref1, uniqueIDs;
      out = [];
      uniqueIDs = this.cube.getDimensionValues(this.config.uniqueIDField);
      for (i = 0, len = uniqueIDs.length; i < len; i++) {
        id = uniqueIDs[i];
        filter = {};
        filter[this.config.uniqueIDField] = id;
        cell = this.cube.getCell(filter);
        outRow = {};
        outRow[this.config.uniqueIDField] = id;
        outRow.ticks = cell.ticks;
        if (this.config.trackLastValueForTheseFields != null) {
          ref1 = this.config.trackLastValueForTheseFields;
          for (j = 0, len1 = ref1.length; j < len1; j++) {
            fieldName = ref1[j];
            outRow[fieldName + '_lastValue'] = cell[fieldName + '_lastValue'];
          }
        }
        out.push(outRow);
      }
      return out;
    };

    TimeInStateCalculator.prototype.getStateForSaving = function(meta) {

      /*
      @method getStateForSaving
        Enables saving the state of this calculator. See class documentation for a detailed example.
      @param {Object} [meta] An optional parameter that will be added to the serialized output and added to the meta field
        within the deserialized calculator.
      @return {Object} Returns an Ojbect representing the state of the calculator. This Object is suitable for saving to
        to an object store. Use the static method `newFromSavedState()` with this Object as the parameter to reconstitute
        the calculator.
       */
      var out;
      out = {
        config: this.config,
        cubeSavedState: this.cube.getStateForSaving(),
        upToDateISOString: this.upToDateISOString
      };
      if (meta != null) {
        out.meta = meta;
      }
      return out;
    };

    TimeInStateCalculator.newFromSavedState = function(p) {

      /*
      @method newFromSavedState
        Deserializes a previously saved calculator and returns a new calculator. See class documentation for a detailed example.
      @static
      @param {String/Object} p A String or Object from a previously saved state
      @return {TimeInStateCalculator}
       */
      var calculator;
      if (utils.type(p) === 'string') {
        p = JSON.parse(p);
      }
      calculator = new TimeInStateCalculator(p.config);
      calculator.cube = OLAPCube.newFromSavedState(p.cubeSavedState);
      calculator.upToDateISOString = p.upToDateISOString;
      if (p.meta != null) {
        calculator.meta = p.meta;
      }
      return calculator;
    };

    return TimeInStateCalculator;

  })();

  exports.TimeInStateCalculator = TimeInStateCalculator;

}).call(this);

//# sourceMappingURL=TimeInStateCalculator.js.map

});

require.define("/src/OLAPCube.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3
(function() {
  var OLAPCube, arrayOfMaps_To_CSVStyleArray, csvStyleArray_To_ArrayOfMaps, functions, ref, utils;

  utils = require('tztime').utils;

  functions = require('./functions').functions;

  ref = require('./dataTransform'), arrayOfMaps_To_CSVStyleArray = ref.arrayOfMaps_To_CSVStyleArray, csvStyleArray_To_ArrayOfMaps = ref.csvStyleArray_To_ArrayOfMaps;

  OLAPCube = (function() {

    /*
    @class OLAPCube
    
    __An efficient, in-memory, incrementally-updateable, hierarchy-capable OLAP Cube implementation.__
    
    [OLAP Cubes](http://en.wikipedia.org/wiki/OLAP_cube) are a powerful abstraction that makes it easier to do everything
    from simple group-by operations to more complex multi-dimensional and hierarchical analysis. This implementation has
    the same conceptual ancestry as implementations found in business intelligence and OLAP database solutions. However,
    it is meant as a light weight alternative primarily targeting the goal of making it easier for developers to implement
    desired analysis. It also supports serialization and incremental updating so it's ideally
    suited for visualizations and analysis that are updated on a periodic or even continuous basis.
    
    ## Features ##
    
    * In-memory
    * Incrementally-updateable
    * Serialize (`getStateForSaving()`) and deserialize (`newFromSavedState()`) to preserve aggregations between sessions
    * Accepts simple JavaScript Objects as facts
    * Storage and output as simple JavaScript Arrays of Objects
    * Hierarchy (trees) derived from fact data assuming [materialized path](http://en.wikipedia.org/wiki/Materialized_path)
      array model commonly used with NoSQL databases
    
    ## 2D Example ##
    
    Let's walk through a simple 2D example from facts to output. Let's say you have this set of facts:
    
        facts = [
          {ProjectHierarchy: [1, 2, 3], Priority: 1, Points: 10},
          {ProjectHierarchy: [1, 2, 4], Priority: 2, Points: 5 },
          {ProjectHierarchy: [5]      , Priority: 1, Points: 17},
          {ProjectHierarchy: [1, 2]   , Priority: 1, Points: 3 },
        ]
    
    The ProjectHierarchy field models its hierarchy (tree) as an array containing a
    [materialized path](http://en.wikipedia.org/wiki/Materialized_path). The first fact is "in" Project 3 whose parent is
    Project 2, whose parent is Project 1. The second fact is "in" Project 4 whose parent is Project 2 which still has
    Project 1 as its parent. Project 5 is another root Project like Project 1; and the fourth fact is "in" Project 2.
    So the first fact will roll-up the tree and be aggregated against [1], and [1, 2] as well as [1, 2, 3]. Root Project 1
    will get the data from all but the third fact which will get aggregated against root Project 5.
    
    We specify the ProjectHierarchy field as a dimension of type 'hierarchy' and the Priorty field as a simple value dimension.
    
        dimensions = [
          {field: "ProjectHierarchy", type: 'hierarchy'},
          {field: "Priority"}
        ]
    
    This will create a 2D "cube" where each unique value for ProjectHierarchy and Priority defines a different cell.
    Note, this happens to be a 2D "cube" (more commonly referred to as a [pivot table](http://en.wikipedia.org/wiki/Pivot_Table)),
    but you can also have a 1D cube (a simple group-by), a 3D cube, or even an n-dimensional hypercube where n is greater than 3.
    
    You can specify any number of metrics to be calculated for each cell in the cube.
    
        metrics = [
          {field: "Points", f: "sum", as: "Scope"}
        ]
    
    You can use any of the aggregation functions found in Lumenize.functions except `count`. The count metric is
    automatically tracked for each cell. The `as` specification is optional unless you provide a custom function. If missing,
    it will build the name of the resulting metric from the field name and the function. So without the `as: "Scope"` the
    second metric in the example above would have been named "Points_sum".
    
    You can also use custom functions in the form of `f(values) -> return <some function of values>`.
    
    Next, we build the config parameter from our dimension and metrics specifications.
    
        config = {dimensions, metrics}
    
    Hierarchy dimensions automatically roll up but you can also tell it to keep all totals by setting config.keepTotals to
    true. The totals are then kept in the cells where one or more of the dimension values are set to `null`. Note, you
    can also set keepTotals for individual dimension and should probably use that if you have more than a few dimensions
    but we're going to set it globally here:
    
        config.keepTotals = true
    
    Now, let's create the cube.
    
        {OLAPCube} = require('../')
        cube = new OLAPCube(config, facts)
    
    `getCell()` allows you to extract a single cell. The "total" cell for all facts where Priority = 1 can be found as follows:
    
        console.log(cube.getCell({Priority: 1}))
         * { ProjectHierarchy: null, Priority: 1, _count: 3, Scope: 30 }
    
    Notice how the ProjectHierarchy field value is `null`. This is because it is a total cell for Priority dimension
    for all ProjectHierarchy values. Think of `null` values in this context as wildcards.
    
    Similarly, we can get the total for all descendants of ProjectHierarchy = [1] regarless of Priority as follows:
    
        console.log(cube.getCell({ProjectHierarchy: [1]}))
         * { ProjectHierarchy: [ 1 ], Priority: null, _count: 3, Scope: 18 }
    
    `getCell()` uses the cellIndex so it's very efficient. Using `getCell()` and `getDimensionValues()`, you can iterate
    over a slice of the OLAPCube. It is usually preferable to access the cells in place like this rather than the
    traditional OLAP approach of extracting a slice for processing. However, there is a `slice()` method for extracting
    a 2D slice.
    
        rowValues = cube.getDimensionValues('ProjectHierarchy')
        columnValues = cube.getDimensionValues('Priority')
        s = OLAPCube._padToWidth('', 7) + ' | '
        s += ((OLAPCube._padToWidth(JSON.stringify(c), 7) for c in columnValues).join(' | '))
        s += ' | '
        console.log(s)
        for r in rowValues
          s = OLAPCube._padToWidth(JSON.stringify(r), 7) + ' | '
          for c in columnValues
            cell = cube.getCell({ProjectHierarchy: r, Priority: c})
            if cell?
              cellString = JSON.stringify(cell._count)
            else
              cellString = ''
            s += OLAPCube._padToWidth(cellString, 7) + ' | '
          console.log(s)
         *         |    null |       1 |       2 |
         *    null |       4 |       3 |       1 |
         *     [1] |       3 |       2 |       1 |
         *   [1,2] |       3 |       2 |       1 |
         * [1,2,3] |       1 |       1 |         |
         * [1,2,4] |       1 |         |       1 |
         *     [5] |       1 |       1 |         |
    
    Or you can just call `toString()` method which extracts a 2D slice for tabular display. Both approachs will work on
    cubes of any number of dimensions two or greater. The manual example above extracted the `count` metric. We'll tell
    the example below to extract the `Scope` metric.
    
        console.log(cube.toString('ProjectHierarchy', 'Priority', 'Scope'))
         * |        || Total |     1     2|
         * |==============================|
         * |Total   ||    35 |    30     5|
         * |------------------------------|
         * |[1]     ||    18 |    13     5|
         * |[1,2]   ||    18 |    13     5|
         * |[1,2,3] ||    10 |    10      |
         * |[1,2,4] ||     5 |           5|
         * |[5]     ||    17 |    17      |
    
    ## Dimension types ##
    
    The following dimension types are supported:
    
    1. Single value
       * Number
       * String
       * Does not work:
         * Boolean - known to fail
         * Object - may sorta work but sort-order at least is not obvious
         * Date - not tested but may actually work
    2. Arrays as materialized path for hierarchical (tree) data
    3. Non-hierarchical Arrays ("tags")
    
    There is no need to tell the OLAPCube what type to use with the exception of #2. In that case, add `type: 'hierarchy'`
    to the dimensions row like this:
    
        dimensions = [
          {field: 'hierarchicalDimensionField', type: 'hierarchy'} #, ...
        ]
    
    ## Hierarchical (tree) data ##
    
    This OLAP Cube implementation assumes your hierarchies (trees) are modeled as a
    [materialized path](http://en.wikipedia.org/wiki/Materialized_path) array. This approach is commonly used with NoSQL databases like
    [CouchDB](http://probablyprogramming.com/2008/07/04/storing-hierarchical-data-in-couchdb) and
    [MongoDB (combining materialized path and array of ancestors)](http://docs.mongodb.org/manual/tutorial/model-tree-structures/)
    and even SQL databases supporting array types like [Postgres](http://justcramer.com/2012/04/08/using-arrays-as-materialized-paths-in-postgres/).
    
    This approach differs from the traditional OLAP/MDX fixed/named level hierarchy approach. In that approach, you assume
    that the number of levels in the hierarchy are fixed. Also, each level in the hierarchy is either represented by a different
    column (clothing example --> level 0: SEX column - mens vs womens; level 1: TYPE column - pants vs shorts vs shirts; etc.) or
    predetermined ranges of values in a single field (date example --> level 0: year; level 1: quarter; level 2: month; etc.)
    
    However, the approach used by this OLAPCube implementaion is the more general case, because it can easily simulate
    fixed/named level hierachies whereas the reverse is not true. In the clothing example above, you would simply key
    your dimension off of a derived field that was a combination of the SEX and TYPE columns (e.g. ['mens', 'pants'])
    
    ## Date/Time hierarchies ##
    
    Lumenize is designed to work well with the tzTime library. Here is an example of taking a bunch of ISOString data
    and doing timezone precise hierarchical roll up based upon the date segments (year, month).
    
        data = [
          {date: '2011-12-31T12:34:56.789Z', value: 10},
          {date: '2012-01-05T12:34:56.789Z', value: 20},
          {date: '2012-01-15T12:34:56.789Z', value: 30},
          {date: '2012-02-01T00:00:01.000Z', value: 40},
          {date: '2012-02-15T12:34:56.789Z', value: 50},
        ]
    
        {Time} = require('../')
    
        config =
          deriveFieldsOnInput: [{
            field: 'dateSegments',
            f: (row) ->
              return new Time(row.date, Time.MONTH, 'America/New_York').getSegmentsAsArray()
          }]
          metrics: [{field: 'value', f: 'sum'}]
          dimensions: [{field: 'dateSegments', type: 'hierarchy'}]
    
        cube = new OLAPCube(config, data)
        console.log(cube.toString(undefined, undefined, 'value_sum'))
         * | dateSegments | value_sum |
         * |==========================|
         * | [2011]       |        10 |
         * | [2011,12]    |        10 |
         * | [2012]       |       140 |
         * | [2012,1]     |        90 |
         * | [2012,2]     |        50 |
    
    Notice how '2012-02-01T00:00:01.000Z' got bucketed in January because the calculation was done in timezone
    'America/New_York'.
    
    ## Non-hierarchical Array fields ##
    
    If you don't specify type: 'hierarchy' and the OLAPCube sees a field whose value is an Array in a dimension field, the
    data in that fact would get aggregated against each element in the Array. So a non-hierarchical Array field like
    ['x', 'y', 'z'] would get aggregated against 'x', 'y', and 'z' rather than ['x'], ['x', 'y'], and ['x','y','z]. This
    functionality is useful for  accomplishing analytics on tags, but it can be used in other powerful ways. For instance
    let's say you have a list of events:
    
        events = [
          {name: 'Renaissance Festival', activeMonths: ['September', 'October']},
          {name: 'Concert Series', activeMonths: ['July', 'August', 'September']},
          {name: 'Fall Festival', activeMonths: ['September']}
        ]
    
    You could figure out the number of events active in each month by specifying "activeMonths" as a dimension.
    Lumenize.TimeInStateCalculator (and other calculators in Lumenize) use this technique.
     */
    function OLAPCube(userConfig, facts) {
      var d, j, k, key, l, len1, len2, len3, len4, m, n, ref1, ref2, ref3, ref4, ref5, requiredFieldsObject, value;
      this.userConfig = userConfig;

      /*
      @constructor
      @param {Object} config See Config options for details. DO NOT change the config settings after the OLAP class is instantiated.
      @param {Object[]} [facts] Optional parameter allowing the population of the OLAPCube with an intitial set of facts
        upon instantiation. Use addFacts() to add facts after instantiation.
      @cfg {Object[]} dimensions Array which specifies the fields to use as dimension fields. If the field contains a
        hierarchy array, say so in the row, (e.g. `{field: 'SomeFieldName', type: 'hierarchy'}`). Any array values that it
        finds in the supplied facts will be assumed to be tags rather than a hierarchy specification unless `type: 'hierarchy'`
        is specified.
      
        For example, let's say you have a set of facts that look like this:
      
          fact = {
            dimensionField: 'a',
            hierarchicalDimensionField: ['1','2','3'],
            tagDimensionField: ['x', 'y', 'z'],
            valueField: 10
          }
      
        Then a set of dimensions like this makes sense.
      
          config.dimensions = [
            {field: 'dimensionField'},
            {field: 'hierarchicalDimensionField', type: 'hierarchy'},
            {field: 'tagDimensionField', keepTotals: true}
          ]
      
        Notice how a keepTotals can be set for an individual dimension. This is preferable to setting it for the entire
        cube in cases where you don't want totals in all dimensions.
      
        If no dimension config is provided, then you must use syntactic sugar like groupBy.
      
      @cfg {String} [groupBy] Syntactic sugar for single-dimension/single-metric usage.
      @cfg {String} [f] Syntactic sugar for single-dimension/single-metric usage. If provided, you must also provide
        a `groupBy` config. If you provided a `groupBy` but no `f` or `field`, then the default `count` metric will be used.
      @cfg {String} [field] Syntactic sugar for single-dimension/single-metric usage. If provided, you must also provide
        a `groupBy` config. If you provided a `groupBy` but no `f` or `field`, then the default `count` metric will be used.
      
      @cfg {Object[]} [metrics=[]] Array which specifies the metrics to calculate for each cell in the cube.
      
        Example:
      
          config = {}
          config.metrics = [
            {field: 'field3'},                                      # defaults to metrics: ['sum']
            {field: 'field4', metrics: [
              {f: 'sum'},                                           # will add a metric named field4_sum
              {as: 'median4', f: 'p50'},                            # renamed p50 to median4 from default of field4_p50
              {as: 'myCount', f: (values) -> return values.length}  # user-supplied function
            ]}
          ]
      
        If you specify a field without any metrics, it will assume you want the sum but it will not automatically
        add the sum metric to fields with a metrics specification. User-supplied aggregation functions are also supported as
        shown in the 'myCount' metric above.
      
        Note, if the metric has dependencies (e.g. average depends upon count and sum) it will automatically add those to
        your metric definition. If you've already added a dependency but put it under a different "as", it's not smart
        enough to sense that and it will add it again. Either live with the slight inefficiency and duplication or leave
        dependency metrics named their default by not providing an "as" field.
      
      @cfg {Boolean} [keepTotals=false] Setting this will add an additional total row (indicated with field: null) along
        all dimensions. This setting can have an impact on the memory usage and performance of the OLAPCube so
        if things are tight, only use it if you really need it. If you don't need it for all dimension, you can specify
        keepTotals for individual dimensions.
      @cfg {Boolean} [keepFacts=false] Setting this will cause the OLAPCube to keep track of the facts that contributed to
        the metrics for each cell by adding an automatic 'facts' metric. Note, facts are restored after deserialization
        as you would expect, but they are no longer tied to the original facts. This feature, especially after a restore
        can eat up memory.
      @cfg {Object[]} [deriveFieldsOnInput] An Array of Maps in the form `{field:'myField', f:(fact)->...}`
      @cfg {Object[]} [deriveFieldsOnOutput] same format as deriveFieldsOnInput, except the callback is in the form `f(row)`
        This is only called for dirty rows that were effected by the latest round of addFacts. It's more efficient to calculate things
        like standard deviation and percentile coverage here than in config.metrics. You just have to remember to include the dependencies
        in config.metrics. Standard deviation depends upon `sum` and `sumSquares`. Percentile coverage depends upon `values`.
        In fact, if you are going to capture values anyway, all of the functions are most efficiently calculated here.
        Maybe some day, I'll write the code to analyze your metrics and move them out to here if it improves efficiency.
       */
      this.config = utils.clone(this.userConfig);
      this.cells = [];
      this.cellIndex = {};
      this.currentValues = {};
      if (this.config.groupBy != null) {
        this.config.dimensions = [
          {
            field: this.config.groupBy
          }
        ];
        if ((this.config.f != null) && (this.config.field != null)) {
          this.config.metrics = [
            {
              field: this.config.field,
              f: this.config.f
            }
          ];
        }
      }
      utils.assert(this.config.dimensions != null, 'Must provide config.dimensions.');
      if (this.config.metrics == null) {
        this.config.metrics = [];
      }
      this._dimensionValues = {};
      ref1 = this.config.dimensions;
      for (j = 0, len1 = ref1.length; j < len1; j++) {
        d = ref1[j];
        this._dimensionValues[d.field] = {};
      }
      if (!this.config.keepTotals) {
        this.config.keepTotals = false;
      }
      if (!this.config.keepFacts) {
        this.config.keepFacts = false;
      }
      ref2 = this.config.dimensions;
      for (k = 0, len2 = ref2.length; k < len2; k++) {
        d = ref2[k];
        if (this.config.keepTotals || d.keepTotals) {
          d.keepTotals = true;
        } else {
          d.keepTotals = false;
        }
      }
      functions.expandMetrics(this.config.metrics, true, true);
      requiredFieldsObject = {};
      ref3 = this.config.metrics;
      for (l = 0, len3 = ref3.length; l < len3; l++) {
        m = ref3[l];
        if (((ref4 = m.field) != null ? ref4.length : void 0) > 0) {
          requiredFieldsObject[m.field] = null;
        }
      }
      this.requiredMetricsFields = (function() {
        var results;
        results = [];
        for (key in requiredFieldsObject) {
          value = requiredFieldsObject[key];
          results.push(key);
        }
        return results;
      })();
      requiredFieldsObject = {};
      ref5 = this.config.dimensions;
      for (n = 0, len4 = ref5.length; n < len4; n++) {
        d = ref5[n];
        requiredFieldsObject[d.field] = null;
      }
      this.requiredDimensionFields = (function() {
        var results;
        results = [];
        for (key in requiredFieldsObject) {
          value = requiredFieldsObject[key];
          results.push(key);
        }
        return results;
      })();
      this.summaryMetrics = {};
      this.addFacts(facts);
    }

    OLAPCube._possibilities = function(key, type, keepTotals) {
      var a, len;
      switch (utils.type(key)) {
        case 'array':
          if (keepTotals) {
            a = [null];
          } else {
            a = [];
          }
          if (type === 'hierarchy') {
            len = key.length;
            while (len > 0) {
              a.push(key.slice(0, len));
              len--;
            }
          } else {
            if (keepTotals) {
              a = [null].concat(key);
            } else {
              a = key;
            }
          }
          return a;
        case 'string':
        case 'number':
          if (keepTotals) {
            return [null, key];
          } else {
            return [key];
          }
      }
    };

    OLAPCube._decrement = function(a, rollover) {
      var i;
      i = a.length - 1;
      a[i]--;
      while (a[i] < 0) {
        a[i] = rollover[i];
        i--;
        if (i < 0) {
          return false;
        } else {
          a[i]--;
        }
      }
      return true;
    };

    OLAPCube.prototype._expandFact = function(fact) {
      var countdownArray, d, index, j, k, l, len1, len2, len3, len4, m, more, n, out, outRow, p, possibilitiesArray, ref1, ref2, ref3, ref4, rolloverArray;
      possibilitiesArray = [];
      countdownArray = [];
      rolloverArray = [];
      ref1 = this.config.dimensions;
      for (j = 0, len1 = ref1.length; j < len1; j++) {
        d = ref1[j];
        p = OLAPCube._possibilities(fact[d.field], d.type, d.keepTotals);
        if (p === void 0) {
          console.log(fact);
        }
        possibilitiesArray.push(p);
        countdownArray.push(p.length - 1);
        rolloverArray.push(p.length - 1);
      }
      ref2 = this.config.metrics;
      for (k = 0, len2 = ref2.length; k < len2; k++) {
        m = ref2[k];
        this.currentValues[m.field] = [fact[m.field]];
      }
      out = [];
      more = true;
      while (more) {
        outRow = {};
        ref3 = this.config.dimensions;
        for (index = l = 0, len3 = ref3.length; l < len3; index = ++l) {
          d = ref3[index];
          outRow[d.field] = possibilitiesArray[index][countdownArray[index]];
        }
        outRow._count = 1;
        if (this.config.keepFacts) {
          outRow._facts = [fact];
        }
        ref4 = this.config.metrics;
        for (n = 0, len4 = ref4.length; n < len4; n++) {
          m = ref4[n];
          outRow[m.as] = m.f([fact[m.field]], void 0, void 0, outRow, m.field + '_');
        }
        out.push(outRow);
        more = OLAPCube._decrement(countdownArray, rolloverArray);
      }
      return out;
    };

    OLAPCube._extractFilter = function(row, dimensions) {
      var d, j, len1, out;
      out = {};
      for (j = 0, len1 = dimensions.length; j < len1; j++) {
        d = dimensions[j];
        out[d.field] = row[d.field];
      }
      return out;
    };

    OLAPCube.prototype._mergeExpandedFactArray = function(expandedFactArray) {
      var d, er, fieldValue, filterString, j, k, l, len1, len2, len3, m, olapRow, ref1, ref2, results;
      results = [];
      for (j = 0, len1 = expandedFactArray.length; j < len1; j++) {
        er = expandedFactArray[j];
        ref1 = this.config.dimensions;
        for (k = 0, len2 = ref1.length; k < len2; k++) {
          d = ref1[k];
          fieldValue = er[d.field];
          this._dimensionValues[d.field][JSON.stringify(fieldValue)] = fieldValue;
        }
        filterString = JSON.stringify(OLAPCube._extractFilter(er, this.config.dimensions));
        olapRow = this.cellIndex[filterString];
        if (olapRow != null) {
          ref2 = this.config.metrics;
          for (l = 0, len3 = ref2.length; l < len3; l++) {
            m = ref2[l];
            olapRow[m.as] = m.f(olapRow[m.field + '_values'], olapRow[m.as], this.currentValues[m.field], olapRow, m.field + '_');
          }
        } else {
          olapRow = er;
          this.cellIndex[filterString] = olapRow;
          this.cells.push(olapRow);
        }
        results.push(this.dirtyRows[filterString] = olapRow);
      }
      return results;
    };

    OLAPCube.prototype.addFacts = function(facts) {

      /*
      @method addFacts
        Adds facts to the OLAPCube.
      
      @chainable
      @param {Object[]} facts An Array of facts to be aggregated into OLAPCube. Each fact is a Map where the keys are the field names
        and the values are the field values (e.g. `{field1: 'a', field2: 5}`).
       */
      var d, dirtyRow, expandedFactArray, fact, fieldName, filterString, j, k, l, len1, len2, len3, len4, n, ref1, ref2, ref3;
      this.dirtyRows = {};
      if (utils.type(facts) === 'array') {
        if (facts.length <= 0) {
          return;
        }
      } else {
        if (facts != null) {
          facts = [facts];
        } else {
          return;
        }
      }
      if (this.config.deriveFieldsOnInput) {
        for (j = 0, len1 = facts.length; j < len1; j++) {
          fact = facts[j];
          ref1 = this.config.deriveFieldsOnInput;
          for (k = 0, len2 = ref1.length; k < len2; k++) {
            d = ref1[k];
            if (d.as != null) {
              fieldName = d.as;
            } else {
              fieldName = d.field;
            }
            fact[fieldName] = d.f(fact);
          }
        }
      }
      for (l = 0, len3 = facts.length; l < len3; l++) {
        fact = facts[l];
        this.addMissingFields(fact);
        this.currentValues = {};
        expandedFactArray = this._expandFact(fact);
        this._mergeExpandedFactArray(expandedFactArray);
      }
      if (this.config.deriveFieldsOnOutput != null) {
        ref2 = this.dirtyRows;
        for (filterString in ref2) {
          dirtyRow = ref2[filterString];
          ref3 = this.config.deriveFieldsOnOutput;
          for (n = 0, len4 = ref3.length; n < len4; n++) {
            d = ref3[n];
            if (d.as != null) {
              fieldName = d.as;
            } else {
              fieldName = d.field;
            }
            dirtyRow[fieldName] = d.f(dirtyRow);
          }
        }
      }
      this.dirtyRows = {};
      return this;
    };

    OLAPCube.prototype.addMissingFields = function(fact) {
      var field, j, k, len1, len2, ref1, ref2;
      ref1 = this.requiredMetricsFields;
      for (j = 0, len1 = ref1.length; j < len1; j++) {
        field = ref1[j];
        if (fact[field] === void 0) {
          fact[field] = null;
        }
      }
      ref2 = this.requiredDimensionFields;
      for (k = 0, len2 = ref2.length; k < len2; k++) {
        field = ref2[k];
        if (fact[field] == null) {
          fact[field] = '<missing>';
        }
      }
      return fact;
    };

    OLAPCube.prototype.getCells = function(filterObject) {

      /*
      @method getCells
        Returns a subset of the cells that match the supplied filter. You can perform slice and dice operations using
        this. If you have criteria for all of the dimensions, you are better off using `getCell()`. Most times, it's
        better to iterate over the unique values for the dimensions of interest using `getCell()` in place of slice or
        dice operations. However, there is a `slice()` method for extracting a 2D slice
      @param {Object} [filterObject] Specifies the constraints that the returned cells must match in the form of
        `{field1: value1, field2: value2}`. If this parameter is missing, the internal cells array is returned.
      @return {Object[]} Returns the cells that match the supplied filter
       */
      var c, j, len1, output, ref1;
      if (filterObject == null) {
        return this.cells;
      }
      output = [];
      ref1 = this.cells;
      for (j = 0, len1 = ref1.length; j < len1; j++) {
        c = ref1[j];
        if (utils.filterMatch(filterObject, c)) {
          output.push(c);
        }
      }
      return output;
    };

    OLAPCube.prototype.getCell = function(filter, defaultValue) {

      /*
      @method getCell
        Returns the single cell matching the supplied filter. Iterating over the unique values for the dimensions of
        interest, you can incrementally retrieve a slice or dice using this method. Since `getCell()` always uses an index,
        in most cases, this is better than using `getCells()` to prefetch a slice or dice.
      @param {Object} [filter={}] Specifies the constraints for the returned cell in the form of `{field1: value1, field2: value2}.
        Any fields that are specified in config.dimensions that are missing from the filter are automatically filled in
        with null. Calling `getCell()` with no parameter or `{}` will return the total of all dimensions (if @config.keepTotals=true).
      @return {Object[]} Returns the cell that match the supplied filter
       */
      var cell, d, foundIt, j, k, key, len1, len2, normalizedFilter, ref1, ref2, value;
      if (filter == null) {
        filter = {};
      }
      for (key in filter) {
        value = filter[key];
        foundIt = false;
        ref1 = this.config.dimensions;
        for (j = 0, len1 = ref1.length; j < len1; j++) {
          d = ref1[j];
          if (d.field === key) {
            foundIt = true;
          }
        }
        if (!foundIt) {
          throw new Error(key + " is not a dimension for this cube.");
        }
      }
      normalizedFilter = {};
      ref2 = this.config.dimensions;
      for (k = 0, len2 = ref2.length; k < len2; k++) {
        d = ref2[k];
        if (filter.hasOwnProperty(d.field)) {
          normalizedFilter[d.field] = filter[d.field];
        } else {
          if (d.keepTotals) {
            normalizedFilter[d.field] = null;
          } else {
            throw new Error('Must set keepTotals to use getCell with a partial filter.');
          }
        }
      }
      cell = this.cellIndex[JSON.stringify(normalizedFilter)];
      if (cell != null) {
        return cell;
      } else {
        return defaultValue;
      }
    };

    OLAPCube.prototype.getDimensionValues = function(field, descending) {
      var values;
      if (descending == null) {
        descending = false;
      }

      /*
      @method getDimensionValues
        Returns the unique values for the specified dimension in sort order.
      @param {String} field The field whose values you want
      @param {Boolean} [descending=false] Set to true if you want them in reverse order
       */
      values = utils.values(this._dimensionValues[field]);
      values.sort(OLAPCube._compare);
      if (!descending) {
        values.reverse();
      }
      return values;
    };

    OLAPCube._compare = function(a, b) {
      var aString, bString, index, j, len1, value;
      if (a === null) {
        return 1;
      }
      if (b === null) {
        return -1;
      }
      switch (utils.type(a)) {
        case 'number':
        case 'boolean':
        case 'date':
          return b - a;
        case 'array':
          for (index = j = 0, len1 = a.length; j < len1; index = ++j) {
            value = a[index];
            if (b.length - 1 >= index && value < b[index]) {
              return 1;
            }
            if (b.length - 1 >= index && value > b[index]) {
              return -1;
            }
          }
          if (a.length < b.length) {
            return 1;
          } else if (a.length > b.length) {
            return -1;
          } else {
            return 0;
          }
          break;
        case 'object':
        case 'string':
          aString = JSON.stringify(a);
          bString = JSON.stringify(b);
          if (aString < bString) {
            return 1;
          } else if (aString > bString) {
            return -1;
          } else {
            return 0;
          }
          break;
        default:
          throw new Error("Do not know how to sort objects of type " + (utils.type(a)) + ".");
      }
    };

    OLAPCube.roundToSignificance = function(value, significance) {
      var multiple;
      if (significance == null) {
        return value;
      }
      multiple = 1 / significance;
      return Math.floor(value * multiple) / multiple;
    };

    OLAPCube.prototype.toString = function(rows, columns, metric, significance) {

      /*
      @method toString
        Produces a printable table with the first dimension as the rows, the second dimension as the columns, and the count
        as the values in the table.
      @return {String} A string which will render as a table when written to the console.
      @param {String} [rows=<first dimension>]
      @param {String} [columns=<second dimension>]
      @param {String} [metric='count']
      @param {Number} [significance] The multiple to which you want to round the bucket edges. 1 means whole numbers.
       0.1 means to round to tenths. 0.01 to hundreds. Etc.
       */
      if (metric == null) {
        metric = '_count';
      }
      if (this.config.dimensions.length === 1) {
        return this.toStringOneDimension(this.config.dimensions[0].field, metric, significance);
      } else {
        return this.toStringTwoDimensions(rows, columns, metric, significance);
      }
    };

    OLAPCube.prototype.toStringOneDimension = function(field, metric, significance) {
      var cell, cellString, filter, fullWidth, indexRow, j, k, len1, len2, maxColumnWidth, r, rowLabelWidth, rowValueStrings, rowValues, s, valueStrings;
      rowValues = this.getDimensionValues(field);
      rowValueStrings = (function() {
        var j, len1, results;
        results = [];
        for (j = 0, len1 = rowValues.length; j < len1; j++) {
          r = rowValues[j];
          results.push(JSON.stringify(r));
        }
        return results;
      })();
      rowLabelWidth = Math.max.apply({}, (function() {
        var j, len1, results;
        results = [];
        for (j = 0, len1 = rowValueStrings.length; j < len1; j++) {
          s = rowValueStrings[j];
          results.push(s.length);
        }
        return results;
      })());
      rowLabelWidth = Math.max(rowLabelWidth, 'Total'.length, field.length);
      maxColumnWidth = metric.length;
      valueStrings = [];
      for (indexRow = j = 0, len1 = rowValues.length; j < len1; indexRow = ++j) {
        r = rowValues[indexRow];
        filter = {};
        filter[field] = r;
        cell = this.getCell(filter);
        if (cell != null) {
          cellString = JSON.stringify(OLAPCube.roundToSignificance(cell[metric], significance));
        } else {
          cellString = '';
        }
        maxColumnWidth = Math.max(maxColumnWidth, cellString.length);
        valueStrings.push(cellString);
      }
      maxColumnWidth += 1;
      fullWidth = rowLabelWidth + maxColumnWidth + 4;
      s = '| ' + (OLAPCube._padToWidth(field, rowLabelWidth, ' ', true)) + ' |';
      s += OLAPCube._padToWidth(metric, maxColumnWidth) + ' |';
      s += '\n|' + OLAPCube._padToWidth('', fullWidth, '=') + '|';
      for (indexRow = k = 0, len2 = rowValueStrings.length; k < len2; indexRow = ++k) {
        r = rowValueStrings[indexRow];
        s += '\n| ';
        if (r === 'null') {
          s += OLAPCube._padToWidth('Total', rowLabelWidth, ' ', true);
        } else {
          s += OLAPCube._padToWidth(r, rowLabelWidth, ' ', true);
        }
        s += ' |' + OLAPCube._padToWidth(valueStrings[indexRow], maxColumnWidth) + ' |';
        if (r === 'null') {
          s += '\n|' + OLAPCube._padToWidth('', fullWidth, '-') + '|';
        }
      }
      return s;
    };

    OLAPCube.prototype.toStringTwoDimensions = function(rows, columns, metric, significance) {
      var c, cell, cellString, columnValueStrings, columnValues, filter, fullWidth, indexColumn, indexRow, j, k, l, len1, len2, len3, len4, len5, maxColumnWidth, n, o, r, rowLabelWidth, rowValueStrings, rowValues, s, valueStrings, valueStringsRow;
      if (rows == null) {
        rows = this.config.dimensions[0].field;
      }
      if (columns == null) {
        columns = this.config.dimensions[1].field;
      }
      rowValues = this.getDimensionValues(rows);
      columnValues = this.getDimensionValues(columns);
      rowValueStrings = (function() {
        var j, len1, results;
        results = [];
        for (j = 0, len1 = rowValues.length; j < len1; j++) {
          r = rowValues[j];
          results.push(JSON.stringify(r));
        }
        return results;
      })();
      columnValueStrings = (function() {
        var j, len1, results;
        results = [];
        for (j = 0, len1 = columnValues.length; j < len1; j++) {
          c = columnValues[j];
          results.push(JSON.stringify(c));
        }
        return results;
      })();
      rowLabelWidth = Math.max.apply({}, (function() {
        var j, len1, results;
        results = [];
        for (j = 0, len1 = rowValueStrings.length; j < len1; j++) {
          s = rowValueStrings[j];
          results.push(s.length);
        }
        return results;
      })());
      rowLabelWidth = Math.max(rowLabelWidth, 'Total'.length);
      valueStrings = [];
      maxColumnWidth = Math.max.apply({}, (function() {
        var j, len1, results;
        results = [];
        for (j = 0, len1 = columnValueStrings.length; j < len1; j++) {
          s = columnValueStrings[j];
          results.push(s.length);
        }
        return results;
      })());
      maxColumnWidth = Math.max(maxColumnWidth, 'Total'.length);
      for (indexRow = j = 0, len1 = rowValues.length; j < len1; indexRow = ++j) {
        r = rowValues[indexRow];
        valueStringsRow = [];
        for (indexColumn = k = 0, len2 = columnValues.length; k < len2; indexColumn = ++k) {
          c = columnValues[indexColumn];
          filter = {};
          filter[rows] = r;
          filter[columns] = c;
          cell = this.getCell(filter);
          if (cell != null) {
            cellString = JSON.stringify(OLAPCube.roundToSignificance(cell[metric], significance));
          } else {
            cellString = '';
          }
          maxColumnWidth = Math.max(maxColumnWidth, cellString.length);
          valueStringsRow.push(cellString);
        }
        valueStrings.push(valueStringsRow);
      }
      maxColumnWidth += 1;
      s = '|' + (OLAPCube._padToWidth('', rowLabelWidth)) + ' ||';
      for (indexColumn = l = 0, len3 = columnValueStrings.length; l < len3; indexColumn = ++l) {
        c = columnValueStrings[indexColumn];
        if (c === 'null') {
          s += OLAPCube._padToWidth('Total', maxColumnWidth) + ' |';
        } else {
          s += OLAPCube._padToWidth(c, maxColumnWidth);
        }
      }
      fullWidth = rowLabelWidth + maxColumnWidth * columnValueStrings.length + 3;
      if (columnValueStrings[0] === 'null') {
        fullWidth += 2;
      }
      s += '|\n|' + OLAPCube._padToWidth('', fullWidth, '=');
      for (indexRow = n = 0, len4 = rowValueStrings.length; n < len4; indexRow = ++n) {
        r = rowValueStrings[indexRow];
        s += '|\n|';
        if (r === 'null') {
          s += OLAPCube._padToWidth('Total', rowLabelWidth, ' ', true);
        } else {
          s += OLAPCube._padToWidth(r, rowLabelWidth, ' ', true);
        }
        s += ' ||';
        for (indexColumn = o = 0, len5 = columnValueStrings.length; o < len5; indexColumn = ++o) {
          c = columnValueStrings[indexColumn];
          s += OLAPCube._padToWidth(valueStrings[indexRow][indexColumn], maxColumnWidth);
          if (c === 'null') {
            s += ' |';
          }
        }
        if (r === 'null') {
          s += '|\n|' + OLAPCube._padToWidth('', fullWidth, '-');
        }
      }
      s += '|';
      return s;
    };

    OLAPCube.prototype.slice = function(rows, columns, metric, significance) {

      /*
      @method slice
        Extracts a 2D slice of the data. It outputs an array of arrays (JavaScript two-dimensional array) organized as the
        C3 charting library would expect if submitting row-oriented data.
      
        Note, the calling parameters and output of this function are very similar to the 2D toString() function output
        except the data is organized as a two-dimensional array instead of newline-separated lines and the cells are
        filled with actual values instead of padded string representations of those values.
      @return {[[]]} An array of arrays with the one row for the header and each row label
      @param {String} [rows=<first dimension>]
      @param {String} [columns=<second dimension>]
      @param {String} [metric='count']
      @param {Number} [significance] The multiple to which you want to round the bucket edges. 1 means whole numbers.
        0.1 means to round to tenths. 0.01 to hundreds. Etc.
       */
      var c, cell, cellValue, columnValues, filter, indexColumn, indexRow, j, k, l, len1, len2, len3, r, rowValues, topRow, values, valuesRow;
      if (rows == null) {
        rows = this.config.dimensions[0].field;
      }
      if (columns == null) {
        columns = this.config.dimensions[1].field;
      }
      rowValues = this.getDimensionValues(rows);
      columnValues = this.getDimensionValues(columns);
      values = [];
      topRow = [];
      topRow.push('x');
      for (indexColumn = j = 0, len1 = columnValues.length; j < len1; indexColumn = ++j) {
        c = columnValues[indexColumn];
        if (c === null) {
          topRow.push('Total');
        } else {
          topRow.push(c);
        }
      }
      values.push(topRow);
      for (indexRow = k = 0, len2 = rowValues.length; k < len2; indexRow = ++k) {
        r = rowValues[indexRow];
        valuesRow = [];
        if (r === null) {
          valuesRow.push('Total');
        } else {
          valuesRow.push(r);
        }
        for (indexColumn = l = 0, len3 = columnValues.length; l < len3; indexColumn = ++l) {
          c = columnValues[indexColumn];
          filter = {};
          filter[rows] = r;
          filter[columns] = c;
          cell = this.getCell(filter);
          if (cell != null) {
            cellValue = OLAPCube.roundToSignificance(cell[metric], significance);
          } else {
            cellValue = null;
          }
          valuesRow.push(cellValue);
        }
        values.push(valuesRow);
      }
      return values;
    };

    OLAPCube._padToWidth = function(s, width, padCharacter, rightPad) {
      var padding;
      if (padCharacter == null) {
        padCharacter = ' ';
      }
      if (rightPad == null) {
        rightPad = false;
      }
      if (s.length > width) {
        return s.substr(0, width);
      }
      padding = new Array(width - s.length + 1).join(padCharacter);
      if (rightPad) {
        return s + padding;
      } else {
        return padding + s;
      }
    };

    OLAPCube.prototype.getStateForSaving = function(meta) {

      /*
      @method getStateForSaving
        Enables saving the state of an OLAPCube.
      @param {Object} [meta] An optional parameter that will be added to the serialized output and added to the meta field
        within the deserialized OLAPCube
      @return {Object} Returns an Ojbect representing the state of the OLAPCube. This Object is suitable for saving to
        to an object store. Use the static method `newFromSavedState()` with this Object as the parameter to reconstitute the OLAPCube.
      
          facts = [
            {ProjectHierarchy: [1, 2, 3], Priority: 1},
            {ProjectHierarchy: [1, 2, 4], Priority: 2},
            {ProjectHierarchy: [5]      , Priority: 1},
            {ProjectHierarchy: [1, 2]   , Priority: 1},
          ]
      
          dimensions = [
            {field: "ProjectHierarchy", type: 'hierarchy'},
            {field: "Priority"}
          ]
      
          config = {dimensions, metrics: []}
          config.keepTotals = true
      
          originalCube = new OLAPCube(config, facts)
      
          dateString = '2012-12-27T12:34:56.789Z'
          savedState = originalCube.getStateForSaving({upToDate: dateString})
          restoredCube = OLAPCube.newFromSavedState(savedState)
      
          newFacts = [
            {ProjectHierarchy: [5], Priority: 3},
            {ProjectHierarchy: [1, 2, 4], Priority: 1}
          ]
          originalCube.addFacts(newFacts)
          restoredCube.addFacts(newFacts)
      
          console.log(restoredCube.toString() == originalCube.toString())
           * true
      
          console.log(restoredCube.meta.upToDate)
           * 2012-12-27T12:34:56.789Z
       */
      var out;
      out = {
        config: this.userConfig,
        cells: this.cells,
        summaryMetrics: this.summaryMetrics
      };
      if (meta != null) {
        out.meta = meta;
      }
      return out;
    };

    OLAPCube.newFromSavedState = function(p) {

      /*
      @method newFromSavedState
        Deserializes a previously stringified OLAPCube and returns a new OLAPCube.
      
        See `getStateForSaving()` documentation for a detailed example.
      
        Note, if you have specified config.keepFacts = true, the values for the facts will be restored, however, they
        will no longer be references to the original facts. For this reason, it's usually better to include a `values` or
        `uniqueValues` metric on some ID field if you want fact drill-down support to survive a save and restore.
      @static
      @param {String/Object} p A String or Object from a previously saved OLAPCube state
      @return {OLAPCube}
       */
      var c, cube, d, fieldValue, filterString, j, k, l, len1, len2, len3, ref1, ref2, ref3;
      if (utils.type(p) === 'string') {
        p = JSON.parse(p);
      }
      cube = new OLAPCube(p.config);
      cube.summaryMetrics = p.summaryMetrics;
      if (p.meta != null) {
        cube.meta = p.meta;
      }
      if (p.cellsAsCSVStyleArray != null) {
        cube.cells = csvStyleArray_To_ArrayOfMaps(p.cellsAsCSVStyleArray);
      } else {
        cube.cells = p.cells;
      }
      cube.cellIndex = {};
      cube._dimensionValues = {};
      ref1 = cube.config.dimensions;
      for (j = 0, len1 = ref1.length; j < len1; j++) {
        d = ref1[j];
        cube._dimensionValues[d.field] = {};
      }
      ref2 = cube.cells;
      for (k = 0, len2 = ref2.length; k < len2; k++) {
        c = ref2[k];
        filterString = JSON.stringify(OLAPCube._extractFilter(c, cube.config.dimensions));
        cube.cellIndex[filterString] = c;
        ref3 = cube.config.dimensions;
        for (l = 0, len3 = ref3.length; l < len3; l++) {
          d = ref3[l];
          fieldValue = c[d.field];
          cube._dimensionValues[d.field][JSON.stringify(fieldValue)] = fieldValue;
        }
      }
      return cube;
    };

    return OLAPCube;

  })();

  exports.OLAPCube = OLAPCube;

}).call(this);

//# sourceMappingURL=OLAPCube.js.map

});

require.define("/src/functions.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3
(function() {
  var _populateDependentValues, functions, utils;

  utils = require('tztime').utils;


  /*
  @class functions
  
  Rules about dependencies:
  
    * If a function can be calculated incrementally from an oldResult and newValues, then you do not need to specify dependencies
    * If a funciton can be calculated from other incrementally calculable results, then you need only specify those dependencies
    * If a function needs the full list of values to be calculated (like percentile coverage), then you must specify 'values'
    * To support the direct passing in of OLAP cube cells, you can provide a prefix (field name) so the key in dependentValues
      can be generated
    * 'count' is special and does not use a prefix because it is not dependent up a particular field
    * You should calculate the dependencies before you calculate the thing that is depedent. The OLAP cube does some
      checking to confirm you've done this.
   */

  functions = {};

  _populateDependentValues = function(values, dependencies, dependentValues, prefix) {
    var d, j, key, len, out;
    if (dependentValues == null) {
      dependentValues = {};
    }
    if (prefix == null) {
      prefix = '';
    }
    out = {};
    for (j = 0, len = dependencies.length; j < len; j++) {
      d = dependencies[j];
      if (d === 'count') {
        if (prefix === '') {
          key = 'count';
        } else {
          key = '_count';
        }
      } else {
        key = prefix + d;
      }
      if (dependentValues[key] == null) {
        dependentValues[key] = functions[d](values, void 0, void 0, dependentValues, prefix);
      }
      out[d] = dependentValues[key];
    }
    return out;
  };


  /*
  @method sum
  @static
  @param {Number[]} [values] Must either provide values or oldResult and newValues
  @param {Number} [oldResult] for incremental calculation
  @param {Number[]} [newValues] for incremental calculation
  @return {Number} The sum of the values
   */

  functions.sum = function(values, oldResult, newValues) {
    var j, len, temp, tempValues, v;
    if (oldResult != null) {
      temp = oldResult;
      tempValues = newValues;
    } else {
      temp = 0;
      tempValues = values;
    }
    for (j = 0, len = tempValues.length; j < len; j++) {
      v = tempValues[j];
      temp += v;
    }
    return temp;
  };


  /*
  @method product
  @static
  @param {Number[]} [values] Must either provide values or oldResult and newValues
  @param {Number} [oldResult] for incremental calculation
  @param {Number[]} [newValues] for incremental calculation
  @return {Number} The product of the values
   */

  functions.product = function(values, oldResult, newValues) {
    var j, len, temp, tempValues, v;
    if (oldResult != null) {
      temp = oldResult;
      tempValues = newValues;
    } else {
      temp = 1;
      tempValues = values;
    }
    for (j = 0, len = tempValues.length; j < len; j++) {
      v = tempValues[j];
      temp = temp * v;
    }
    return temp;
  };


  /*
  @method sumSquares
  @static
  @param {Number[]} [values] Must either provide values or oldResult and newValues
  @param {Number} [oldResult] for incremental calculation
  @param {Number[]} [newValues] for incremental calculation
  @return {Number} The sum of the squares of the values
   */

  functions.sumSquares = function(values, oldResult, newValues) {
    var j, len, temp, tempValues, v;
    if (oldResult != null) {
      temp = oldResult;
      tempValues = newValues;
    } else {
      temp = 0;
      tempValues = values;
    }
    for (j = 0, len = tempValues.length; j < len; j++) {
      v = tempValues[j];
      temp += v * v;
    }
    return temp;
  };


  /*
  @method sumCubes
  @static
  @param {Number[]} [values] Must either provide values or oldResult and newValues
  @param {Number} [oldResult] for incremental calculation
  @param {Number[]} [newValues] for incremental calculation
  @return {Number} The sum of the cubes of the values
   */

  functions.sumCubes = function(values, oldResult, newValues) {
    var j, len, temp, tempValues, v;
    if (oldResult != null) {
      temp = oldResult;
      tempValues = newValues;
    } else {
      temp = 0;
      tempValues = values;
    }
    for (j = 0, len = tempValues.length; j < len; j++) {
      v = tempValues[j];
      temp += v * v * v;
    }
    return temp;
  };


  /*
  @method lastValue
  @static
  @param {Number[]} [values] Must either provide values or newValues
  @param {Number} [oldResult] Not used. It is included to make the interface consistent.
  @param {Number[]} [newValues] for incremental calculation
  @return {Number} The last value
   */

  functions.lastValue = function(values, oldResult, newValues) {
    if (newValues != null) {
      return newValues[newValues.length - 1];
    }
    return values[values.length - 1];
  };


  /*
  @method firstValue
  @static
  @param {Number[]} [values] Must either provide values or oldResult
  @param {Number} [oldResult] for incremental calculation
  @param {Number[]} [newValues] Not used. It is included to make the interface consistent.
  @return {Number} The first value
   */

  functions.firstValue = function(values, oldResult, newValues) {
    if (oldResult != null) {
      return oldResult;
    }
    return values[0];
  };


  /*
  @method count
  @static
  @param {Number[]} [values] Must either provide values or oldResult and newValues
  @param {Number} [oldResult] for incremental calculation
  @param {Number[]} [newValues] for incremental calculation
  @return {Number} The length of the values Array
   */

  functions.count = function(values, oldResult, newValues) {
    if (oldResult != null) {
      return oldResult + newValues.length;
    }
    return values.length;
  };


  /*
  @method min
  @static
  @param {Number[]} [values] Must either provide values or oldResult and newValues
  @param {Number} [oldResult] for incremental calculation
  @param {Number[]} [newValues] for incremental calculation
  @return {Number} The minimum value or null if no values
   */

  functions.min = function(values, oldResult, newValues) {
    var j, len, temp, v;
    if (oldResult != null) {
      return functions.min(newValues.concat([oldResult]));
    }
    if (values.length === 0) {
      return null;
    }
    temp = values[0];
    for (j = 0, len = values.length; j < len; j++) {
      v = values[j];
      if (v < temp) {
        temp = v;
      }
    }
    return temp;
  };


  /*
  @method max
  @static
  @param {Number[]} [values] Must either provide values or oldResult and newValues
  @param {Number} [oldResult] for incremental calculation
  @param {Number[]} [newValues] for incremental calculation
  @return {Number} The maximum value or null if no values
   */

  functions.max = function(values, oldResult, newValues) {
    var j, len, temp, v;
    if (oldResult != null) {
      return functions.max(newValues.concat([oldResult]));
    }
    if (values.length === 0) {
      return null;
    }
    temp = values[0];
    for (j = 0, len = values.length; j < len; j++) {
      v = values[j];
      if (v > temp) {
        temp = v;
      }
    }
    return temp;
  };


  /*
  @method values
  @static
  @param {Object[]} [values] Must either provide values or oldResult and newValues
  @param {Number} [oldResult] for incremental calculation
  @param {Number[]} [newValues] for incremental calculation
  @return {Array} All values (allows duplicates). Can be used for drill down.
   */

  functions.values = function(values, oldResult, newValues) {
    if (oldResult != null) {
      return oldResult.concat(newValues);
    }
    return values;
  };


  /*
  @method uniqueValues
  @static
  @param {Object[]} [values] Must either provide values or oldResult and newValues
  @param {Number} [oldResult] for incremental calculation
  @param {Number[]} [newValues] for incremental calculation
  @return {Array} Unique values. This is good for generating an OLAP dimension or drill down.
   */

  functions.uniqueValues = function(values, oldResult, newValues) {
    var j, key, l, len, len1, r, temp, temp2, tempValues, v, value;
    temp = {};
    if (oldResult != null) {
      for (j = 0, len = oldResult.length; j < len; j++) {
        r = oldResult[j];
        temp[r] = null;
      }
      tempValues = newValues;
    } else {
      tempValues = values;
    }
    temp2 = [];
    for (l = 0, len1 = tempValues.length; l < len1; l++) {
      v = tempValues[l];
      temp[v] = null;
    }
    for (key in temp) {
      value = temp[key];
      temp2.push(key);
    }
    return temp2;
  };


  /*
  @method average
  @static
  @param {Number[]} [values] Must either provide values or oldResult and newValues
  @param {Number} [oldResult] not used by this function but included so all functions have a consistent signature
  @param {Number[]} [newValues] not used by this function but included so all functions have a consistent signature
  @param {Object} [dependentValues] If the function can be calculated from the results of other functions, this allows
    you to provide those pre-calculated values.
  @return {Number} The arithmetic mean
   */

  functions.average = function(values, oldResult, newValues, dependentValues, prefix) {
    var count, ref, sum;
    ref = _populateDependentValues(values, functions.average.dependencies, dependentValues, prefix), count = ref.count, sum = ref.sum;
    if (count === 0) {
      return null;
    } else {
      return sum / count;
    }
  };

  functions.average.dependencies = ['count', 'sum'];


  /*
  @method errorSquared
  @static
  @param {Number[]} [values] Must either provide values or oldResult and newValues
  @param {Number} [oldResult] not used by this function but included so all functions have a consistent signature
  @param {Number[]} [newValues] not used by this function but included so all functions have a consistent signature
  @param {Object} [dependentValues] If the function can be calculated from the results of other functions, this allows
    you to provide those pre-calculated values.
  @return {Number} The error squared
   */

  functions.errorSquared = function(values, oldResult, newValues, dependentValues, prefix) {
    var count, difference, errorSquared, j, len, mean, ref, sum, v;
    ref = _populateDependentValues(values, functions.errorSquared.dependencies, dependentValues, prefix), count = ref.count, sum = ref.sum;
    mean = sum / count;
    errorSquared = 0;
    for (j = 0, len = values.length; j < len; j++) {
      v = values[j];
      difference = v - mean;
      errorSquared += difference * difference;
    }
    return errorSquared;
  };

  functions.errorSquared.dependencies = ['count', 'sum'];


  /*
  @method variance
  @static
  @param {Number[]} [values] Must either provide values or oldResult and newValues
  @param {Number} [oldResult] not used by this function but included so all functions have a consistent signature
  @param {Number[]} [newValues] not used by this function but included so all functions have a consistent signature
  @param {Object} [dependentValues] If the function can be calculated from the results of other functions, this allows
    you to provide those pre-calculated values.
  @return {Number} The variance
   */

  functions.variance = function(values, oldResult, newValues, dependentValues, prefix) {
    var count, ref, sum, sumSquares;
    ref = _populateDependentValues(values, functions.variance.dependencies, dependentValues, prefix), count = ref.count, sum = ref.sum, sumSquares = ref.sumSquares;
    if (count === 0) {
      return null;
    } else if (count === 1) {
      return 0;
    } else {
      return (count * sumSquares - sum * sum) / (count * (count - 1));
    }
  };

  functions.variance.dependencies = ['count', 'sum', 'sumSquares'];


  /*
  @method standardDeviation
  @static
  @param {Number[]} [values] Must either provide values or oldResult and newValues
  @param {Number} [oldResult] not used by this function but included so all functions have a consistent signature
  @param {Number[]} [newValues] not used by this function but included so all functions have a consistent signature
  @param {Object} [dependentValues] If the function can be calculated from the results of other functions, this allows
    you to provide those pre-calculated values.
  @return {Number} The standard deviation
   */

  functions.standardDeviation = function(values, oldResult, newValues, dependentValues, prefix) {
    return Math.sqrt(functions.variance(values, oldResult, newValues, dependentValues, prefix));
  };

  functions.standardDeviation.dependencies = functions.variance.dependencies;


  /*
  @method percentileCreator
  @static
  @param {Number} p The percentile for the resulting function (50 = median, 75, 99, etc.)
  @return {Function} A function to calculate the percentile
  
  When the user passes in `p<n>` as an aggregation function, this `percentileCreator` is called to return the appropriate
  percentile function. The returned function will find the `<n>`th percentile where `<n>` is some number in the form of
  `##[.##]`. (e.g. `p40`, `p99`, `p99.9`).
  
  There is no official definition of percentile. The most popular choices differ in the interpolation algorithm that they
  use. The function returned by this `percentileCreator` uses the Excel interpolation algorithm which differs from the NIST
  primary method. However, NIST lists something very similar to the Excel approach as an acceptible alternative. The only
  difference seems to be for the edge case for when you have only two data points in your data set. Agreement with Excel,
  NIST's acceptance of it as an alternative (almost), and the fact that it makes the most sense to me is why this approach
  was chosen.
  
  http://en.wikipedia.org/wiki/Percentile#Alternative_methods
  
  Note: `median` is an alias for p50. The approach chosen for calculating p50 gives you the
  exact same result as the definition for median even for edge cases like sets with only one or two data points.
   */

  functions.percentileCreator = function(p) {
    var f;
    f = function(values, oldResult, newValues, dependentValues, prefix) {
      var d, k, n, sortfunc, vLength;
      if (values == null) {
        values = _populateDependentValues(values, ['values'], dependentValues, prefix).values;
      }
      if (values.length === 0) {
        return null;
      }
      sortfunc = function(a, b) {
        return a - b;
      };
      vLength = values.length;
      values.sort(sortfunc);
      n = (p * (vLength - 1) / 100) + 1;
      k = Math.floor(n);
      d = n - k;
      if (n === 1) {
        return values[1 - 1];
      }
      if (n === vLength) {
        return values[vLength - 1];
      }
      return values[k - 1] + d * (values[k] - values[k - 1]);
    };
    f.dependencies = ['values'];
    return f;
  };


  /*
  @method median
  @static
  @param {Number[]} [values] Must either provide values or oldResult and newValues
  @param {Number} [oldResult] not used by this function but included so all functions have a consistent signature
  @param {Number[]} [newValues] not used by this function but included so all functions have a consistent signature
  @param {Object} [dependentValues] If the function can be calculated from the results of other functions, this allows
    you to provide those pre-calculated values.
  @return {Number} The median
   */

  functions.median = functions.percentileCreator(50);

  functions.expandFandAs = function(a) {

    /*
    @method expandFandAs
    @static
    @param {Object} a Will look like this `{as: 'mySum', f: 'sum', field: 'Points'}`
    @return {Object} returns the expanded specification
    
    Takes specifications for functions and expands them to include the actual function and 'as'. If you do not provide
    an 'as' property, it will build it from the field name and function with an underscore between. Also, if the
    'f' provided is a string, it is copied over to the 'metric' property before the 'f' property is replaced with the
    actual function. `{field: 'a', f: 'sum'}` would expand to `{as: 'a_sum', field: 'a', metric: 'sum', f: [Function]}`.
     */
    var p;
    utils.assert(a.f != null, "'f' missing from specification: \n" + (JSON.stringify(a, void 0, 4)));
    if (utils.type(a.f) === 'function') {
      utils.assert(a.as != null, 'Must provide "as" field with your aggregation when providing a user defined function');
      a.metric = a.f.toString();
    } else if (functions[a.f] != null) {
      a.metric = a.f;
      a.f = functions[a.f];
    } else if (a.f.substr(0, 1) === 'p') {
      a.metric = a.f;
      p = /\p(\d+(.\d+)?)/.exec(a.f)[1];
      a.f = functions.percentileCreator(Number(p));
    } else {
      throw new Error(a.f + " is not a recognized built-in function");
    }
    if (a.as == null) {
      if (a.metric === 'count') {
        a.field = '';
        a.metric = 'count';
      }
      a.as = a.field + "_" + a.metric;
      utils.assert((a.field != null) || a.f === 'count', "'field' missing from specification: \n" + (JSON.stringify(a, void 0, 4)));
    }
    return a;
  };

  functions.expandMetrics = function(metrics, addCountIfMissing, addValuesForCustomFunctions) {
    var assureDependenciesAbove, confirmMetricAbove, countRow, dependencies, hasCount, index, j, l, len, len1, m, metricsRow, valuesRow;
    if (metrics == null) {
      metrics = [];
    }
    if (addCountIfMissing == null) {
      addCountIfMissing = false;
    }
    if (addValuesForCustomFunctions == null) {
      addValuesForCustomFunctions = false;
    }

    /*
    @method expandMetrics
    @static
    @private
    
    This is called internally by several Lumenize Calculators. You should probably not call it.
     */
    confirmMetricAbove = function(m, fieldName, aboveThisIndex) {
      var currentRow, i, lookingFor, metricsLength;
      if (m === 'count') {
        lookingFor = '_' + m;
      } else {
        lookingFor = fieldName + '_' + m;
      }
      i = 0;
      while (i < aboveThisIndex) {
        currentRow = metrics[i];
        if (currentRow.as === lookingFor) {
          return true;
        }
        i++;
      }
      i = aboveThisIndex + 1;
      metricsLength = metrics.length;
      while (i < metricsLength) {
        currentRow = metrics[i];
        if (currentRow.as === lookingFor) {
          throw new Error("Depdencies must appear before the metric they are dependant upon. " + m + " appears after.");
        }
        i++;
      }
      return false;
    };
    assureDependenciesAbove = function(dependencies, fieldName, aboveThisIndex) {
      var d, j, len, newRow;
      for (j = 0, len = dependencies.length; j < len; j++) {
        d = dependencies[j];
        if (!confirmMetricAbove(d, fieldName, aboveThisIndex)) {
          if (d === 'count') {
            newRow = {
              f: 'count'
            };
          } else {
            newRow = {
              f: d,
              field: fieldName
            };
          }
          functions.expandFandAs(newRow);
          metrics.unshift(newRow);
          return false;
        }
      }
      return true;
    };
    if (addValuesForCustomFunctions) {
      for (index = j = 0, len = metrics.length; j < len; index = ++j) {
        m = metrics[index];
        if (utils.type(m.f) === 'function') {
          if (m.f.dependencies == null) {
            m.f.dependencies = [];
          }
          if (m.f.dependencies[0] !== 'values') {
            m.f.dependencies.push('values');
          }
          if (!confirmMetricAbove('values', m.field, index)) {
            valuesRow = {
              f: 'values',
              field: m.field
            };
            functions.expandFandAs(valuesRow);
            metrics.unshift(valuesRow);
          }
        }
      }
    }
    hasCount = false;
    for (l = 0, len1 = metrics.length; l < len1; l++) {
      m = metrics[l];
      functions.expandFandAs(m);
      if (m.metric === 'count') {
        hasCount = true;
      }
    }
    if (addCountIfMissing && !hasCount) {
      countRow = {
        f: 'count'
      };
      functions.expandFandAs(countRow);
      metrics.unshift(countRow);
    }
    index = 0;
    while (index < metrics.length) {
      metricsRow = metrics[index];
      if (utils.type(metricsRow.f) === 'function') {
        dependencies = ['values'];
      }
      if (metricsRow.f.dependencies != null) {
        if (!assureDependenciesAbove(metricsRow.f.dependencies, metricsRow.field, index)) {
          index = -1;
        }
      }
      index++;
    }
    return metrics;
  };

  exports.functions = functions;

}).call(this);

//# sourceMappingURL=functions.js.map

});

require.define("/src/dataTransform.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3
(function() {
  var Time, arrayOfMaps_To_CSVStyleArray, arrayOfMaps_To_HighChartsSeries, csvString_To_CSVStyleArray, csvStyleArray_To_ArrayOfMaps, csvStyleArray_To_CSVString, ref, utils;

  ref = require('tztime'), utils = ref.utils, Time = ref.Time;

  csvStyleArray_To_ArrayOfMaps = function(csvStyleArray, rowKeys) {

    /*
    @method csvStyleArray_To_ArrayOfMaps
    @param {Array[]} csvStyleArray The first row is usually the list of column headers but if not, you can
      provide your own such list in the second parameter
    @param {String[]} [rowKeys] specify the column headers like `['column1', 'column2']`. If not provided, it will use
      the first row of the csvStyleArray
    @return {Object[]}
    
    `csvStyleArry_To_ArryOfMaps` is a convenience function that will convert a csvStyleArray like:
    
        {csvStyleArray_To_ArrayOfMaps} = require('../')
    
        csvStyleArray = [
          ['column1', 'column2'],
          [1         , 2       ],
          [3         , 4       ],
          [5         , 6       ]
        ]
    
    to an Array of Maps like this:
    
        console.log(csvStyleArray_To_ArrayOfMaps(csvStyleArray))
    
         * [ { column1: 1, column2: 2 },
         *   { column1: 3, column2: 4 },
         *   { column1: 5, column2: 6 } ]
     */
    var arrayOfMaps, i, index, inputRow, j, key, len, outputRow, tableLength;
    arrayOfMaps = [];
    if (rowKeys != null) {
      i = 0;
    } else {
      rowKeys = csvStyleArray[0];
      i = 1;
    }
    tableLength = csvStyleArray.length;
    while (i < tableLength) {
      inputRow = csvStyleArray[i];
      outputRow = {};
      for (index = j = 0, len = rowKeys.length; j < len; index = ++j) {
        key = rowKeys[index];
        outputRow[key] = inputRow[index];
      }
      arrayOfMaps.push(outputRow);
      i++;
    }
    return arrayOfMaps;
  };

  arrayOfMaps_To_CSVStyleArray = function(arrayOfMaps, fields) {

    /*
    @method arrayOfMaps_To_CSVStyleArray
    @param {Object[]} arrayOfMaps
    @param {String[]} [fields] If not provided, it will use the first row and get all fields
    @return {Array[]} The first row will be the column headers
    
       `arrayOfMaps_To_CSVStyleArray` is a convenience function that will convert an array of maps like:
    
        {arrayOfMaps_To_CSVStyleArray} = require('../')
    
        arrayOfMaps = [
          {column1: 10000, column2: 20000},
          {column1: 30000, column2: 40000},
          {column1: 50000, column2: 60000}
        ]
    
    to a CSV-style array like this:
    
        console.log(arrayOfMaps_To_CSVStyleArray(arrayOfMaps))
    
         * [ [ 'column1', 'column2' ],
         *   [ 10000, 20000 ],
         *   [ 30000, 40000 ],
         *   [ 50000, 60000 ] ]
     */
    var csvStyleArray, inRow, j, k, key, len, len1, outRow, ref1, value;
    if (arrayOfMaps.length === 0) {
      return [];
    }
    csvStyleArray = [];
    outRow = [];
    if (fields == null) {
      fields = [];
      ref1 = arrayOfMaps[0];
      for (key in ref1) {
        value = ref1[key];
        fields.push(key);
      }
    }
    csvStyleArray.push(fields);
    for (j = 0, len = arrayOfMaps.length; j < len; j++) {
      inRow = arrayOfMaps[j];
      outRow = [];
      for (k = 0, len1 = fields.length; k < len1; k++) {
        key = fields[k];
        outRow.push(inRow[key]);
      }
      csvStyleArray.push(outRow);
    }
    return csvStyleArray;
  };

  arrayOfMaps_To_HighChartsSeries = function(arrayOfMaps, config) {

    /*
    @method arrayOfMaps_To_HighChartsSeries
    @param {Array[]} arrayOfMaps
    @param {Object} config You can use the same config you used to call TimeSeriesCalculator including your yAxis specifications
    @return {Object[]} in HighCharts form
    
    Takes an array of arrays that came from a call to TimeSeriesCalculator and looks like this:
    
        {arrayOfMaps_To_HighChartsSeries} = require('../')
    
        arrayOfMaps = [
          {"Series 1": 8, "Series 2": 5, "Series3": 10},
          {"Series 1": 2, "Series 2": 3},
          {"Series 1": 1, "Series 2": 2, "Series3": 40},
        ]
    
    and a list of series configurations
    
        config = [
          {name: "Series 1", yAxis: 1},
          {name: "Series 2"},
          {name: "Series3"}
        ]
    
    and extracts the data into seperate series
    
        console.log(arrayOfMaps_To_HighChartsSeries(arrayOfMaps, config))
         * [ { name: 'Series 1', data: [ 8, 2, 1 ], yAxis: 1 },
         *   { name: 'Series 2', data: [ 5, 3, 2 ] },
         *   { name: 'Series3', data: [ 10, null, 40 ] } ]
    
    Notice how the extra fields from the series array are included in the output. Also, notice how the missing second
    value for Series3 was replaced with a null. HighCharts will skip right over this for category charts as you would
    expect.
     */
    var a, aggregationRow, idx, j, k, key, l, len, len1, len2, len3, m, output, outputRow, preOutput, s, seriesNames, seriesRow, value;
    preOutput = {};
    seriesNames = [];
    for (j = 0, len = config.length; j < len; j++) {
      a = config[j];
      seriesNames.push(a.name);
    }
    for (k = 0, len1 = seriesNames.length; k < len1; k++) {
      s = seriesNames[k];
      preOutput[s] = [];
      for (l = 0, len2 = arrayOfMaps.length; l < len2; l++) {
        aggregationRow = arrayOfMaps[l];
        value = aggregationRow[s];
        if (value == null) {
          value = null;
        }
        preOutput[s].push(value);
      }
    }
    output = [];
    for (idx = m = 0, len3 = seriesNames.length; m < len3; idx = ++m) {
      s = seriesNames[idx];
      outputRow = {
        name: s,
        data: preOutput[s]
      };
      seriesRow = config[idx];
      for (key in seriesRow) {
        value = seriesRow[key];
        if (key !== 'name' && key !== 'data') {
          outputRow[key] = value;
        }
      }
      output.push(outputRow);
    }
    return output;
  };

  csvString_To_CSVStyleArray = function(s, asterixForUndefined) {
    var c, cValue, error, headerLength, index, j, k, len, len1, newRow, out, rawRowArray, row, rows;
    if (asterixForUndefined == null) {
      asterixForUndefined = true;
    }
    rows = s.split('\n');
    headerLength = rows[0].split(',').length;
    out = [];
    for (index = j = 0, len = rows.length; j < len; index = ++j) {
      row = rows[index];
      newRow = [];
      rawRowArray = row.split(',');
      if (rawRowArray.length === headerLength) {
        for (k = 0, len1 = rawRowArray.length; k < len1; k++) {
          c = rawRowArray[k];
          if (asterixForUndefined && c === '*') {
            cValue = void 0;
          } else {
            try {
              cValue = JSON.parse(c);
            } catch (_error) {
              error = _error;
            }
          }
          newRow.push(cValue);
        }
        out.push(newRow);
      } else {
        console.log("Warning: Skipping row because length does not match header length in row " + index + ": " + row);
      }
    }
    return out;
  };

  csvStyleArray_To_CSVString = function(csvStyleArray) {
    var j, k, len, len1, row, s, value;
    s = '';
    for (j = 0, len = csvStyleArray.length; j < len; j++) {
      row = csvStyleArray[j];
      for (k = 0, len1 = row.length; k < len1; k++) {
        value = row[k];
        s += JSON.stringify(value) + ', ';
      }
      s += "\n";
    }
    return s;
  };

  exports.arrayOfMaps_To_CSVStyleArray = arrayOfMaps_To_CSVStyleArray;

  exports.csvStyleArray_To_ArrayOfMaps = csvStyleArray_To_ArrayOfMaps;

  exports.arrayOfMaps_To_HighChartsSeries = arrayOfMaps_To_HighChartsSeries;

  exports.csvString_To_CSVStyleArray = csvString_To_CSVStyleArray;

  exports.csvStyleArray_To_CSVString = csvStyleArray_To_CSVString;

}).call(this);

//# sourceMappingURL=dataTransform.js.map

});

require.define("/src/TransitionsCalculator.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3
(function() {
  var OLAPCube, Time, Timeline, TransitionsCalculator, ref, utils;

  OLAPCube = require('./OLAPCube').OLAPCube;

  ref = require('tztime'), utils = ref.utils, Time = ref.Time, Timeline = ref.Timeline;

  TransitionsCalculator = (function() {

    /*
    @class TransitionsCalculator
    
    Used to accumlate counts and sums about transitions.
    
    Let's say that you want to create a throughput or velocity chart where each column on the chart represents the
    number of work items that cross over from one state into another state in a given month/week/quarter/etc. You would
    send a transitions to a temporal data store like Rally's Lookback API specifying both the current values and the
    previous values. For instance, the work items crossing from "In Progress" to "Completed" could be found
    with this query clause `"_PreviousValues.ScheduleState": {"$lte": "In Progress"}, "ScheduleState": {"$gt": "In Progress"}`
    
        {TransitionsCalculator, Time} = require('../')
    
        snapshots = [
          { id: 1, from: '2011-01-03T00:00:00.000Z', PlanEstimate: 10 },
          { id: 1, from: '2011-01-05T00:00:00.000Z', PlanEstimate: 10 },
          { id: 2, from: '2011-01-04T00:00:00.000Z', PlanEstimate: 20 },
          { id: 3, from: '2011-01-10T00:00:00.000Z', PlanEstimate: 30 },
          { id: 4, from: '2011-01-11T00:00:00.000Z', PlanEstimate: 40 },
          { id: 5, from: '2011-01-17T00:00:00.000Z', PlanEstimate: 50 },
          { id: 6, from: '2011-02-07T00:00:00.000Z', PlanEstimate: 60 },
          { id: 7, from: '2011-02-08T00:00:00.000Z', PlanEstimate: 70 },
        ]
    
    But that's not the entire story. What if something crosses over into "Completed" and beyond but crosses back. It could
    do this several times and get counted multiple times. That would be bad. The way we deal with this is to also
    look for the list of snapshots that pass backwards across the boundary and subract thier impact on the final calculations.
    
    One can think of alternative aproaches for avoiding this double counting. You could, for instance, only count the last
    transition for each unique work item. The problem with this approach is that the backward moving transition might
    occur in a different time period from the forward moving one. A later snapshot could invalidate an earlier calculation
    which is bad for incremental calculation and caching. To complicate matters, the field values being summed by the
    calculator might have changed between subsequent forward/backward transitions. The chosen algorithm is the only way I know to
    preserve the idempotency and cachable incremental calculation properties.
    
        snapshotsToSubtract = [
          { id: 1, from: '2011-01-04T00:00:00.000Z', PlanEstimate: 10 },
          { id: 7, from: '2011-02-09T00:00:00.000Z', PlanEstimate: 70 },
        ]
    
    The calculator will keep track of the count of items automatically (think throughput), but if you want to sum up a
    particular field (think velocity), you can specify that with the 'fieldsToSum' config property.
    
        fieldsToSum = ['PlanEstimate']
    
    Now let's build our config object.
    
        config =
          asOf: '2011-02-10'  # Leave this off if you want it to continuously update to today
          granularity: Time.MONTH
          tz: 'America/Chicago'
          validFromField: 'from'
          validToField: 'to'
          uniqueIDField: 'id'
          fieldsToSum: fieldsToSum
          asterixToDateTimePeriod: true  # Set to false or leave off if you are going to reformat the timePeriod
    
    In most cases, you'll want to leave off the `asOf` configuration property so the data can be continuously updated
    with new snapshots as they come in. We include it in this example so the output stays stable. If we hadn't, then
    the rows would continue to grow to encompass today.
    
        startOn = '2011-01-02T00:00:00.000Z'
        endBefore = '2011-02-27T00:00:00.000Z'
    
        calculator = new TransitionsCalculator(config)
        calculator.addSnapshots(snapshots, startOn, endBefore, snapshotsToSubtract)
    
        console.log(calculator.getResults())
         * [ { timePeriod: '2011-01', count: 5, PlanEstimate: 150 },
         *   { timePeriod: '2011-02*', count: 1, PlanEstimate: 60 } ]
    
    The asterix on the last row in the results is to indicate that it is a to-date value. As more snapshots come in, this
    last row will change. The caching and incremental calcuation capability of this Calculator are designed to take
    this into account.
    
    Now, let's use the same data but aggregate in granularity of weeks.
    
        config.granularity = Time.WEEK
        calculator = new TransitionsCalculator(config)
        calculator.addSnapshots(snapshots, startOn, endBefore, snapshotsToSubtract)
    
        console.log(calculator.getResults())
         * [ { timePeriod: '2010W52', count: 1, PlanEstimate: 10 },
         *   { timePeriod: '2011W01', count: 2, PlanEstimate: 50 },
         *   { timePeriod: '2011W02', count: 2, PlanEstimate: 90 },
         *   { timePeriod: '2011W03', count: 0, PlanEstimate: 0 },
         *   { timePeriod: '2011W04', count: 0, PlanEstimate: 0 },
         *   { timePeriod: '2011W05', count: 1, PlanEstimate: 60 },
         *   { timePeriod: '2011W06*', count: 0, PlanEstimate: 0 } ]
    
    Remember, you can easily convert weeks to other granularities for display.
    
        weekStartingLabel = 'week starting ' + new Time('2010W52').inGranularity(Time.DAY).toString()
        console.log(weekStartingLabel)
         * week starting 2010-12-27
    
    If you want to display spinners while the chart is rendering, you can read this calculator's upToDateISOString property and
    compare it directly to the getResults() row's timePeriod property using code like this. Yes, this works eventhough
    upToDateISOString is an ISOString.
    
        row = {timePeriod: '2011W07'}
        if calculator.upToDateISOString < row.timePeriod
          console.log("#{row.timePeriod} not yet calculated.")
         * 2011W07 not yet calculated.
     */
    function TransitionsCalculator(config) {

      /*
      @constructor
      @param {Object} config
      @cfg {String} tz The timezone for analysis in the form like `America/New_York`
      @cfg {String} [validFromField = "_ValidFrom"]
      @cfg {String} [validToField = "_ValidTo"]
      @cfg {String} [uniqueIDField = "ObjectID"] Not used right now but when drill-down is added it will be
      @cfg {String} granularity 'month', 'week', 'quarter', etc. Use Time.MONTH, Time.WEEK, etc.
      @cfg {String[]} [fieldsToSum=[]] It will track the count automatically but it can keep a running sum of other fields also
      @cfg {Boolean} [asterixToDateTimePeriod=false] If set to true, then the still-in-progress last time period will be asterixed
       */
      var cubeConfig, dimensions, f, i, len, metrics, ref1, ref2;
      this.config = utils.clone(config);
      if (this.config.validFromField == null) {
        this.config.validFromField = "_ValidFrom";
      }
      if (this.config.validToField == null) {
        this.config.validToField = "_ValidTo";
      }
      if (this.config.uniqueIDField == null) {
        this.config.uniqueIDField = "ObjectID";
      }
      if (this.config.fieldsToSum == null) {
        this.config.fieldsToSum = [];
      }
      if (this.config.asterixToDateTimePeriod == null) {
        this.config.asterixToDateTimePeriod = false;
      }
      utils.assert(this.config.tz != null, "Must provide a timezone to this calculator.");
      utils.assert(this.config.granularity != null, "Must provide a granularity to this calculator.");
      if ((ref1 = this.config.granularity) === Time.HOUR || ref1 === Time.MINUTE || ref1 === Time.SECOND || ref1 === Time.MILLISECOND) {
        throw new Error("Transitions calculator is not designed to work on granularities finer than 'day'");
      }
      dimensions = [
        {
          field: 'timePeriod'
        }
      ];
      metrics = [
        {
          field: 'count',
          f: 'sum'
        }
      ];
      ref2 = this.config.fieldsToSum;
      for (i = 0, len = ref2.length; i < len; i++) {
        f = ref2[i];
        metrics.push({
          field: f,
          f: 'sum'
        });
      }
      cubeConfig = {
        dimensions: dimensions,
        metrics: metrics
      };
      this.cube = new OLAPCube(cubeConfig);
      this.upToDateISOString = null;
      this.lowestTimePeriod = null;
      if (this.config.asOf != null) {
        this.maxTimeString = new Time(this.config.asOf, Time.MILLISECOND).getISOStringInTZ(this.config.tz);
      } else {
        this.maxTimeString = Time.getISOStringFromJSDate();
      }
      this.virgin = true;
    }

    TransitionsCalculator.prototype.addSnapshots = function(snapshots, startOn, endBefore, snapshotsToSubtract) {
      var filteredSnapshots, filteredSnapshotsToSubstract, startOnString;
      if (snapshotsToSubtract == null) {
        snapshotsToSubtract = [];
      }

      /*
      @method addSnapshots
        Allows you to incrementally add snapshots to this calculator.
      @chainable
      @param {Object[]} snapshots An array of temporal data model snapshots.
      @param {String} startOn A ISOString (e.g. '2012-01-01T12:34:56.789Z') indicating the time start of the period of
        interest. On the second through nth call, this should equal the previous endBefore.
      @param {String} endBefore A ISOString (e.g. '2012-01-01T12:34:56.789Z') indicating the moment just past the time
        period of interest.
      @return {TransitionsCalculator}
       */
      if (this.upToDateISOString != null) {
        utils.assert(this.upToDateISOString === startOn, "startOn (" + startOn + ") parameter should equal endBefore of previous call (" + this.upToDateISOString + ") to addSnapshots.");
      }
      this.upToDateISOString = endBefore;
      startOnString = new Time(startOn, this.config.granularity, this.config.tz).toString();
      if (this.lowestTimePeriod != null) {
        if (startOnString < this.lowestTimePeriod) {
          this.lowestTimePeriod = startOnString;
        }
      } else {
        this.lowestTimePeriod = startOnString;
      }
      filteredSnapshots = this._filterSnapshots(snapshots);
      this.cube.addFacts(filteredSnapshots);
      filteredSnapshotsToSubstract = this._filterSnapshots(snapshotsToSubtract, -1);
      this.cube.addFacts(filteredSnapshotsToSubstract);
      this.virgin = false;
      return this;
    };

    TransitionsCalculator.prototype._filterSnapshots = function(snapshots, sign) {
      var f, filteredSnapshots, fs, i, j, len, len1, ref1, s;
      if (sign == null) {
        sign = 1;
      }
      filteredSnapshots = [];
      for (i = 0, len = snapshots.length; i < len; i++) {
        s = snapshots[i];
        if (s[this.config.validFromField] <= this.maxTimeString) {
          if (s.count != null) {
            throw new Error('Snapshots passed into a TransitionsCalculator cannot have a `count` field.');
          }
          if (s.timePeriod != null) {
            throw new Error('Snapshots passed into a TransitionsCalculator cannot have a `timePeriod` field.');
          }
          fs = utils.clone(s);
          fs.count = sign * 1;
          fs.timePeriod = new Time(s[this.config.validFromField], this.config.granularity, this.config.tz).toString();
          ref1 = this.config.fieldsToSum;
          for (j = 0, len1 = ref1.length; j < len1; j++) {
            f = ref1[j];
            fs[f] = sign * s[f];
          }
          filteredSnapshots.push(fs);
        }
      }
      return filteredSnapshots;
    };

    TransitionsCalculator.prototype.getResults = function() {

      /*
      @method getResults
        Returns the current state of the calculator
      @return {Object[]} Returns an Array of Maps like `{timePeriod: '2012-12', count: 10, otherField: 34}`
       */
      var cell, config, f, filter, i, j, k, len, len1, len2, out, outRow, ref1, ref2, t, timeLine, timePeriods, tp;
      if (this.virgin) {
        return [];
      }
      out = [];
      this.highestTimePeriod = new Time(this.maxTimeString, this.config.granularity, this.config.tz).toString();
      config = {
        startOn: this.lowestTimePeriod,
        endBefore: this.highestTimePeriod,
        granularity: this.config.granularity
      };
      timeLine = new Timeline(config);
      timePeriods = (function() {
        var i, len, ref1, results;
        ref1 = timeLine.getAllRaw();
        results = [];
        for (i = 0, len = ref1.length; i < len; i++) {
          t = ref1[i];
          results.push(t.toString());
        }
        return results;
      })();
      timePeriods.push(this.highestTimePeriod);
      for (i = 0, len = timePeriods.length; i < len; i++) {
        tp = timePeriods[i];
        filter = {};
        filter['timePeriod'] = tp;
        cell = this.cube.getCell(filter);
        outRow = {};
        outRow.timePeriod = tp;
        if (cell != null) {
          outRow.count = cell.count_sum;
          ref1 = this.config.fieldsToSum;
          for (j = 0, len1 = ref1.length; j < len1; j++) {
            f = ref1[j];
            outRow[f] = cell[f + '_sum'];
          }
        } else {
          outRow.count = 0;
          ref2 = this.config.fieldsToSum;
          for (k = 0, len2 = ref2.length; k < len2; k++) {
            f = ref2[k];
            outRow[f] = 0;
          }
        }
        out.push(outRow);
      }
      if (this.config.asterixToDateTimePeriod) {
        out[out.length - 1].timePeriod += '*';
      }
      return out;
    };

    TransitionsCalculator.prototype.getStateForSaving = function(meta) {

      /*
      @method getStateForSaving
        Enables saving the state of this calculator. See TimeInStateCalculator documentation for a detailed example.
      @param {Object} [meta] An optional parameter that will be added to the serialized output and added to the meta field
        within the deserialized calculator.
      @return {Object} Returns an Ojbect representing the state of the calculator. This Object is suitable for saving to
        to an object store. Use the static method `newFromSavedState()` with this Object as the parameter to reconstitute
        the calculator.
       */
      var out;
      out = {
        config: this.config,
        cubeSavedState: this.cube.getStateForSaving(),
        upToDateISOString: this.upToDateISOString,
        maxTimeString: this.maxTimeString,
        lowestTimePeriod: this.lowestTimePeriod,
        virgin: this.virgin
      };
      if (meta != null) {
        out.meta = meta;
      }
      return out;
    };

    TransitionsCalculator.newFromSavedState = function(p) {

      /*
      @method newFromSavedState
        Deserializes a previously saved calculator and returns a new calculator. See TimeInStateCalculator for a detailed example.
      @static
      @param {String/Object} p A String or Object from a previously saved state
      @return {TransitionsCalculator}
       */
      var calculator;
      if (utils.type(p) === 'string') {
        p = JSON.parse(p);
      }
      calculator = new TransitionsCalculator(p.config);
      calculator.cube = OLAPCube.newFromSavedState(p.cubeSavedState);
      calculator.upToDateISOString = p.upToDateISOString;
      calculator.maxTimeString = p.maxTimeString;
      calculator.lowestTimePeriod = p.lowestTimePeriod;
      calculator.virgin = p.virgin;
      if (p.meta != null) {
        calculator.meta = p.meta;
      }
      return calculator;
    };

    return TransitionsCalculator;

  })();

  exports.TransitionsCalculator = TransitionsCalculator;

}).call(this);

//# sourceMappingURL=TransitionsCalculator.js.map

});

require.define("/src/TimeSeriesCalculator.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3
(function() {
  var OLAPCube, Time, TimeSeriesCalculator, Timeline, functions, ref, utils,
    indexOf = [].indexOf || function(item) { for (var i = 0, l = this.length; i < l; i++) { if (i in this && this[i] === item) return i; } return -1; };

  OLAPCube = require('./OLAPCube').OLAPCube;

  ref = require('tztime'), utils = ref.utils, Time = ref.Time, Timeline = ref.Timeline;

  functions = require('./functions').functions;

  TimeSeriesCalculator = (function() {

    /*
    @class TimeSeriesCalculator
    This calculator is used to convert snapshot data into time series aggregations.
    
    Below are two examples of using the TimeSeriesCalculator. The first is a detailed example showing how you would create
    a set of single-metric series (line, spline, or column). The second, is an example of creating a set of group-by series
    (like you would use to create a stacked column or stacked area chart). You can mix and match these on the same chart, but
    one type (a set of single-metric series versus a single group-by meta-series) typically dominates.
    
    ## Time-series example - a burn chart ##
    
    Let's start with a fairly large set of snapshots and create a set of series for a burn (up/down) chart.
    
        lumenize = require('../')
        {TimeSeriesCalculator, Time} = lumenize
    
        snapshotsCSV = [
          ["ObjectID", "_ValidFrom",               "_ValidTo",                 "ScheduleState", "PlanEstimate", "TaskRemainingTotal", "TaskEstimateTotal"],
    
          [1,          "2010-10-10T15:00:00.000Z", "2011-01-02T13:00:00.000Z", "Ready to pull", 5             , 15                  , 15],
    
          [1,          "2011-01-02T13:00:00.000Z", "2011-01-02T15:10:00.000Z", "Ready to pull", 5             , 15                  , 15],
          [1,          "2011-01-02T15:10:00.000Z", "2011-01-03T15:00:00.000Z", "In progress"  , 5             , 20                  , 15],
          [2,          "2011-01-02T15:00:00.000Z", "2011-01-03T15:00:00.000Z", "Ready to pull", 3             , 5                   , 5],
          [3,          "2011-01-02T15:00:00.000Z", "2011-01-03T15:00:00.000Z", "Ready to pull", 5             , 12                  , 12],
    
          [2,          "2011-01-03T15:00:00.000Z", "2011-01-04T15:00:00.000Z", "In progress"  , 3             , 5                   , 5],
          [3,          "2011-01-03T15:00:00.000Z", "2011-01-04T15:00:00.000Z", "Ready to pull", 5             , 12                  , 12],
          [4,          "2011-01-03T15:00:00.000Z", "2011-01-04T15:00:00.000Z", "Ready to pull", 5             , 15                  , 15],
          [1,          "2011-01-03T15:10:00.000Z", "2011-01-04T15:00:00.000Z", "In progress"  , 5             , 12                  , 15],
    
          [1,          "2011-01-04T15:00:00.000Z", "2011-01-06T15:00:00.000Z", "Accepted"     , 5             , 0                   , 15],
          [2,          "2011-01-04T15:00:00.000Z", "2011-01-06T15:00:00.000Z", "In test"      , 3             , 1                   , 5],
          [3,          "2011-01-04T15:00:00.000Z", "2011-01-05T15:00:00.000Z", "In progress"  , 5             , 10                  , 12],
          [4,          "2011-01-04T15:00:00.000Z", "2011-01-06T15:00:00.000Z", "Ready to pull", 5             , 15                  , 15],
          [5,          "2011-01-04T15:00:00.000Z", "2011-01-06T15:00:00.000Z", "Ready to pull", 2             , 4                   , 4],
    
          [3,          "2011-01-05T15:00:00.000Z", "2011-01-07T15:00:00.000Z", "In test"      , 5             , 5                   , 12],
    
          [1,          "2011-01-06T15:00:00.000Z", "2011-01-07T15:00:00.000Z", "Released"     , 5             , 0                   , 15],
          [2,          "2011-01-06T15:00:00.000Z", "2011-01-07T15:00:00.000Z", "Accepted"     , 3             , 0                   , 5],
          [4,          "2011-01-06T15:00:00.000Z", "2011-01-07T15:00:00.000Z", "In progress"  , 5             , 7                   , 15],
          [5,          "2011-01-06T15:00:00.000Z", "2011-01-07T15:00:00.000Z", "Ready to pull", 2             , 4                   , 4],
    
          [1,          "2011-01-07T15:00:00.000Z", "9999-01-01T00:00:00.000Z", "Released"     , 5            , 0                    , 15],
          [2,          "2011-01-07T15:00:00.000Z", "9999-01-01T00:00:00.000Z", "Released"     , 3            , 0                    , 5],
          [3,          "2011-01-07T15:00:00.000Z", "9999-01-01T00:00:00.000Z", "Accepted"     , 5            , 0                    , 12],
          [4,          "2011-01-07T15:00:00.000Z", "9999-01-01T00:00:00.000Z", "In test"      , 5            , 3                    , 15]  # Note: ObjectID 5 deleted
        ]
    
        snapshots = lumenize.csvStyleArray_To_ArrayOfMaps(snapshotsCSV)
    
    Let's add our first aggregation specification. You can add virtual fields to the input rows by providing your own callback function.
    
        deriveFieldsOnInput = [
          {as: 'PercentRemaining', f: (row) -> 100 * row.TaskRemainingTotal / row.TaskEstimateTotal }
        ]
    
    You can have as many of these derived fields as you wish. They are calculated in order to it's OK to use an earlier
    derived field when calculating a later one.
    
    Next, we use the native fields in the snapshots, plus our derived field above to calculate most of the chart
    series. Sums and counts are bread and butter, but all Lumenize.functions functions are supported (standardDeviation,
    median, percentile coverage, etc.) and Lumenize includes some functions specifically well suited to burn chart
    calculations (filteredSum, and filteredCount) as we shall now demonstrate.
    
        acceptedValues = ['Accepted', 'Released']
    
        metrics = [
          {as: 'StoryCountBurnUp', f: 'filteredCount', filterField: 'ScheduleState', filterValues: acceptedValues},
          {as: 'StoryUnitBurnUp', field: 'PlanEstimate', f: 'filteredSum', filterField: 'ScheduleState', filterValues: acceptedValues},
          {as: 'StoryUnitScope', field: 'PlanEstimate', f: 'sum'},
          {as: 'StoryCountScope', f: 'count'},
          {as: 'TaskUnitBurnDown', field: 'TaskRemainingTotal', f: 'sum'},
          {as: 'TaskUnitScope', field: 'TaskEstimateTotal', f: 'sum'},
          {as: 'MedianPercentRemaining', field: 'PercentRemaining', f: 'median'}
        ]
    
    Let's break this down. The first series uses a `filteredCount` function. What this says is "count the number of items
    where the ScheduleState is either 'Accepted' or 'Released' and store that in a series named 'StoryCountBurnUp'. The
    second series is very similar but instead of counting, we are summing the PlanEstimate field and sticking it in
    the StoryUnitBurnUp series. The next four series are simple sums or counts (no filtering) and the final series
    is a gratuitous use of the 'median' function least you forget that it can do more than counts and sums.
    
    Next, we specify the summary metrics for the chart. We're not really interested in displaying any summary metrics for
    this chart but we need to calculate the max values of two of the existing series in order to add the two ideal line series.
    Notice how the summary metric for TaskUnitBurnDown_max_index uses an earlier summary metric. They are calculated
    in order and made avalable in the scope of the callback function to enable this.
    
        summaryMetricsConfig = [
          {field: 'TaskUnitScope', f: 'max'},
          {field: 'TaskUnitBurnDown', f: 'max'},
          {as: 'TaskUnitBurnDown_max_index', f: (seriesData, summaryMetrics) ->
            for row, index in seriesData
              if row.TaskUnitBurnDown is summaryMetrics.TaskUnitBurnDown_max
                return index
          }
        ]
    
    The calculations from the summary metrics above are passed into the calculations for 'deriveFieldsAfterSummary'.
    Here is where we calculate two alternatives for the burn down ideal line.
    
        deriveFieldsAfterSummary = [
          {as: 'Ideal', f: (row, index, summaryMetrics, seriesData) ->
            max = summaryMetrics.TaskUnitScope_max
            increments = seriesData.length - 1
            incrementAmount = max / increments
            return Math.floor(100 * (max - index * incrementAmount)) / 100
          },
          {as: 'Ideal2', f: (row, index, summaryMetrics, seriesData) ->
            if index < summaryMetrics.TaskUnitBurnDown_max_index
              return null
            else
              max = summaryMetrics.TaskUnitBurnDown_max
              increments = seriesData.length - 1 - summaryMetrics.TaskUnitBurnDown_max_index
              incrementAmount = max / increments
              return Math.floor(100 * (max - (index - summaryMetrics.TaskUnitBurnDown_max_index) * incrementAmount)) / 100
          }
        ]
    
    The two above series ignore the row values and simply key off of the index and summaryMetrics, but you could have
    used the row values to, for instance, add two existing series to create a third.
    
    Notice how the entire seriesData is available inside of your provided callback. This would allow you to derive a metric
    off of rows other than the current row like you would for a sliding-window calculation (Shewarts method).
    
    Just like all Lumenize Calculators, we can set holidays to be knocked out of the results.
    
        holidays = [
          {year: 2011, month: 1, day: 5}  # Made up holiday to test knockout
        ]
    
    Let's build the config Object from the above specifications and instantiate the calculator.
    
        config =
          deriveFieldsOnInput: deriveFieldsOnInput
          metrics: metrics
          summaryMetricsConfig: summaryMetricsConfig
          deriveFieldsAfterSummary: deriveFieldsAfterSummary
          granularity: lumenize.Time.DAY
          tz: 'America/Chicago'
          holidays: holidays
          workDays: 'Sunday,Monday,Tuesday,Wednesday,Thursday,Friday' # They work on Sundays
    
        calculator = new TimeSeriesCalculator(config)
    
    We can now send our snapshots into the calculator.
    
        startOnISOString = new Time('2011-01-02').getISOStringInTZ(config.tz)
        upToDateISOString = new Time('2011-01-10').getISOStringInTZ(config.tz)
        calculator.addSnapshots(snapshots, startOnISOString, upToDateISOString)
    
    Note, you must specify a startOnISOString and upToDateISOString. If you send in another round of snapshots, the new startOnISOString must match
    the upToDateISOString of the prior call to addSnapshots(). This is the key to  making sure that incremental calculations don't
    skip or double count anything. You can even send in the same snapshots in a later round and they won't be double
    counted. This idempotency property is also accomplished by the precise startOnISOString (current) upToDateISOString (prior) alignment.
    If you restore the calculator from a saved state, the upToDate property will contain the prior upToDateISOString. You can use
    this to compose a query that gets all of the snapshots necessary for the update. Just query with
    `_ValidTo: {$gte: upToDate}`. Note, this will refetch all the snapshots that were still active the last time
    you updated the calculator. This is expected and necessary.
    
    Let's print out our results and see what we have.
    
        keys = ['label', 'StoryUnitScope', 'StoryCountScope', 'StoryCountBurnUp',
          'StoryUnitBurnUp', 'TaskUnitBurnDown', 'TaskUnitScope', 'Ideal', 'Ideal2', 'MedianPercentRemaining']
    
        csv = lumenize.arrayOfMaps_To_CSVStyleArray(calculator.getResults().seriesData, keys)
    
        console.log(csv.slice(1))
         *  [ [ '2011-01-02', 13, 3, 0, 0, 37, 32, 51, null, 100 ],
         *    [ '2011-01-03', 18, 4, 0, 0, 44, 47, 42.5, 44, 100 ],
         *    [ '2011-01-04', 20, 5, 1, 5, 25, 51, 34, 35.2, 41.666666666666664 ],
         *    [ '2011-01-06', 20, 5, 2, 8, 16, 51, 25.5, 26.4, 41.666666666666664 ],
         *    [ '2011-01-07', 18, 4, 3, 13, 3, 47, 17, 17.59, 0 ],
         *    [ '2011-01-09', 18, 4, 3, 13, 3, 47, 8.5, 8.79, 0 ],
         *    [ '2011-01-10', 18, 4, 3, 13, 3, 47, 0, 0, 0 ] ]
    
    ## Time-series group-by example ##
    
        allowedValues = ['Ready to pull', 'In progress', 'In test', 'Accepted', 'Released']
    
    It supports both count and sum for group-by metrics
    
        metrics = [
          {f: 'groupBySum', field: 'PlanEstimate', groupByField: 'ScheduleState', allowedValues: allowedValues},
          {f: 'groupByCount', groupByField: 'ScheduleState', allowedValues: allowedValues, prefix: 'Count '},
          {as: 'MedianTaskRemainingTotal', field: 'TaskRemainingTotal', f: 'median'}  # An example of how you might overlay a line series
        ]
    
        holidays = [
          {year: 2011, month: 1, day: 5}  # Made up holiday to test knockout
        ]
    
        config =  # default workDays
          metrics: metrics
          granularity: Time.DAY
          tz: 'America/Chicago'
          holidays: holidays
          workDays: 'Sunday,Monday,Tuesday,Wednesday,Thursday,Friday' # They work on Sundays
    
        calculator = new TimeSeriesCalculator(config)
    
        startOnISOString = new Time('2010-12-31').getISOStringInTZ(config.tz)
        upToDateISOString = new Time('2011-01-09').getISOStringInTZ(config.tz)
        calculator.addSnapshots(snapshots, startOnISOString, upToDateISOString)
    
    Here is the output of the sum metrics
    
        keys = ['label'].concat(allowedValues)
        csv = lumenize.arrayOfMaps_To_CSVStyleArray(calculator.getResults().seriesData, keys)
        console.log(csv.slice(1))
         * [ [ '2010-12-31', 5, 0, 0, 0, 0 ],
         *   [ '2011-01-02', 8, 5, 0, 0, 0 ],
         *   [ '2011-01-03', 10, 8, 0, 0, 0 ],
         *   [ '2011-01-04', 7, 0, 8, 5, 0 ],
         *   [ '2011-01-06', 2, 5, 5, 3, 5 ],
         *   [ '2011-01-07', 0, 0, 5, 5, 8 ],
         *   [ '2011-01-09', 0, 0, 5, 5, 8 ] ]
    
    Here is the output of the count metrics
    
        keys = ['label'].concat('Count ' + a for a in allowedValues)
        csv = lumenize.arrayOfMaps_To_CSVStyleArray(calculator.getResults().seriesData, keys)
        console.log(csv.slice(1))
         * [ [ '2010-12-31', 1, 0, 0, 0, 0 ],
         *   [ '2011-01-02', 2, 1, 0, 0, 0 ],
         *   [ '2011-01-03', 2, 2, 0, 0, 0 ],
         *   [ '2011-01-04', 2, 0, 2, 1, 0 ],
         *   [ '2011-01-06', 1, 1, 1, 1, 1 ],
         *   [ '2011-01-07', 0, 0, 1, 1, 2 ],
         *   [ '2011-01-09', 0, 0, 1, 1, 2 ] ]
    
    We didn't output the MedianTaskRemainingTotal metric but it's in there. I included it to demonstrate that you can
    calculate non-group-by series along side group-by series.
    
    The order of execution of all of the configurations that modify or augment the results is as follows:
    
    1. **deriveFieldsOnInput** operate on the snapshots by adding virtual fields to them. This is done when addSnapshots() is
       called before any time series calculations are run your metrics config can refer to them as if they were real fields
       on the snapshots.
    1. **metrics** which defines the seriesData.
    1. **deriveFieldsOnOutput** operates on the output seriesData table that has one row per tick. It is also done when you call
       addSnapshots() but after the seriesData calculations are completed.
    1. **summaryMetricsConfig** also operates on the seriesData table but rather than augmenting the rows in that table, it creates
       a new table (summaryMetrics) that just contains summary information. An example usage would be to find the max scope to be
       used by deriveFieldsAfterSummary to create an ideal line that burned down from that max. Note, this is run
       every time you call getResults(), so it can potentially be expensive if you fetch the results often with getResults().
    1. **deriveFieldsAfterSummary** is used next. It's essentially the same as deriveFieldsOnOutput and also creates new columns
       in the seriesData table whose rows are made up of ticks. However, it allows you to use the summary table. Only use this
       if the field calculation needs something from the summary (like an ideal line) because it is potentially more
       expensive since it's done every time you call getResults().
    1. **projectionsConfig** is the last augmentation config used.
     */
    function TimeSeriesCalculator(config) {

      /*
      @constructor
      @param {Object} config
      @cfg {String} tz The timezone for analysis
      @cfg {String} [validFromField = "_ValidFrom"]
      @cfg {String} [validToField = "_ValidTo"]
      @cfg {String} [uniqueIDField = "ObjectID"]
      @cfg {String} granularity 'month', 'week', 'quarter', 'day', etc. Use Time.MONTH, Time.WEEK, etc.
      @cfg {String[]/String} [workDays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']] List of days of the week that you work on. You can specify this as an Array of Strings
         (['Monday', 'Tuesday', ...]) or a single comma seperated String ("Monday,Tuesday,...").
      @cfg {Object[]} [holidays] An optional Array containing rows that are either ISOStrings or JavaScript Objects
        (mix and match). Example: `[{month: 12, day: 25}, {year: 2011, month: 11, day: 24}, "2012-12-24"]`
         Notice how you can leave off the year if the holiday falls on the same day every year.
      @cfg {Object} [workDayStartOn] An optional object in the form {hour: 8, minute: 15}. If minute is zero it can be omitted.
         If workDayStartOn is later than workDayEndBefore, then it assumes that you work the night shift and your work
         hours span midnight. If tickGranularity is "hour" or finer, you probably want to set this; if tickGranularity is
         "day" or coarser, probably not.
      @cfg {Object} [workDayEndBefore] An optional object in the form {hour: 17, minute: 0}. If minute is zero it can be omitted.
         The use of workDayStartOn and workDayEndBefore only make sense when the granularity is "hour" or finer.
         Note: If the business closes at 5:00pm, you'll want to leave workDayEndBefore to 17:00, rather
         than 17:01. Think about it, you'll be open 4:59:59.999pm, but you'll be closed at 5:00pm. This also makes all of
         the math work. 9am to 5pm means 17 - 9 = an 8 hour work day.
      
      @cfg {Object[]} [metrics=[]] Array which specifies the metrics to calculate for tick in time.
      
        Example:
      
          config = {}
          config.metrics = [
            {field: 'field3'},                                      # defaults to metrics: ['sum']
            {field: 'field4', metrics: [
              {f: 'sum'},                                           # will add a metric named field4_sum
              {as: 'median4', f: 'p50'},                            # renamed p50 to median4 from default of field4_p50
              {as: 'myCount', f: (values) -> return values.length}  # user-supplied function
            ]}
          ]
      
        If you specify a field without any metrics, it will assume you want the sum but it will not automatically
        add the sum metric to fields with a metrics specification. User-supplied aggregation functions are also supported as
        shown in the 'myCount' metric above.
      
        Note, if the metric has dependencies (e.g. average depends upon count and sum) it will automatically add those to
        your metric definition. If you've already added a dependency but put it under a different "as", it's not smart
        enough to sense that and it will add it again. Either live with the duplication or leave
        dependency metrics named their default by not providing an "as" field.
      @cfg {Object[]} [deriveFieldsOnInput] An Array of Maps in the form `{field:'myField', f:(fact)->...}`
      @cfg {Object[]} [deriveFieldsOnOutput] same format at deriveFieldsOnInput, except the callback is in the form `f(row)`
        This is only called for dirty rows that were effected by the latest round of additions in an incremental calculation.
      @cfg {Object[]} [summaryMetricsConfig] Allows you to specify a list of metrics to calculate on the results before returning.
        These can either be in the form of `{as: 'myMetric', field: 'field4', f:'sum'}` which would extract all of the values
        for field `field4` and pass it as the values parameter to the `f` (`sum` in this example) function (from Lumenize.functions), or
        it can be in the form of `{as: 'myMetric', f:(seriesData, summaryMetrics) -> ...}`. Note, they are calculated
        in order, so you can use the result of an earlier summaryMetric to calculate a later one.
      @cfg {Object[]} [deriveFieldsAfterSummary] same format at deriveFieldsOnInput, except the callback is in the form `f(row, index, summaryMetrics, seriesData)`
        This is called on all rows every time you call getResults() so it's less efficient than deriveFieldsOnOutput. Only use it if you need
        the summaryMetrics in your calculation.
      @cfg {Object} [projectionsConfig] Allows you to project series into the future
      
        Example:
      
          projectionsConfig = {
            limit: 100  # optional, defaults to 300
            continueWhile: (point) ->  # Optional but recommended
              return point.StoryCountScope_projection > point.StoryCountBurnUp_projection
            minFractionToConsider: 1.0 / 2.0  # optional, defaults to 1/3
            minCountToConsider: 3  # optional, defaults to 15
            series: [
              {as: 'ScopeProjection', field: 'StoryUnitScope', slope: 0.5},
              {field: 'StoryCountScope', slope: 0},  # 0 slope is a level projection
              {field: 'StoryCountBurnUp'},  # Will use v-Optimal (least squares of difference in angle / count)
              {field: 'field5', startIndex: 0}  # 0 will use entire series. Add grab-handle to allow user to specify some other index
            ]
          }
      
        When a projectionsConfig is provided, the TimeSeriesCalculator will add points to the output seriesData showing
        the series being projected. These projected series will always start at the last point of the series and go out from there.
        By default, they are named the same as the series (field) they are projecting with '_projection' concatenated onto the end.
        However, this name can be overridden by using the `as` field of the series configuration.
      
        In addition to adding to the dataSeries, a summary of the projection is provided in the `projections` sub-field
        returned when you call `getResults()`. The format of this sub-field is something like this:
      
          projections = {
            "limit": 100,
            "series": [
              {"as": "ScopeProjection", "field": "StoryUnitScope", "slope": 0.5},
              {"field": "StoryCountScope", "slope": 0},
              {"field": "StoryCountBurnUp", "startIndex": 0, "slope": 0.6},
              {"field": "field5", "startIndex": 0, "slope": 0.123259838293}
            ],
            "minFractionToConsider": 0.5,
            "minCountToConsider": 3,
            "pointsAddedCount": 6,
            "lastPoint": {
              "tick": "2011-01-17T06:00:00.000Z",
              "label": "2011-01-16",
              "ScopeProjection": 21,
              "StoryCountScope_projection": 4,
              "StoryCountBurnUp_projection": 6.6
            }
          }
      
        You can inspect this returned Object to see what slope it used for each series. Also, if you were not
        rendering a chart but just wanted to use this calculator to make a holiday-knockout-precise forecast, you could
        inspect the `lastPoint.tick` field to identify when this work is forecast to finish.
      
        One thing to keep in mind when using this functionality is that these calculators in general and these projections
        in particular, is that the x-axis is a complex Timeline of ticks rather than simple linear calander time.
        So, these projections will take into account any holidays specified in the future.
      
        The `projectionsConfig` is a fairly complicated configuration in its own right. It is embedded in the config object
        for the overall TimeSeriesCalculator but it has a bunch of sub-configuration also. The five top level items are:
        `limit`, `continueWhile`, `minFractionToConsider`, `minCountToConsider`, and `series`.
      
        `limit` and `continueWhile`
        are used to control how far in the future the projection will go. It will stop at `limit` even if the `continueWhile`
        is always met. This will prevent the projection from becoming an infinite loop. The `continueWhile` predicate
        is technically not required but in almost all cases you will not know how far into the future you want to go
        so you will have to use it.
      
        `minFractionToConsider` and `minCountToConsider` are used for series where you allow the calculator to find
        the optimal starting point for the projection (the default behavior). It's very common for projects to start out slowly and then ramp up.
        The optimal algorithm is designed to find this knee where the difference in angle of the projection is the minimum
        of the square of the difference between the overall angle and all the sub-angles between this starting point going up to the point before
        the last point. This minimum is also divided by the number of points so using more data points for the projection
        is favored over using fewer. These two configuration parameters, `minFractionToConsider`, and `minCountToConsider`
        tell the v-optimal algorthim the minimum number or portion of points to consider. This prevents the algorithm
        from just using the angle of the last few points if they happen to be v-optimal. They currently default to the max of 1/3rd of the project or
        15 (3 work weeks if granularity is 'days'). Note, that the `minCountToConsider` default is optimized for
        granularity of 'days'. If you were to use granularity of weeks, I would suggest a much lower number like 3 to 5.
        If you were to use granularity of 'months' then maybe 2-3 months would suffice.
      
        The `series` sub-config is similar to the main series config, with a required `field` field and an optional
        `as` field. The remaining two possible fields (`startIndex` and `slope`) are both optional. They are also mutually
        exclusive with the `slope` trumping the `startIndex` in cases where both are mistakenly provided.
        If both are ommitted, then the projection will attempt to find the optimal starting point for the projection using the
        algorithm described above.
      
        If the `slope` is specified, it will override any `startingIndex` specification. You will commonly set this
        to 0 for scope series where you want the projection to only consider the current scope. If you set this manually,
        be sure to remember that the "run" (slope = rise / run) is ticks along the x-axis (holidays and weekends knocked out),
        not true calendar time. Also, note that in the output
        (`getResults().projections.series`), the slope will always be set even if you did not specify one in your original
        configuration. The startIndex or optimal (default) behaviors operate by setting this slope.
      
        The `startingIndex` is specified if you want to tell the projection from what point in time, the projection should
        start. Maybe the project doubled staff 3 months into the project and you want the projection to start from there.
        The common usage for this functionality is to provide a grab-handle on the chart and allow the user to use his
        insight combined with the visualization of the data series to pick his own optimal starting point. Note, if you
        specify a `startingIndex` you should not specify a `slope` and vice-versa.
      
        Note, that if you specify a `startIndex` or one is derived for you using the optimal algorithm, then the projection
        series will reach back into the seriesData to this startIndex. If you are using HighCharts, you will want to set
        connectNulls to true for projection series that have a startIndex. Projection series where you specify a `slope`
        start at the end of the dataSeries and only project into the future.
      
      @cfg {String/ISOString/Date/Lumenize.Time} [startOn=-infinity] This becomes the master startOn for the entire calculator limiting
        the calculator to only emit ticks equal to this or later.
      @cfg {String/ISOString/Date/Lumenize.Time} [endBefore=infinity] This becomes the master endBefore for the entire calculator
        limiting the calculator to only emit ticks before this.
       */
      var a, dimensions, f, field, fieldsMap, filterValue, filteredCountCreator, filteredSumCreator, inputCubeDimensions, inputCubeMetrics, j, k, l, len, len1, len2, len3, len4, len5, m, n, newMetrics, o, q, ref1, ref2, ref3, ref4, ref5, ref6, ref7, row, ticks, timeline, timelineConfig, tl;
      this.config = utils.clone(config);
      this.tickToLabelLookup = {};
      if (this.config.validFromField == null) {
        this.config.validFromField = "_ValidFrom";
      }
      if (this.config.validToField == null) {
        this.config.validToField = "_ValidTo";
      }
      if (this.config.uniqueIDField == null) {
        this.config.uniqueIDField = "ObjectID";
      }
      utils.assert(this.config.tz != null, "Must provide a timezone to this calculator.");
      utils.assert(this.config.granularity != null, "Must provide a granularity to this calculator.");
      newMetrics = [];
      ref1 = this.config.metrics;
      for (j = 0, len = ref1.length; j < len; j++) {
        a = ref1[j];
        if ((ref2 = a.f) === 'groupBySum' || ref2 === 'groupByCount') {
          if (a.prefix == null) {
            a.prefix = '';
          }
          ref3 = a.allowedValues;
          for (k = 0, len1 = ref3.length; k < len1; k++) {
            filterValue = ref3[k];
            row = {
              as: a.prefix + filterValue,
              filterField: a.groupByField,
              filterValues: [filterValue]
            };
            if (a.f === 'groupBySum') {
              row.field = a.field;
              row.f = 'filteredSum';
            } else {
              row.f = 'filteredCount';
            }
            newMetrics.push(row);
          }
        } else {
          newMetrics.push(a);
        }
      }
      this.config.metrics = newMetrics;
      filteredCountCreator = function(filterField, filterValues) {
        var f;
        f = function(row) {
          var ref4;
          if (ref4 = row[filterField], indexOf.call(filterValues, ref4) >= 0) {
            return 1;
          } else {
            return 0;
          }
        };
        return f;
      };
      filteredSumCreator = function(field, filterField, filterValues) {
        var f;
        f = function(row) {
          var ref4;
          if (ref4 = row[filterField], indexOf.call(filterValues, ref4) >= 0) {
            return row[field];
          } else {
            return 0;
          }
        };
        return f;
      };
      ref4 = this.config.metrics;
      for (l = 0, len2 = ref4.length; l < len2; l++) {
        a = ref4[l];
        if ((ref5 = a.f) === 'filteredCount' || ref5 === 'filteredSum') {
          if (a.f === 'filteredCount') {
            f = filteredCountCreator(a.filterField, a.filterValues);
          } else {
            f = filteredSumCreator(a.field, a.filterField, a.filterValues);
          }
          if (a.as == null) {
            throw new Error("Must provide `as` specification for a `" + a.f + "` metric.");
          }
          if (this.config.deriveFieldsOnInput == null) {
            this.config.deriveFieldsOnInput = [];
          }
          this.config.deriveFieldsOnInput.push({
            as: a.as,
            f: f
          });
          a.f = 'sum';
          a.field = a.as;
        }
      }
      inputCubeDimensions = [
        {
          field: this.config.uniqueIDField
        }, {
          field: 'tick'
        }
      ];
      fieldsMap = {};
      ref6 = this.config.metrics;
      for (n = 0, len3 = ref6.length; n < len3; n++) {
        m = ref6[n];
        if (m.field != null) {
          fieldsMap[m.field] = true;
        }
      }
      inputCubeMetrics = [];
      for (field in fieldsMap) {
        inputCubeMetrics.push({
          field: field,
          f: 'firstValue',
          as: field
        });
      }
      this.inputCubeConfig = {
        dimensions: inputCubeDimensions,
        metrics: inputCubeMetrics,
        deriveFieldsOnInput: this.config.deriveFieldsOnInput
      };
      dimensions = [
        {
          field: 'tick'
        }
      ];
      this.cubeConfig = {
        dimensions: dimensions,
        metrics: this.config.metrics,
        deriveFieldsOnOutput: this.config.deriveFieldsOnOutput
      };
      this.toDateCubeConfig = utils.clone(this.cubeConfig);
      this.toDateCubeConfig.deriveFieldsOnInput = this.config.deriveFieldsOnInput;
      this.cube = new OLAPCube(this.cubeConfig);
      this.upToDateISOString = null;
      if (this.config.summaryMetricsConfig != null) {
        ref7 = this.config.summaryMetricsConfig;
        for (o = 0, len4 = ref7.length; o < len4; o++) {
          m = ref7[o];
          functions.expandFandAs(m);
        }
      }
      if (config.startOn != null) {
        this.masterStartOnTime = new Time(config.startOn, this.config.granularity, this.config.tz);
      } else {
        this.masterStartOnTime = new Time('BEFORE_FIRST', this.config.granularity);
      }
      if (config.endBefore != null) {
        this.masterEndBeforeTime = new Time(config.endBefore, this.config.granularity, this.config.tz);
      } else {
        this.masterEndBeforeTime = new Time('PAST_LAST', this.config.granularity);
      }
      if ((config.startOn != null) && (config.endBefore != null)) {
        timelineConfig = utils.clone(this.config);
        timelineConfig.startOn = this.masterStartOnTime;
        timelineConfig.endBefore = this.masterEndBeforeTime;
        timeline = new Timeline(timelineConfig);
        ticks = timeline.getAll('Timeline', this.config.tz, this.config.granularity);
        for (q = 0, len5 = ticks.length; q < len5; q++) {
          tl = ticks[q];
          this.tickToLabelLookup[tl.endBefore.getISOStringInTZ(config.tz)] = tl.startOn.toString();
        }
      }
    }

    TimeSeriesCalculator.prototype.addSnapshots = function(snapshots, startOnISOString, upToDateISOString) {

      /*
      @method addSnapshots
        Allows you to incrementally add snapshots to this calculator.
      @chainable
      @param {Object[]} snapshots An array of temporal data model snapshots.
      @param {String} startOnISOString A ISOString (e.g. '2012-01-01T12:34:56.789Z') indicating the time start of the period of
        interest. On the second through nth call, this should equal the previous upToDateISOString.
      @param {String} upToDateISOString A ISOString (e.g. '2012-01-01T12:34:56.789Z') indicating the moment just past the time
        period of interest.
      @return {TimeInStateCalculator}
       */
      var advanceOneTimeline, advanceOneTimelineConfig, advanceOneTimelineIterator, endBeforeTime, inputCube, j, k, l, len, len1, len2, ref1, s, startOnTime, ticks, timeline, timelineConfig, tl, validSnapshots;
      if (this.upToDateISOString != null) {
        utils.assert(this.upToDateISOString === startOnISOString, "startOnISOString (" + startOnISOString + ") parameter should equal upToDateISOString of previous call (" + this.upToDateISOString + ") to addSnapshots.");
      }
      this.upToDateISOString = upToDateISOString;
      advanceOneTimelineConfig = utils.clone(this.config);
      advanceOneTimelineConfig.startOn = new Time(upToDateISOString, this.config.granularity, this.config.tz);
      delete advanceOneTimelineConfig.endBefore;
      advanceOneTimelineConfig.limit = 2;
      advanceOneTimeline = new Timeline(advanceOneTimelineConfig);
      advanceOneTimelineIterator = advanceOneTimeline.getIterator();
      advanceOneTimelineIterator.next();
      endBeforeTime = advanceOneTimelineIterator.next();
      timelineConfig = utils.clone(this.config);
      startOnTime = new Time(startOnISOString, this.config.granularity, this.config.tz);
      if (startOnTime.greaterThan(this.masterStartOnTime)) {
        timelineConfig.startOn = startOnTime;
      } else {
        timelineConfig.startOn = this.masterStartOnTime;
      }
      if (endBeforeTime.lessThan(this.masterEndBeforeTime)) {
        timelineConfig.endBefore = endBeforeTime;
      } else {
        timelineConfig.endBefore = this.masterEndBeforeTime;
      }
      this.asOfISOString = timelineConfig.endBefore.getISOStringInTZ(this.config.tz);
      timeline = new Timeline(timelineConfig);
      ticks = timeline.getAll('Timeline', this.config.tz, this.config.granularity);
      for (j = 0, len = ticks.length; j < len; j++) {
        tl = ticks[j];
        this.tickToLabelLookup[tl.endBefore.getISOStringInTZ(this.config.tz)] = tl.startOn.toString();
      }
      validSnapshots = [];
      for (k = 0, len1 = snapshots.length; k < len1; k++) {
        s = snapshots[k];
        ticks = timeline.ticksThatIntersect(s[this.config.validFromField], s[this.config.validToField], this.config.tz);
        if (ticks.length > 0) {
          s.tick = ticks;
          validSnapshots.push(s);
        }
      }
      inputCube = new OLAPCube(this.inputCubeConfig, validSnapshots);
      this.cube.addFacts(inputCube.getCells());
      if (true || this.masterEndBeforeTime.greaterThanOrEqual(endBeforeTime)) {
        this.toDateSnapshots = [];
        for (l = 0, len2 = snapshots.length; l < len2; l++) {
          s = snapshots[l];
          if ((s[this.config.validToField] > (ref1 = this.asOfISOString) && ref1 >= s[this.config.validFromField])) {
            this.toDateSnapshots.push(s);
          }
        }
      } else {
        this.toDateSnapshots = void 0;
      }
      return this;
    };

    TimeSeriesCalculator.prototype.getResults = function() {

      /*
      @method getResults
        Returns the current state of the calculator
      @return {Object[]} Returns an Array of Maps like `{<uniqueIDField>: <id>, ticks: <ticks>, lastValidTo: <lastValidTo>}`
       */
      var as, cell, d, foundFirstNullCell, highestIndexAllowed, highestIndexAllowed1, highestIndexAllowed2, index, j, k, l, labels, lastIndex, lastPoint, lastTick, len, len1, len2, len3, len4, len5, len6, len7, len8, len9, m, n, o, pointsAddedCount, projectedPoint, projectionSeries, projectionTimeline, projectionTimelineConfig, projectionTimelineIterator, projections, q, r, ref1, ref2, ref3, ref4, ref5, ref6, ref7, ref8, row, s, seriesData, startIndex, startOn, startPoint, summaryMetric, summaryMetrics, t, tick, tickIndex, ticks, toDateCell, toDateCube, u, v, values, w;
      ticks = utils.keys(this.tickToLabelLookup).sort();
      labels = (function() {
        var j, len, results;
        results = [];
        for (j = 0, len = ticks.length; j < len; j++) {
          t = ticks[j];
          results.push(this.tickToLabelLookup[t]);
        }
        return results;
      }).call(this);
      if ((this.toDateSnapshots != null) && this.toDateSnapshots.length > 0) {
        ref1 = this.toDateSnapshots;
        for (j = 0, len = ref1.length; j < len; j++) {
          s = ref1[j];
          s.tick = 'To Date';
        }
        toDateCube = new OLAPCube(this.toDateCubeConfig, this.toDateSnapshots);
        toDateCell = toDateCube.getCells()[0];
        delete toDateCell._count;
      }
      seriesData = [];
      foundFirstNullCell = false;
      for (tickIndex = k = 0, len1 = ticks.length; k < len1; tickIndex = ++k) {
        t = ticks[tickIndex];
        cell = utils.clone(this.cube.getCell({
          tick: t
        }));
        if (cell != null) {
          delete cell._count;
        } else {
          startOn = new Time(labels[tickIndex]).getISOStringInTZ(this.config.tz);
          if (toDateCell && (startOn < (ref2 = this.asOfISOString) && ref2 <= t)) {
            cell = toDateCell;
          } else {
            cell = {};
            ref3 = this.config.metrics;
            for (l = 0, len2 = ref3.length; l < len2; l++) {
              m = ref3[l];
              cell[m.as] = null;
            }
          }
          cell.tick = t;
        }
        cell.label = this.tickToLabelLookup[cell.tick];
        seriesData.push(cell);
      }
      summaryMetrics = {};
      if (this.config.summaryMetricsConfig != null) {
        ref4 = this.config.summaryMetricsConfig;
        for (n = 0, len3 = ref4.length; n < len3; n++) {
          summaryMetric = ref4[n];
          if (summaryMetric.field != null) {
            values = [];
            for (o = 0, len4 = seriesData.length; o < len4; o++) {
              row = seriesData[o];
              values.push(row[summaryMetric.field]);
            }
            summaryMetrics[summaryMetric.as] = summaryMetric.f(values);
          } else {
            summaryMetrics[summaryMetric.as] = summaryMetric.f(seriesData, summaryMetrics);
          }
        }
      }
      if (this.config.deriveFieldsAfterSummary != null) {
        for (index = q = 0, len5 = seriesData.length; q < len5; index = ++q) {
          row = seriesData[index];
          ref5 = this.config.deriveFieldsAfterSummary;
          for (r = 0, len6 = ref5.length; r < len6; r++) {
            d = ref5[r];
            row[d.as] = d.f(row, index, summaryMetrics, seriesData);
          }
        }
      }
      projections = {};
      if (this.config.projectionsConfig != null) {
        projections = utils.clone(this.config.projectionsConfig);
        lastIndex = seriesData.length - 1;
        lastPoint = seriesData[lastIndex];
        lastTick = lastPoint.tick;
        ref6 = projections.series;
        for (u = 0, len7 = ref6.length; u < len7; u++) {
          projectionSeries = ref6[u];
          as = projectionSeries.as || projectionSeries.field + "_projection";
          lastPoint[as] = lastPoint[projectionSeries.field];
        }
        ref7 = projections.series;
        for (v = 0, len8 = ref7.length; v < len8; v++) {
          projectionSeries = ref7[v];
          if (projectionSeries.slope == null) {
            if (projectionSeries.startIndex == null) {
              if (projections.minFractionToConsider == null) {
                projections.minFractionToConsider = 1.0 / 3.0;
              }
              if (projections.minCountToConsider == null) {
                projections.minCountToConsider = 15;
              }
              highestIndexAllowed1 = Math.floor((1 - projections.minFractionToConsider) * seriesData.length) - 1;
              highestIndexAllowed2 = seriesData.length - 1 - projections.minCountToConsider;
              highestIndexAllowed = Math.min(highestIndexAllowed1, highestIndexAllowed2);
              if (highestIndexAllowed < 1) {
                projectionSeries.startIndex = 0;
              } else {
                projectionSeries.startIndex = TimeSeriesCalculator._findVOptimalProjectionStartIndex(seriesData, projectionSeries.field, highestIndexAllowed);
              }
            }
            startIndex = projectionSeries.startIndex;
            startPoint = seriesData[startIndex];
            as = projectionSeries.as || projectionSeries.field + "_projection";
            startPoint[as] = startPoint[projectionSeries.field];
            projectionSeries.slope = (lastPoint[projectionSeries.field] - startPoint[projectionSeries.field]) / (lastIndex - startIndex);
          }
        }
        projectionTimelineConfig = utils.clone(this.config);
        projectionTimelineConfig.startOn = new Time(lastTick, this.config.granularity, this.config.tz);
        delete projectionTimelineConfig.endBefore;
        projectionTimelineConfig.limit = projections.limit || 300;
        projectionTimeline = new Timeline(projectionTimelineConfig);
        projectionTimelineIterator = projectionTimeline.getIterator('Timeline');
        pointsAddedCount = 0;
        projectedPoint = null;
        while (projectionTimelineIterator.hasNext() && ((projectedPoint == null) || ((projections.continueWhile == null) || projections.continueWhile(projectedPoint)))) {
          pointsAddedCount++;
          projectedPoint = {};
          tick = projectionTimelineIterator.next();
          projectedPoint.tick = tick.endBefore.getISOStringInTZ(this.config.tz);
          projectedPoint.label = tick.startOn.toString();
          ref8 = projections.series;
          for (w = 0, len9 = ref8.length; w < len9; w++) {
            projectionSeries = ref8[w];
            as = projectionSeries.as || projectionSeries.field + "_projection";
            projectedPoint[as] = lastPoint[projectionSeries.field] + pointsAddedCount * projectionSeries.slope;
          }
          seriesData.push(projectedPoint);
        }
        projections.pointsAddedCount = pointsAddedCount;
        projections.lastPoint = projectedPoint;
      }
      return {
        seriesData: seriesData,
        summaryMetrics: summaryMetrics,
        projections: projections
      };
    };

    TimeSeriesCalculator._findVOptimalProjectionStartIndex = function(seriesData, field, highestIndexAllowed) {
      var calculateTotalErrorSquared, errorSquared, i, indexForMinNormalizedErrorSquared, j, lastIndex, lastPoint, minNormalizedErrorSquared, normalizedErrorSquared, ref1, slopeToEnd;
      utils.assert(highestIndexAllowed < seriesData.length - 2, "Cannot use the last two points for calculating v-optimal slope.");
      lastIndex = seriesData.length - 1;
      lastPoint = seriesData[lastIndex];
      slopeToEnd = (function(_this) {
        return function(index) {
          return (lastPoint[field] - seriesData[index][field]) / (lastIndex - index);
        };
      })(this);
      calculateTotalErrorSquared = (function(_this) {
        return function(index) {
          var currentAngle, currentSlope, error, i, j, ref1, ref2, totalErrorSquared, trialAngle, trialSlope;
          trialSlope = slopeToEnd(index);
          trialAngle = Math.atan(trialSlope);
          totalErrorSquared = 0;
          for (i = j = ref1 = index + 1, ref2 = lastIndex - 1; ref1 <= ref2 ? j <= ref2 : j >= ref2; i = ref1 <= ref2 ? ++j : --j) {
            currentSlope = slopeToEnd(i);
            currentAngle = Math.atan(currentSlope);
            error = trialAngle - currentAngle;
            totalErrorSquared += error * error;
          }
          return totalErrorSquared;
        };
      })(this);
      minNormalizedErrorSquared = Number.MAX_VALUE;
      indexForMinNormalizedErrorSquared = highestIndexAllowed;
      for (i = j = ref1 = highestIndexAllowed; ref1 <= 0 ? j <= 0 : j >= 0; i = ref1 <= 0 ? ++j : --j) {
        errorSquared = calculateTotalErrorSquared(i);
        normalizedErrorSquared = errorSquared / (seriesData.length - 2 - i);
        if (normalizedErrorSquared <= minNormalizedErrorSquared) {
          minNormalizedErrorSquared = normalizedErrorSquared;
          indexForMinNormalizedErrorSquared = i;
        }
      }
      return indexForMinNormalizedErrorSquared;
    };

    TimeSeriesCalculator.prototype.getStateForSaving = function(meta) {

      /*
      @method getStateForSaving
        Enables saving the state of this calculator. See class documentation for a detailed example.
      @param {Object} [meta] An optional parameter that will be added to the serialized output and added to the meta field
        within the deserialized calculator.
      @return {Object} Returns an Ojbect representing the state of the calculator. This Object is suitable for saving to
        to an object store. Use the static method `newFromSavedState()` with this Object as the parameter to reconstitute
        the calculator.
       */
      var out;
      out = {
        config: this.config,
        cubeSavedState: this.cube.getStateForSaving(),
        upToDateISOString: this.upToDateISOString
      };
      if (meta != null) {
        out.meta = meta;
      }
      return out;
    };

    TimeSeriesCalculator.newFromSavedState = function(p) {

      /*
      @method newFromSavedState
        Deserializes a previously saved calculator and returns a new calculator. See class documentation for a detailed example.
      @static
      @param {String/Object} p A String or Object from a previously saved state
      @return {TimeInStateCalculator}
       */
      var calculator;
      if (utils.type(p) === 'string') {
        p = JSON.parse(p);
      }
      calculator = new TimeSeriesCalculator(p.config);
      calculator.cube = OLAPCube.newFromSavedState(p.cubeSavedState);
      calculator.upToDateISOString = p.upToDateISOString;
      if (p.meta != null) {
        calculator.meta = p.meta;
      }
      return calculator;
    };

    return TimeSeriesCalculator;

  })();

  exports.TimeSeriesCalculator = TimeSeriesCalculator;

}).call(this);

//# sourceMappingURL=TimeSeriesCalculator.js.map

});

require.define("/src/histogram.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3
(function() {
  var functions, getBucketCountMinMax, histogram, justHereForDocsAndDoctest, roundDownToSignificance, roundUpToSignificance, setParameters, utils;

  functions = require('./functions').functions;

  utils = require('tztime').utils;

  histogram = {};

  justHereForDocsAndDoctest = function() {

    /*
    @class histogram
    
    This module has functionality that will allow you to create histograms and do bucketing.
    
    Features:
    
      * Three bucketing strategies:
        1. constant width (default)
        2. constant depth - for an example of using this mode, look at the source code for the `bucketPercentile()` function
        3. [v-optimal](http://en.wikipedia.org/wiki/V-optimal_histograms)
      * Two operating modes modes:
        1. Automatic. Call histogram with data and all of your parameters and out pops a histogram.
        2. Piecemeal. Create buckets, put data into buckets, generate histograms from data and pre-calculated buckets.
           Sometimes you are less interested in the histogram than you are in the bucketing.
    
    Let's walk through some examples of both modes. But first a general discussion about how these functions accept raw data.
    
    ## Getting data into the histogram functions ##
    
    We have two ways to define data. We can pass in an Array of Objects and specify the field to use.
    
        grades = [
          {name: 'Joe', average: 105},
          {name: 'Jeff', average: 104.9}, # ...
    
        ]
    
        {histogram} = require('../')
        h = histogram.histogram(grades, 'average')
    
        console.log(h)
         * [ { index: 0, startOn: null, endBelow: null, label: 'all', count: 2 } ]
    
    Or, we can just pass in a list of values
    
        grades = [105, 104.9, 99, 98.7, 85, 78, 54, 98, 78, 20]
        h = histogram.histogram(grades)
        console.log((row.label + ': ' + row.count for row in h))
         * [ '< 41.25: 1', '41.25-62.5: 1', '62.5-83.75: 2', '>= 83.75: 6' ]
    
    ## Automatic histogram creation ##
    
    The above examples for the two ways of getting data into the histogram functions also demonstrates the use of
    automatic histogram creation. There are additional parameters to this function that allow you to control the
    type of bucketing (constantWidth, constantDepth, etc.), min and max values, significance of the bucket boundaries, etc.
    See the individual functions for details on these parameters.
    
    ## Piecemeal usage ##
    
    Sometimes you don't actually want a histogram. You want a way to create constantWidth or constantDepth or v-optimal buckets
    and you want a tool to know which bucket a particular value falls into. The cannonical example of this is for calculating
    percentiles for standardized testing... or for grading on a curve. The documentation for the `percentileBuckets()`
    function walks you through an example like this.
     */
  };

  getBucketCountMinMax = function(values) {
    var max, min, targetBucketCount;
    targetBucketCount = Math.floor(Math.sqrt(values.length)) + 1;
    if (targetBucketCount < 3) {
      targetBucketCount = 2;
    }
    min = functions.min(values);
    max = functions.max(values);
    return {
      targetBucketCount: targetBucketCount,
      min: min,
      max: max
    };
  };

  roundUpToSignificance = function(value, significance) {
    var multiple;
    if (significance == null) {
      return value;
    }
    multiple = 1 / significance;
    return Math.ceil(value * multiple) / multiple;
  };

  roundDownToSignificance = function(value, significance) {
    var multiple;
    if (significance == null) {
      return value;
    }
    multiple = 1 / significance;
    return Math.floor(value * multiple) / multiple;
  };

  setParameters = function(rows, valueField, firstStartOn, lastEndBelow, bucketCount, significance) {
    var lowerBase, max, min, ref, row, targetBucketCount, upperBase, values;
    if (valueField != null) {
      values = (function() {
        var j, len, results;
        results = [];
        for (j = 0, len = rows.length; j < len; j++) {
          row = rows[j];
          results.push(row[valueField]);
        }
        return results;
      })();
    } else {
      values = rows;
    }
    ref = getBucketCountMinMax(values), targetBucketCount = ref.targetBucketCount, min = ref.min, max = ref.max;
    if (bucketCount == null) {
      bucketCount = targetBucketCount;
    }
    if (firstStartOn != null) {
      lowerBase = firstStartOn;
    } else {
      lowerBase = roundDownToSignificance(min, significance);
      firstStartOn = null;
    }
    if (lastEndBelow != null) {
      upperBase = lastEndBelow;
    } else {
      upperBase = roundUpToSignificance(max, significance);
      lastEndBelow = null;
    }
    return {
      values: values,
      bucketCount: bucketCount,
      firstStartOn: firstStartOn,
      lowerBase: lowerBase,
      lastEndBelow: lastEndBelow,
      upperBase: upperBase
    };
  };

  histogram.bucketsConstantWidth = function(rows, valueField, significance, firstStartOn, lastEndBelow, bucketCount) {
    var bucket, bucketSize, buckets, edge, i, j, lastEdge, lowerBase, ref, ref1, upperBase, values;
    ref = setParameters(rows, valueField, firstStartOn, lastEndBelow, bucketCount, significance), values = ref.values, bucketCount = ref.bucketCount, firstStartOn = ref.firstStartOn, lowerBase = ref.lowerBase, lastEndBelow = ref.lastEndBelow, upperBase = ref.upperBase;
    buckets = [];
    if (bucketCount < 3) {
      bucket = {
        index: 0,
        startOn: firstStartOn,
        endBelow: lastEndBelow,
        label: 'all'
      };
      buckets.push(bucket);
      return buckets;
    }
    bucketSize = roundDownToSignificance((upperBase - lowerBase) / bucketCount, significance);
    if (bucketSize <= 0) {
      throw new Error("Calculated bucketSizes <= 0 are not allowed. Try a smaller significance.");
    }
    lastEdge = lowerBase + bucketSize;
    bucket = {
      index: 0,
      startOn: firstStartOn,
      endBelow: lastEdge
    };
    buckets.push(bucket);
    for (i = j = 1, ref1 = bucketCount - 2; 1 <= ref1 ? j <= ref1 : j >= ref1; i = 1 <= ref1 ? ++j : --j) {
      edge = lastEdge + bucketSize;
      buckets.push({
        index: i,
        startOn: lastEdge,
        endBelow: edge
      });
      lastEdge = edge;
    }
    if ((lastEdge != null) && (lastEndBelow != null) && lastEdge >= lastEndBelow) {
      throw new Error("Somehow, the last bucket didn't work out. Try a smaller significance. lastEdge: " + lastEdge + "  lastEndBelow: " + lastEndBelow);
    }
    bucket = {
      index: bucketCount - 1,
      startOn: lastEdge,
      endBelow: lastEndBelow
    };
    buckets.push(bucket);
    return buckets;
  };

  histogram.bucketsConstantDepth = function(rows, valueField, significance, firstStartOn, lastEndBelow, bucketCount) {
    var bucket, bucketSize, buckets, currentBoundary, i, j, lastBoundary, lowerBase, ref, ref1, upperBase, values;
    ref = setParameters(rows, valueField, firstStartOn, lastEndBelow, bucketCount, significance), values = ref.values, bucketCount = ref.bucketCount, firstStartOn = ref.firstStartOn, lowerBase = ref.lowerBase, lastEndBelow = ref.lastEndBelow, upperBase = ref.upperBase;
    if (bucketCount < 3) {
      bucket = {
        index: 0,
        startOn: firstStartOn,
        endBelow: lastEndBelow
      };
      buckets.push(bucket);
      return buckets;
    }
    bucketSize = 100 / bucketCount;
    buckets = [];
    currentBoundary = roundDownToSignificance(functions.percentileCreator(bucketSize)(values), significance);
    bucket = {
      index: 0,
      startOn: firstStartOn,
      endBelow: currentBoundary
    };
    buckets.push(bucket);
    for (i = j = 1, ref1 = bucketCount - 2; 1 <= ref1 ? j <= ref1 : j >= ref1; i = 1 <= ref1 ? ++j : --j) {
      lastBoundary = currentBoundary;
      currentBoundary = roundDownToSignificance(functions.percentileCreator(bucketSize * (i + 1))(values), significance);
      buckets.push({
        index: i,
        startOn: lastBoundary,
        endBelow: currentBoundary
      });
    }
    if ((lastBoundary != null) && (lastEndBelow != null) && lastBoundary >= lastEndBelow) {
      throw new Error("Somehow, the last bucket didn't work out. Try a different bucketCount.");
    }
    bucket = {
      index: bucketCount - 1,
      startOn: currentBoundary,
      endBelow: lastEndBelow
    };
    buckets.push(bucket);
    return buckets;
  };

  histogram.bucketsPercentile = function(rows, valueField) {

    /*
    @method bucketsPercentile
    
    This is a short cut to creating a set of buckets for "scoring" in percentiles (think standardized testing).
    
    Note: You can't score in the 100th percentile because you can't beat your own score.
    If you have a higher score than anybody else, you didn't beat your own score. So, you aren't better than 100%. If there are
    less than 100 total scores then you technically can't even be in the 99th percentile. This function is hard-coded
    to only create 100 buckets. However, if you wanted to calculate fractional percentiles. Say you want to know who
    is in the 99.9th percentile, then you could simulate that yourself by calling bucketsConstantDepth with 1000 as
    the bucketCount parameter.
    
    Let's say you are a teacher and you only give out A's, B's, C's, and F's. Let's say you
    want the top 10% to get an A. This should only be one student, no matter what he scores. The next 30% of students
    to get a B. The next 50% of students to get a C and the last 10% to get an F (again, only 1 student). So with 10 students,
    the final distribution of grades will be this:
    
      * A: 1
      * B: 3
      * C: 5
      * F: 1
      * Total: 10
    
    Let's say you have these grades:
    
        grades = [
          {name: 'Joe', average: 105},    # 1 A 90th percentile and above
          {name: 'Jeff', average: 104.9}, # 1 B 60th percentile and above
          {name: 'John', average: 92},    # 2
          {name: 'Jess', average: 90},    # 3
          {name: 'Joseph', average: 87},  # 1 C 10th percentile and above
          {name: 'Julie', average: 87},   # 2
          {name: 'Juan', average: 75},    # 3
          {name: 'Jill', average: 73},    # 4
          {name: 'Jon', average: 71},     # 5
          {name: 'Jorge', average: 32}    # 1 F rest
        ]
    
    Now, let's create the percentile buckets for this by calling bucketsPercentile.
    
        {histogram} = require('../')
        buckets = histogram.bucketsPercentile(grades, 'average')
    
    Let's create a little helper function to convert the percentiles to grades. It includes a call to `histogram.bucket`.
    
        getGrade = (average, buckets) ->
          percentile = histogram.bucket(average, buckets).percentileHigherIsBetter
          if percentile >= 90
            return 'A'
          else if percentile >= 60
            return 'B'
          else if percentile >= 10
            return 'C'
          else
            return 'F'
    
    Now, if we loop over this and call getGrade, we can print out the final grade for each student.
    
        for student in grades
          console.log(student.name, getGrade(student.average, buckets))
    
         * Joe A
         * Jeff B
         * John B
         * Jess B
         * Joseph C
         * Julie C
         * Juan C
         * Jill C
         * Jon C
         * Jorge F
    
    @static
    @param {Object[]/Number[]} rows If no valueField is provided or the valueField parameter is null, then the first parameter is
    assumed to be an Array of Numbers representing the values to bucket. Otherwise, it is assumed to be an Array of Objects
    with a bunch of fields.
    
    @return {Object[]}
    
    Returns an Array of Objects (buckets) in the form of {index, startOn, endBelow, label, percentileHigherIsBetter, percentileLowerIsBetter}
    
    To convert a value into a percentile call `histogram.bucket(value, bucketsFromCallToBucketsPercentile)` and
    then read the percentileHigherIsBetter or percentileLowerIsBetter of the bucket that is returned.
     */
    var b, buckets, j, len, percentile;
    buckets = histogram.buckets(rows, valueField, histogram.bucketsConstantDepth, null, null, null, 100);
    percentile = 0;
    for (j = 0, len = buckets.length; j < len; j++) {
      b = buckets[j];
      if (b.matchingRangeIndexEnd != null) {
        b.percentileHigherIsBetter = b.matchingRangeIndexStart;
        b.percentileLowerIsBetter = 99 - b.matchingRangeIndexEnd;
        percentile = b.matchingRangeIndexEnd;
        delete b.matchingRangeIndexEnd;
        delete b.matchingRangeIndexStart;
      } else {
        b.percentileHigherIsBetter = percentile;
        b.percentileLowerIsBetter = 99 - percentile;
      }
      percentile++;
    }
    return buckets;
  };

  histogram.buckets = function(rows, valueField, type, significance, firstStartOn, lastEndBelow, bucketCount) {
    var bucket, buckets, currentBucket, gotToEnd, i, index, j, len, startOfMatching, tempBuckets;
    if (type == null) {
      type = histogram.bucketsConstantWidth;
    }

    /*
    @method buckets
    @static
    @param {Object[]/Number[]} rows If no valueField is provided or the valueField parameter is null, then the first parameter is
    assumed to be an Array of Numbers representing the values to bucket. Otherwise, it is assumed to be an Array of Objects
    with a bunch of fields.
    @param {String} [valueField] Specifies the field containing the values to calculate the histogram on
    @param {function} [type = histogram.constantWidth] Specifies how to pick the edges of the buckets. Three standard schemes
      are provided: histogram.bucketsConstantWidth, histogram.bucketsConstantDepth, and histogram.bucketsVOptimal.
      You could inject your own but this function simply calls that so you may as well just create the buckets yourself.
    @param {Number} [significance] The multiple to which you want to round the bucket edges. 1 means whole numbers.
     0.1 means to round to tenths. 0.01 to hundreds. Etc. If you provide all of these last four parameters, ensure
     that (lastEndBelow - firstStartOn) / bucketCount will naturally come out in the significance specified. So,
     (100 - 0) / 100 = 1. This works well with a significance of 1, 0.1, 0.01, etc. But (13 - 0) / 10  = 1.3. This
     would not work with a significance of 1. However, a signficance of 0.1 would work fine.
    
    @param {Number} [firstStartOn] This will be the startOn of the first bucket. Think of it as the min value.
    @param {Number} [lastEndBelow] This will be the endBelow of the last bucket. Think of it as the max value.
    @param {Number} [bucketCount] If provided, the histogram will have this many buckets.
    @return {Object[]}
    
    Returns an Array of Objects (buckets) in the form of {index, startOn, endBelow, label}
    
    The buckets array that is returned will have these properties:
    
    * Each bucket (row) will have these fields {index, startOn, endBelow, label}.
    * Duplicate buckets are merged. When they are merged two fields are added to the resulting merged bucket:
      {matchingRangeIndexStart, matchingRangeIndexEnd} indicating the range that this bucket replaces.
    * If firstStartOn is not provided, it will be null indicating -Infinity
    * If lastEndBelow is not provided, it will be null indicating Infinity.
     */
    tempBuckets = type(rows, valueField, significance, firstStartOn, lastEndBelow, bucketCount);
    if (tempBuckets.length < 2) {
      buckets = tempBuckets;
    } else {
      buckets = [];
      startOfMatching = tempBuckets[0];
      gotToEnd = false;
      i = 1;
      while (i < tempBuckets.length) {
        currentBucket = tempBuckets[i];
        if (startOfMatching.startOn === currentBucket.startOn) {
          i++;
          currentBucket = tempBuckets[i];
          while ((currentBucket != null) && startOfMatching.startOn === currentBucket.startOn && startOfMatching.endBelow === currentBucket.endBelow) {
            i++;
            currentBucket = tempBuckets[i];
          }
          if (i >= tempBuckets.length - 1) {
            currentBucket = tempBuckets[tempBuckets.length - 1];
            gotToEnd = true;
          }
          startOfMatching.matchingRangeIndexStart = startOfMatching.index;
          startOfMatching.matchingRangeIndexEnd = currentBucket.index;
          startOfMatching.endBelow = currentBucket.endBelow;
          buckets.push(startOfMatching);
          i++;
          currentBucket = tempBuckets[i];
        } else {
          buckets.push(startOfMatching);
        }
        startOfMatching = currentBucket;
        i++;
      }
      if (!gotToEnd) {
        buckets.push(currentBucket);
      }
    }
    for (index = j = 0, len = buckets.length; j < len; index = ++j) {
      bucket = buckets[index];
      bucket.index = index;
      if ((bucket.startOn != null) && (bucket.endBelow != null)) {
        bucket.label = bucket.startOn + "-" + bucket.endBelow;
      } else if (bucket.startOn != null) {
        bucket.label = ">= " + bucket.startOn;
      } else if (bucket.endBelow != null) {
        bucket.label = "< " + bucket.endBelow;
      } else {
        bucket.label = "all";
      }
    }
    return buckets;
  };

  histogram.bucket = function(value, buckets) {

    /*
    @method bucket
    @static
    @param {Number} value The value to bucket
    @param {Object[]} buckets Array of objects where each row is in the form {index, startOn, endBelow, label}
    @return {Object}
    
    Returns the bucket that contains the given value unless the data fits in none of the buckets, in which case, it returns
    `null`.
    
    Note: With default parameters, the buckets generated by this module will cover -Infinity to Infinity, (i.e. all
    possible values). However, if you hand generate your own buckets or you use firstStartOn or lastEndBelow parameters,
    when calling histogram.buckets, then it's possible for values to fall into no buckets.
    You can effectively use this as a way to filter out outliers or unexpected
    negative values. Also note that the firstStartOn (min) is inclusive, but the lastEndBelow (max) is exclusive. If
    you set the lastEndBelow to 100, then no values of 100 will get bucketed. You can't score in the 100th percentile
    because you can't beat your own score. This is simlar logic.
     */
    var b, i, j, ref;
    if (value == null) {
      return null;
    }
    if (buckets.length >= 3) {
      for (i = j = 1, ref = buckets.length - 2; 1 <= ref ? j <= ref : j >= ref; i = 1 <= ref ? ++j : --j) {
        b = buckets[i];
        if ((b.startOn <= value && value < b.endBelow)) {
          return b;
        }
      }
    }
    b = buckets[0];
    if ((b.startOn != null) && (b.endBelow != null)) {
      if ((b.startOn <= value && value < b.endBelow)) {
        return b;
      }
    } else if (b.startOn != null) {
      if (b.startOn <= value) {
        return b;
      }
    } else if (b.endBelow != null) {
      if (value < b.endBelow) {
        return b;
      }
    } else if ((b.startOn == null) && (b.endBelow == null)) {
      return b;
    }
    b = buckets[buckets.length - 1];
    if (b.endBelow != null) {
      if ((b.startOn <= value && value < b.endBelow)) {
        return b;
      }
    } else {
      if (b.startOn <= value) {
        return b;
      }
    }
    return null;
  };

  histogram.histogramFromBuckets = function(rows, valueField, buckets) {

    /*
    @method histogramFromBuckets
    @static
    @param {Object[]/Number[]} rows If no valueField is provided or the valueField parameter is null, then the first parameter is
     assumed to be an Array of Numbers representing the values to bucket. Otherwise, it is assumed to be an Array of Objects
     with a bunch of fields.
    @param {String} valueField Specifies the field containing the values to calculate the histogram on
    @param {Object[]} buckets Array of Objects as output from a get...Buckets() function. Each row {index, startOn, endBelow, label}
    @return {Object[]}
    
    Returns a histogram from rows using the provided buckets. See histogram.histogram() for details on the returned Array.
     */
    var bucket, h, histogramRow, j, k, len, len1, row, v, values;
    if (valueField != null) {
      values = (function() {
        var j, len, results;
        results = [];
        for (j = 0, len = rows.length; j < len; j++) {
          row = rows[j];
          results.push(row[valueField]);
        }
        return results;
      })();
    } else {
      values = rows;
    }
    h = utils.clone(buckets);
    for (j = 0, len = h.length; j < len; j++) {
      histogramRow = h[j];
      histogramRow.count = 0;
    }
    for (k = 0, len1 = values.length; k < len1; k++) {
      v = values[k];
      bucket = histogram.bucket(v, buckets);
      if (bucket != null) {
        h[bucket.index].count++;
      }
    }
    return h;
  };

  histogram.histogram = function(rows, valueField, type, significance, firstStartOn, lastEndBelow, bucketCount) {
    var buckets;
    if (type == null) {
      type = histogram.constantWidth;
    }

    /*
    @method histogram
    @static
    @param {Object[]/Number[]} rows If no valueField is provided or the valueField parameter is null, then the first parameter is
     assumed to be an Array of Numbers representing the values to bucket. Otherwise, it is assumed to be an Array of Objects
     with a bunch of fields.
    @param {String} [valueField] Specifies the field containing the values to calculate the histogram on
    @param {function} [type = histogram.constantWidth] Specifies how to pick the edges of the buckets. Three standard schemes
      are provided: histogram.bucketsConstantWidth, histogram.bucketsConstantDepth, and histogram.bucketsVOptimal.
      However, you can inject your own.
    @param {Number} [significance] The multiple to which you want to round the bucket edges. 1 means whole numbers.
     0.1 means to round to tenths. 0.01 to hundreds. Etc. If you provide all of these last four parameters, ensure
     that (lastEndBelow - firstStartOn) / bucketCount will naturally come out in the significance specified. So,
     (100 - 0) / 100 = 1. This works well with a significance of 1, 0.1, 0.01, etc. But (13 - 0) / 10  = 1.3. This
     would not work with a significance of 1. However, a signficance of 0.1 would work fine.
    @param {Number} [firstStartOn] This will be the startOn of the first bucket.
    @param {Number} [lastEndBelow] This will be the endBelow of the last bucket. Think of it as the max value.
    @param {Number} [bucketCount] If provided, the histogram will have this many buckets.
    @return {Object[]}
    
    Returns an Array of Objects (buckets) in the form of {index, startOn, endBelow, label, count} where count is the
    number of values in each bucket.
    
    Note: With default parameters, the buckets will cover -Infinity to Infinity, (i.e. all
    possible values). However, if firstStartOn or lastEndBelow are provided, then any values that you pass in that
    fall outside of this range will be ignored. You can effectively use this as a way to filter out outliers or unexpected
    negative values. Also note that the firstStartOn (min) is inclusive, but the lastEndBelow (max) is exclusive. If
    you set the lastEndBelow to 100, then no values of 100 will get counted. You can't score in the 100th percentile
    because you can't beat your own score. This is simlar logic.
     */
    buckets = histogram.buckets(rows, valueField, type, significance, firstStartOn, lastEndBelow, bucketCount);
    return histogram.histogramFromBuckets(rows, valueField, buckets);
  };

  histogram.clipping = function(rows, valueField, noClipping) {
    var b, bucket, bucketCount, bucketSize, buckets, c, chartMax, chartValues, chartValuesMinusOutliers, clipped, i, iqr, j, k, l, len, len1, len2, m, max, percentile, q1, q3, ref, row, total, upperBound, valueMax;
    if (noClipping == null) {
      noClipping = false;
    }

    /*
    @method clipping
    @static
    
    Note: The calling pattern and functionality of this method is legacy and a bit different from the other members of
    this histogram module. I just haven't yet had the opportunity to upgrade it to the new pattern.
    
    This histogram function is designed to work with data that is zero bound on the low end and might have outliers
    on the high end. It's not very general purpose but it's ideal for distributions that have a long-fat-tail.
    
    @param {Object[]} rows
    @param {String} valueField Specifies the field containing the values to calculate the histogram on
    @param {Boolean} [noClipping = false] If set to true, then it will not create a non-linear band for the outliers. The
     default behavior (noClipping = false) is to lump together outliers into a single bucket at the top.
    @return {Object[]}
    
    Returns an object containing the following:
    
    * buckets - An Array containing {label, count, rows, clippedChartValue}
    * bucketSize - The size of each bucket (except the top one)
    * chartMax - The maximum to use for charting using clipped values
    * clipped - A Boolean indicating if the result is clipped
    * valueMax - The actual maximum value found. Will always be >= chartMax
    
    Given an array of rows like:
    
        {histogram} = require('../')
    
        rows = [
          {age:  7},
          {age: 25},
          {age: 23},
          {age: 27},
          {age: 34},
          {age: 55},
          {age: 42},
          {age: 13},
          {age: 11},
          {age: 23},
          {age: 31},
          {age: 32},
          {age: 29},
          {age: 16},
          {age: 31},
          {age: 22},
          {age: 25},
        ]
    
    histogram will calculate a histogram. There will be sqrt(n) + 1 buckets
    
        {buckets, chartMax} = histogram.clipping(rows, 'age')
        for b in buckets
          console.log(b.label, b.count)
         * 0-12 2
         * 12-24 5
         * 24-36 8
         * 36-48 1
         * 48-60 1
    
        console.log(chartMax)
         * 60
    
    This histogram calculator will also attempt to lump outliers into a single bucket at the top.
    
        rows.push({age: 85})
    
        {buckets, chartMax} = histogram.clipping(rows, 'age')
    
        lastBucket = buckets[buckets.length - 1]
        console.log(lastBucket.label, lastBucket.count)
         * 48-86* 2
    
    The asterix `*` is there to indicate that this bucket is not the same size as the others and non-linear.
    The histogram calculator will also "clip" the values for these outliers so that you can
    display them in a scatter chart on a linear scale with the last band compressed.
    The `clippedChartValue` will be guaranteed to be below the `chartMax` by interpolating it's position between
    the bounds of the top band where the actual max value is scaled down to the `chartMax`
    
        lastBucket = buckets[buckets.length - 1]
        console.log(lastBucket.rows[1].age, lastBucket.rows[1].clippedChartValue)
         * 85 59.68421052631579
     */
    if (valueField != null) {
      chartValues = (function() {
        var j, len, results;
        results = [];
        for (j = 0, len = rows.length; j < len; j++) {
          row = rows[j];
          results.push(row[valueField]);
        }
        return results;
      })();
    } else {
      chartValues = rows;
    }
    max = functions.max(chartValues);
    max = Math.max(max, 1);
    if (noClipping) {
      upperBound = max;
      chartValuesMinusOutliers = chartValues;
    } else {
      q3 = functions.percentileCreator(75)(chartValues);
      q1 = functions.percentileCreator(25)(chartValues);
      iqr = q3 - q1;
      upperBound = q3 + 1.5 * iqr;
      if (isNaN(upperBound) || upperBound > max) {
        upperBound = max;
      }
      chartValuesMinusOutliers = (function() {
        var j, len, results;
        results = [];
        for (j = 0, len = chartValues.length; j < len; j++) {
          c = chartValues[j];
          if (c <= upperBound) {
            results.push(c);
          }
        }
        return results;
      })();
    }
    bucketCount = Math.floor(Math.sqrt(chartValuesMinusOutliers.length));
    if (bucketCount < 3) {
      bucketCount = 2;
    }
    bucketSize = Math.floor(upperBound / bucketCount) + 1;
    upperBound = bucketSize * bucketCount;
    chartMax = upperBound + bucketSize;
    valueMax = Math.floor(functions.max(chartValues)) + 1;
    valueMax = Math.max(chartMax, valueMax);
    for (j = 0, len = rows.length; j < len; j++) {
      row = rows[j];
      if (row[valueField] >= upperBound) {
        row.clippedChartValue = upperBound + bucketSize * (row[valueField] - upperBound) / (valueMax - upperBound);
      } else {
        row.clippedChartValue = row[valueField];
      }
    }
    buckets = [];
    for (i = k = 0, ref = bucketCount; 0 <= ref ? k <= ref : k >= ref; i = 0 <= ref ? ++k : --k) {
      bucket = {
        label: (Math.floor(i * bucketSize)) + "-" + (Math.floor((i + 1) * bucketSize)),
        rows: [],
        count: 0
      };
      buckets.push(bucket);
    }
    clipped = !(valueMax === chartMax);
    if (clipped) {
      buckets[bucketCount].label = upperBound + "-" + valueMax + "*";
    } else {
      buckets[bucketCount].label = upperBound + "-" + valueMax;
    }
    total = 0;
    for (l = 0, len1 = rows.length; l < len1; l++) {
      row = rows[l];
      if (row[valueField] >= upperBound) {
        bucket = buckets[buckets.length - 1];
      } else {
        bucket = buckets[Math.floor(row[valueField] / bucketSize)];
      }
      bucket.rows.push(row);
      bucket.count++;
      total++;
    }
    percentile = 0;
    for (m = 0, len2 = buckets.length; m < len2; m++) {
      b = buckets[m];
      percentile += b.count / total;
      if (isNaN(percentile)) {
        b.percentile = 0;
      } else {
        b.percentile = percentile;
      }
    }
    buckets[buckets.length - 1].percentile = 1.0;
    return {
      buckets: buckets,
      bucketSize: bucketSize,
      chartMax: chartMax,
      clipped: clipped,
      valueMax: valueMax
    };
  };

  exports.histogram = histogram;

}).call(this);

//# sourceMappingURL=histogram.js.map

});

require.define("/src/multiRegression.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3
(function() {
  var multiRegression, predict;

  multiRegression = {};

  multiRegression.calculateA = function(data) {

    /*
    @method calculateA
      Calculates the coefficient matrix for gaussian elimination solution
     */
    var a, i, j, k, l, m, n, numOfVariables, o, ref, ref1, ref2;
    numOfVariables = data[0].length;
    n = data.length;
    a = [];
    for (i = l = 0, ref = numOfVariables - 1; 0 <= ref ? l <= ref : l >= ref; i = 0 <= ref ? ++l : --l) {
      a.push([]);
      for (j = m = 0, ref1 = numOfVariables; 0 <= ref1 ? m <= ref1 : m >= ref1; j = 0 <= ref1 ? ++m : --m) {
        a[i].push(0);
        for (k = o = 0, ref2 = n - 1; 0 <= ref2 ? o <= ref2 : o >= ref2; k = 0 <= ref2 ? ++o : --o) {
          a[i][j] += (i === 0 ? 1 : data[k][i - 1]) * (j === 0 ? 1 : data[k][j - 1]);
        }
      }
    }
    return a;
  };

  multiRegression.swapRows = function(a, firstRowIndex, secondRowIndex) {
    var j, l, ref, results, temp;
    results = [];
    for (j = l = 0, ref = a[0].length - 1; 0 <= ref ? l <= ref : l >= ref; j = 0 <= ref ? ++l : --l) {
      temp = a[firstRowIndex][j];
      a[firstRowIndex][j] = a[secondRowIndex][j];
      results.push(a[secondRowIndex][j] = temp);
    }
    return results;
  };

  predict = function(data, inputs) {

    /*
    @method predict
    @param {[][]} data A two-dimensional array
    @param
    
    Returns a prediction of the output based upon historical data and input "estimates"
    The last column of the Data array is the value we are trying to predict. The other
    columns are the inputs.  The input array will order-wise coorespond to the first
    n-1 columns of the data array.
    
    @return {Object}
    
    returns {A, Beta, variance, prediction}
     */
  };

  exports.multiRegression = multiRegression;

}).call(this);

//# sourceMappingURL=multiRegression.js.map

});

require.define("/src/table.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3
(function() {
  var table, utils;

  utils = require('tztime').utils;

  table = {};


  /*
  @class table
   */

  table.padToWidth = function(s, width, padCharacter, rightPad) {
    var padding;
    if (padCharacter == null) {
      padCharacter = ' ';
    }
    if (rightPad == null) {
      rightPad = false;
    }
    if (s.length > width) {
      return s.substr(0, width);
    }
    padding = new Array(width - s.length + 1).join(padCharacter);
    if (rightPad) {
      return s + padding;
    } else {
      return padding + s;
    }
  };

  table.toString = function(rows, fields, sortBy, descending) {
    var field, i, index, j, k, key, l, len, len1, len2, len3, len4, len5, m, maxWidths, n, ref, ref1, ref2, row, s, sortedRows, value;
    if (descending == null) {
      descending = false;
    }

    /*
    @method toString
    @param {Object[]} rows
    @param {Object} [fields] If not provided, it will use the fields found in the first row
    @param {String} [sortBy] If provided, it will sort the table by this field before returning
    @param {Boolean} [descending = false] By default, the sort will be ascending, setting this to true will sort descending
    @return {String} Returns a string for the table in Markdown format
    
        t = [
          {col1: 'hello', col2: 12, col3: true},
          {col1: 'goodbye', col2: 120, col3: false},
          {col1: 'yep', col2: -23, col3: true},
        ]
    
        console.log(require('../').table.toString(t, null, 'col2', true))
         * | col1    | col2 | col3  |
         * | ------- | ---- | ----- |
         * | goodbye | 120  | false |
         * | hello   | 12   | true  |
         * | yep     | -23  | true  |
     */
    if (fields == null) {
      fields = [];
      ref = rows[0];
      for (key in ref) {
        value = ref[key];
        fields.push(key);
      }
    }
    maxWidths = [];
    for (index = i = 0, len = fields.length; i < len; index = ++i) {
      field = fields[index];
      maxWidths.push(field.length);
      for (j = 0, len1 = rows.length; j < len1; j++) {
        row = rows[j];
        maxWidths[index] = Math.max(maxWidths[index], ((ref1 = row[field]) != null ? ref1.toString().length : void 0) || 0);
      }
    }
    if (sortBy != null) {
      sortedRows = utils._.sortBy(rows, sortBy);
      if (descending) {
        sortedRows = sortedRows.reverse();
      }
    } else {
      sortedRows = rows;
    }
    s = '|';
    for (index = k = 0, len2 = fields.length; k < len2; index = ++k) {
      field = fields[index];
      s += ' ';
      s += table.padToWidth(field, maxWidths[index], void 0, true) + ' |';
    }
    s += '\n|';
    for (index = l = 0, len3 = fields.length; l < len3; index = ++l) {
      field = fields[index];
      s += ' ';
      s += table.padToWidth('', maxWidths[index], '-', true) + ' |';
    }
    for (m = 0, len4 = sortedRows.length; m < len4; m++) {
      row = sortedRows[m];
      s += '\n|';
      for (index = n = 0, len5 = fields.length; n < len5; index = ++n) {
        field = fields[index];
        s += ' ';
        s += table.padToWidth(((ref2 = row[field]) != null ? ref2.toString() : void 0) || '', maxWidths[index], void 0, true) + ' |';
      }
    }
    return s;
  };

  exports.table = table;

}).call(this);

//# sourceMappingURL=table.js.map

});

require.define("/src/anova.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3
(function() {
  var anova, correlate, fDist, functions, normInverseUpper, ref, utils;

  utils = require('tztime').utils;

  functions = require('./functions').functions;

  ref = require('./distributions').distributions, fDist = ref.fDist, normInverseUpper = ref.normInverseUpper;

  correlate = require('./correlate').correlate;

  anova = function(rawData, overallPredicate, field, groups, ci) {
    var bucket, buckets, data, errorDF, errorMS, errorSS, factorDF, factorF, factorMS, factorP, factorSS, group, histogram, i, index, j, k, l, len, len1, len2, len3, len4, len5, len6, len7, m, multiplier, n, nTimesMeanSquared, o, overallMean, overallN, overallSum, overallSumSquares, p, pooledNumerator, pooledStandardDeviation, q, r, rSquared, rSquaredAdjusted, ref1, ref2, ref3, residual, residualPlot, residuals, row, s, t, totalDF, totalSS, value, xStdDev, xValues, y, yStdDev, yValues;
    if (ci == null) {
      ci = 0.95;
    }

    /*
    @param {Object} groups {label, predicate} This is modified as a side-effect of this function. Many properties are added.
    
    https://onlinecourses.science.psu.edu/stat414/node/218
    
    http://www.calvin.edu/~rpruim/courses/m243/F03/overheads/ANOVAf03.ppt
     */
    utils.assert((0 < ci && ci < 1.0), "ci must be between 0.0 and 1.0");
    if (overallPredicate != null) {
      data = (function() {
        var j, len, results;
        results = [];
        for (j = 0, len = rawData.length; j < len; j++) {
          row = rawData[j];
          if (overallPredicate(row) && (row[field] != null)) {
            results.push(row);
          }
        }
        return results;
      })();
    } else {
      data = rawData;
    }
    utils.assert(groups.length < data.length, 'After filtering with the overallPredicate, there were fewer rows in the dataset than there were groups');
    overallN = 0;
    overallSum = 0;
    overallSumSquares = 0;
    pooledNumerator = 0;
    for (j = 0, len = groups.length; j < len; j++) {
      group = groups[j];
      group.values = (function() {
        var k, len1, results;
        results = [];
        for (k = 0, len1 = data.length; k < len1; k++) {
          row = data[k];
          if (group.predicate(row)) {
            results.push(row[field]);
          }
        }
        return results;
      })();
      group.sum = functions.sum(group.values);
      group.n = group.values.length;
      group.sumSquares = functions.sumSquares(group.values);
      group.variance = functions.variance(group.values);
      group.standardDeviation = Math.sqrt(group.variance);
      group.mean = group.sum / group.n;
      overallN += group.n;
      overallSum += group.sum;
      overallSumSquares += group.sumSquares;
      pooledNumerator += (group.n - 1) * group.variance;
    }
    overallMean = overallSum / overallN;
    pooledStandardDeviation = Math.sqrt(pooledNumerator / (overallN - groups.length));
    multiplier = normInverseUpper((1.0 - ci) / 2);
    for (k = 0, len1 = groups.length; k < len1; k++) {
      group = groups[k];
      group.ciDelta = multiplier * pooledStandardDeviation / Math.sqrt(group.n);
    }
    residuals = [];
    for (l = 0, len2 = groups.length; l < len2; l++) {
      group = groups[l];
      ref1 = group.values;
      for (m = 0, len3 = ref1.length; m < len3; m++) {
        value = ref1[m];
        residual = group.mean - value;
        residuals.push(residual);
      }
    }
    residuals = residuals.sort(function(a, b) {
      return a - b;
    });
    residualPlot = [];
    for (index = n = 0, len4 = residuals.length; n < len4; index = ++n) {
      r = residuals[index];
      i = index + 1;
      if (i === 1) {
        y = 1 - Math.pow(0.5, 1 / residuals.length);
      } else if (i === residuals.length) {
        y = Math.pow(0.5, 1 / residuals.length);
      } else {
        y = (i - 0.3175) / (residuals.length + 0.365);
      }
      y = y - 0.5;
      if (y === 0) {
        y = 0;
      } else {
        y = Math.abs(y) * y;
      }
      residualPlot.push({
        x: r,
        y: y
      });
    }
    xValues = (function() {
      var len5, o, results;
      results = [];
      for (o = 0, len5 = residualPlot.length; o < len5; o++) {
        r = residualPlot[o];
        results.push(r.x);
      }
      return results;
    })();
    yValues = (function() {
      var len5, o, results;
      results = [];
      for (o = 0, len5 = residualPlot.length; o < len5; o++) {
        r = residualPlot[o];
        results.push(r.y);
      }
      return results;
    })();
    xStdDev = functions.standardDeviation(xValues);
    yStdDev = functions.standardDeviation(yValues);
    for (o = 0, len5 = residualPlot.length; o < len5; o++) {
      r = residualPlot[o];
      r.x = r.x / xStdDev;
      r.y = r.y / yStdDev;
    }
    buckets = {};
    for (bucket = p = ref2 = -2.5; ref2 <= 2.5 ? p <= 2.5 : p >= 2.5; bucket = ref2 <= 2.5 ? ++p : --p) {
      buckets[bucket] = 0;
    }
    for (q = 0, len6 = residualPlot.length; q < len6; q++) {
      r = residualPlot[q];
      bucket = Math.floor(r.y + 1.0) - 0.5;
      buckets[bucket] += 1;
    }
    histogram = [];
    for (bucket = s = ref3 = -2.5; ref3 <= 2.5 ? s <= 2.5 : s >= 2.5; bucket = ref3 <= 2.5 ? ++s : --s) {
      row = {
        label: (-0.5 + bucket) + " to " + (0.5 + bucket),
        center: bucket,
        count: buckets[bucket]
      };
      histogram.push(row);
    }
    factorDF = groups.length - 1;
    errorDF = overallN - groups.length;
    totalDF = factorDF + errorDF;
    factorSS = 0;
    for (t = 0, len7 = groups.length; t < len7; t++) {
      group = groups[t];
      factorSS += group.n * group.mean * group.mean;
    }
    nTimesMeanSquared = overallN * overallMean * overallMean;
    factorSS -= nTimesMeanSquared;
    totalSS = overallSumSquares - nTimesMeanSquared;
    errorSS = totalSS - factorSS;
    factorMS = factorSS / factorDF;
    errorMS = errorSS / errorDF;
    factorF = factorMS / errorMS;
    factorP = fDist(factorDF, errorDF, factorF);
    rSquared = factorSS / totalSS;
    rSquaredAdjusted = Math.abs(1 - (1 - rSquared) * (overallN - 1) / (overallN - groups.length));
    return {
      factorDF: factorDF,
      factorSS: factorSS,
      factorMS: factorMS,
      factorF: factorF,
      factorP: factorP,
      errorDF: errorDF,
      errorSS: errorSS,
      errorMS: errorMS,
      totalDF: totalDF,
      totalSS: totalSS,
      rSquared: rSquared,
      rSquaredAdjusted: rSquaredAdjusted,
      residualPlot: residualPlot,
      histogram: histogram,
      pooledStandardDeviation: pooledStandardDeviation
    };
  };

  exports.anova = anova;

}).call(this);

//# sourceMappingURL=anova.js.map

});

require.define("/src/distributions.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3

/*
JavaScript version from which this CoffeeScript version was derived by Ben Tilly <btilly@gmail.com>
which was derived from the Perl version by Michael Kospach <mike.perl@gmx.at>
both of which are licensed under the Perl Artistic License which allows linking from MIT licensed code.

Note: these are approximations good to 5 digits (which is good enough for almost every thing)

https://code.google.com/p/statistics-distributions-js/source/browse/trunk/statistics-distributions.js
 */

(function() {
  var distributions;

  distributions = {};

  distributions.fDist = function(n, m, x) {

    /*
    Upper probability of the F distribution
     */
    var a, b, i, p, p1, y, z;
    p = void 0;
    if (x <= 0) {
      p = 1;
    } else if (m % 2 === 0) {
      z = m / (m + n * x);
      a = 1;
      i = m - 2;
      while (i >= 2) {
        a = 1 + (n + i - 2) / i * z * a;
        i -= 2;
      }
      p = 1 - (Math.pow(1 - z, n / 2) * a);
    } else if (n % 2 === 0) {
      z = n * x / (m + n * x);
      a = 1;
      i = n - 2;
      while (i >= 2) {
        a = 1 + (m + i - 2) / i * z * a;
        i -= 2;
      }
      p = Math.pow(1 - z, m / 2) * a;
    } else {
      y = Math.atan2(Math.sqrt(n * x / m), 1);
      z = Math.pow(Math.sin(y), 2);
      a = (n === 1 ? 0 : 1);
      i = n - 2;
      while (i >= 3) {
        a = 1 + (m + i - 2) / i * z * a;
        i -= 2;
      }
      b = Math.PI;
      i = 2;
      while (i <= m - 1) {
        b *= (i - 1) / i;
        i += 2;
      }
      p1 = 2 / b * Math.sin(y) * Math.pow(Math.cos(y), m) * a;
      z = Math.pow(Math.cos(y), 2);
      a = (m === 1 ? 0 : 1);
      i = m - 2;
      while (i >= 3) {
        a = 1 + (i - 1) / i * z * a;
        i -= 2;
      }
      p = Math.max(0, p1 + 1 - 2 * y / Math.PI - 2 / Math.PI * Math.sin(y) * Math.cos(y) * a);
    }
    return p;
  };

  distributions.tInverseUpper = function($n, p) {
    var $a, $b, $c, $d, $delta, $e, $n1, $round, $u, $u2, $x, p1;
    if (p >= 1 || p <= 0) {
      throw new Error("Invalid p: p\n");
    }
    if (p === 0.5) {
      return 0;
    } else {
      if (p < 0.5) {
        return -_subt($n, 1 - p);
      }
    }
    $u = _subu(p);
    $u2 = Math.pow($u, 2);
    $a = ($u2 + 1) / 4;
    $b = ((5 * $u2 + 16) * $u2 + 3) / 96;
    $c = (((3 * $u2 + 19) * $u2 + 17) * $u2 - 15) / 384;
    $d = ((((79 * $u2 + 776) * $u2 + 1482) * $u2 - 1920) * $u2 - 945) / 92160;
    $e = (((((27 * $u2 + 339) * $u2 + 930) * $u2 - 1782) * $u2 - 765) * $u2 + 17955) / 368640;
    $x = $u * (1 + ($a + ($b + ($c + ($d + $e / $n) / $n) / $n) / $n) / $n);
    if ($n <= Math.pow(log10(p), 2) + 3) {
      $round = void 0;
      while (true) {
        p1 = _subtprob($n, $x);
        $n1 = $n + 1;
        $delta = (p1 - p) / Math.exp(($n1 * Math.log($n1 / ($n + $x * $x)) + Math.log($n / $n1 / 2 / Math.PI) - 1 + (1 / $n1 - 1 / $n) / 6) / 2);
        $x += $delta;
        $round = round_to_precision($delta, Math.abs(integer(log10(Math.abs($x)) - 4)));
        if (!($x && ($round !== 0))) {
          break;
        }
      }
    }
    return $x;
  };

  distributions.tDist = function($n, $x) {
    var $a, $b, $i, $w, $y, $z;
    $a = void 0;
    $b = void 0;
    $w = Math.atan2($x / Math.sqrt($n), 1);
    $z = Math.pow(Math.cos($w), 2);
    $y = 1;
    $i = $n - 2;
    while ($i >= 2) {
      $y = 1 + ($i - 1) / $i * $z * $y;
      $i -= 2;
    }
    if ($n % 2 === 0) {
      $a = Math.sin($w) / 2;
      $b = .5;
    } else {
      $a = ($n === 1 ? 0 : Math.sin($w) * Math.cos($w) / Math.PI);
      $b = .5 + $w / Math.PI;
    }
    return Math.max(0, 1 - $b - $a * $y);
  };

  distributions.normDist = function($x) {
    var $absx, $i, p;
    p = 0;
    $absx = Math.abs($x);
    if ($absx < 1.9) {
      p = Math.pow(1 + $absx * (.049867347 + $absx * (.0211410061 + $absx * (.0032776263 + $absx * (.0000380036 + $absx * (.0000488906 + $absx * .000005383))))), -16) / 2;
    } else if ($absx <= 100) {
      $i = 18;
      while ($i >= 1) {
        p = $i / ($absx + p);
        $i--;
      }
      p = Math.exp(-.5 * $absx * $absx) / Math.sqrt(2 * Math.PI) / ($absx + p);
    }
    if ($x < 0) {
      p = 1 - p;
    }
    return p;
  };

  distributions.normInverseUpper = function(p) {
    var $x, $y;
    $y = -Math.log(4 * p * (1 - p));
    $x = Math.sqrt($y * (1.570796288 + $y * (.03706987906 + $y * (-.8364353589e-3 + $y * (-.2250947176e-3 + $y * (.6841218299e-5 + $y * (0.5824238515e-5 + $y * (-.104527497e-5 + $y * (.8360937017e-7 + $y * (-.3231081277e-8 + $y * (.3657763036e-10 + $y * .6936233982e-12)))))))))));
    if (p > .5) {
      $x = -$x;
    }
    return $x;
  };

  distributions.normInverse = function(p) {
    return distributions.normInverseUpper(1 - p);
  };

  exports.distributions = distributions;

}).call(this);

//# sourceMappingURL=distributions.js.map

});

require.define("/src/correlate.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3
(function() {
  var correlate;

  correlate = function(points, xField, yField) {
    var description, div, i, intercept, len, n, point, rSquared, slope, sumX, sumX2, sumXY, sumY, sumY2;
    if (xField == null) {
      xField = 'x';
    }
    if (yField == null) {
      yField = 'y';
    }
    n = points.length;
    sumX = 0;
    sumY = 0;
    sumXY = 0;
    sumX2 = 0;
    sumY2 = 0;
    for (i = 0, len = points.length; i < len; i++) {
      point = points[i];
      sumX += point[xField];
      sumY += point[yField];
      sumXY += point[xField] * point[yField];
      sumX2 += point[xField] * point[xField];
      sumY2 += point[yField] * point[yField];
    }
    div = (n * sumX2) - (sumX * sumX);
    intercept = ((sumY * sumX2) - (sumX * sumXY)) / div;
    slope = ((n * sumXY) - (sumX * sumY)) / div;
    rSquared = Math.pow((n * sumXY - sumX * sumY) / Math.sqrt((n * sumX2 - sumX * sumX) * (n * sumY2 - sumY * sumY)), 2);
    description = "y = " + slope + " * x + " + intercept + " with R^2 of " + rSquared;
    return {
      intercept: intercept,
      slope: slope,
      rSquared: rSquared,
      description: description
    };
  };

  exports.correlate = correlate;

}).call(this);

//# sourceMappingURL=correlate.js.map

});

require.define("/src/Classifier.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3
(function() {
  var BayesianClassifier, Classifier, OLAPCube, functions, utils,
    extend = function(child, parent) { for (var key in parent) { if (hasProp.call(parent, key)) child[key] = parent[key]; } function ctor() { this.constructor = child; } ctor.prototype = parent.prototype; child.prototype = new ctor(); child.__super__ = parent.prototype; return child; },
    hasProp = {}.hasOwnProperty;

  functions = require('./functions').functions;

  utils = require('tztime').utils;

  OLAPCube = require('./OLAPCube').OLAPCube;

  Classifier = (function() {
    function Classifier() {}


    /*
    @class Classifier
    
    __Base class for all Classifiers__
    
    See individual subclasses for usage details
     */

    Classifier.getBucketCountMinMax = function(values) {
      var max, min, targetBucketCount;
      targetBucketCount = Math.floor(Math.sqrt(values.length)) + 1;
      if (targetBucketCount < 3) {
        throw new Error("Need more training data");
      }
      min = functions.min(values);
      max = functions.max(values);
      return {
        targetBucketCount: targetBucketCount,
        min: min,
        max: max
      };
    };

    Classifier.generateConstantWidthBucketer = function(values) {
      var bucketSize, bucketer, i, j, max, min, ref, ref1, targetBucketCount;
      ref = Classifier.getBucketCountMinMax(values), targetBucketCount = ref.targetBucketCount, min = ref.min, max = ref.max;
      bucketSize = (max - min) / targetBucketCount;
      bucketer = [];
      bucketer.push({
        value: 'B' + 0,
        startOn: null,
        endBelow: min + bucketSize
      });
      for (i = j = 1, ref1 = targetBucketCount - 2; 1 <= ref1 ? j <= ref1 : j >= ref1; i = 1 <= ref1 ? ++j : --j) {
        bucketer.push({
          value: 'B' + i,
          startOn: min + bucketSize * i,
          endBelow: min + bucketSize * (i + 1)
        });
      }
      bucketer.push({
        value: 'B' + (targetBucketCount - 1),
        startOn: min + bucketSize * (targetBucketCount - 1),
        endBelow: null
      });
      return bucketer;
    };

    Classifier.generateConstantQuantityBucketer = function(values) {
      var bucketSize, bucketer, currentBoundary, i, j, lastBoundary, max, min, ref, ref1, targetBucketCount;
      ref = Classifier.getBucketCountMinMax(values), targetBucketCount = ref.targetBucketCount, min = ref.min, max = ref.max;
      bucketSize = 100 / targetBucketCount;
      bucketer = [];
      currentBoundary = functions.percentileCreator(bucketSize)(values);
      bucketer.push({
        value: 'B' + 0,
        startOn: null,
        endBelow: currentBoundary
      });
      for (i = j = 1, ref1 = targetBucketCount - 2; 1 <= ref1 ? j <= ref1 : j >= ref1; i = 1 <= ref1 ? ++j : --j) {
        lastBoundary = currentBoundary;
        currentBoundary = functions.percentileCreator(bucketSize * (i + 1))(values);
        bucketer.push({
          value: 'B' + i,
          startOn: lastBoundary,
          endBelow: currentBoundary
        });
      }
      bucketer.push({
        value: 'B' + (targetBucketCount - 1),
        startOn: currentBoundary,
        endBelow: null
      });
      return bucketer;
    };

    Classifier.splitAt = function(values, index) {
      var left, right;
      left = values.slice(0, index);
      right = values.slice(index);
      return {
        left: left,
        right: right
      };
    };

    Classifier.optimalSplitFor2Buckets = function(values) {
      var bestIndex, bestLeft, bestRight, bestTotalErrorSquared, i, j, left, ref, ref1, right, splitAt, totalErrorSquared;
      bestIndex = 1;
      bestTotalErrorSquared = Number.MAX_VALUE;
      for (i = j = 1, ref = values.length - 1; 1 <= ref ? j <= ref : j >= ref; i = 1 <= ref ? ++j : --j) {
        ref1 = Classifier.splitAt(values, i), left = ref1.left, right = ref1.right;
        totalErrorSquared = functions.errorSquared(left) + functions.errorSquared(right);
        if (totalErrorSquared < bestTotalErrorSquared) {
          bestTotalErrorSquared = totalErrorSquared;
          bestIndex = i;
          bestLeft = left;
          bestRight = right;
        }
      }
      splitAt = (values[bestIndex - 1] + values[bestIndex]) / 2;
      return {
        splitAt: splitAt,
        left: bestLeft,
        right: bestRight
      };
    };

    Classifier.areAllSame = function(values) {
      var firstValue, j, len, value;
      firstValue = values[0];
      for (j = 0, len = values.length; j < len; j++) {
        value = values[j];
        if (value !== firstValue) {
          return false;
        }
      }
      return true;
    };

    Classifier.findBucketSplits = function(currentSplits, values, targetBucketCount) {
      var left, ref, right, splitAt;
      if (values.length < 5 || Classifier.areAllSame(values)) {
        return null;
      }
      ref = Classifier.optimalSplitFor2Buckets(values), splitAt = ref.splitAt, left = ref.left, right = ref.right;
      currentSplits.push(splitAt);
      if (currentSplits.length < targetBucketCount) {
        Classifier.findBucketSplits(currentSplits, left, targetBucketCount);
        Classifier.findBucketSplits(currentSplits, right, targetBucketCount);
      }
      return currentSplits;
    };

    Classifier.generateVOptimalBucketer = function(values) {
      var bucketer, currentBoundary, i, j, lastBoundary, max, min, ref, ref1, splits, targetBucketCount;
      ref = Classifier.getBucketCountMinMax(values), targetBucketCount = ref.targetBucketCount, min = ref.min, max = ref.max;
      values.sort(function(a, b) {
        return a - b;
      });
      splits = [];
      Classifier.findBucketSplits(splits, values, targetBucketCount);
      splits.sort(function(a, b) {
        return a - b;
      });
      bucketer = [];
      currentBoundary = splits[0];
      bucketer.push({
        value: 'B' + 0,
        startOn: null,
        endBelow: currentBoundary
      });
      for (i = j = 1, ref1 = splits.length - 1; 1 <= ref1 ? j <= ref1 : j >= ref1; i = 1 <= ref1 ? ++j : --j) {
        lastBoundary = currentBoundary;
        currentBoundary = splits[i];
        bucketer.push({
          value: 'B' + i,
          startOn: lastBoundary,
          endBelow: currentBoundary
        });
      }
      bucketer.push({
        value: 'B' + splits.length,
        startOn: currentBoundary,
        endBelow: null
      });
      return bucketer;
    };

    Classifier.prototype.discreteizeRow = function(row) {
      var bin, feature, index, j, k, len, len1, ref, ref1, value;
      ref = this.features;
      for (j = 0, len = ref.length; j < len; j++) {
        feature = ref[j];
        if (feature.type === 'continuous') {
          value = row[feature.field];
          if (value == null) {
            throw new Error("Could not find field " + feature.field + " in " + (JSON.stringify(row)) + ".");
          }
          ref1 = feature.bins;
          for (index = k = 0, len1 = ref1.length; k < len1; index = ++k) {
            bin = ref1[index];
            if (bin.startOn != null) {
              if (bin.endBelow != null) {
                if ((bin.startOn <= value && value < bin.endBelow)) {
                  row[feature.field] = bin.value;
                  break;
                }
              } else if (bin.startOn <= value) {
                row[feature.field] = bin.value;
                break;
              }
            } else if (value < bin.endBelow) {
              row[feature.field] = bin.value;
              break;
            }
          }
        }
      }
      return row;
    };

    return Classifier;

  })();

  BayesianClassifier = (function(superClass) {
    extend(BayesianClassifier, superClass);


    /*
    @class BayesianClassifier
    
    __A Bayesian classifier with non-parametric modeling of distributions using v-optimal bucketing.__
    
    If you look for libraries for Bayesian classification, the primary use case is spam filtering and they assume that
    the presence or absence of a word is the only feature you are interested in. This is a more general purpose tool.
    
    ## Features ##
    
    * Works even for bi-modal and other non-normal distributions
    * No requirement that you identify the distribution
    * Uses [non-parametric modeling](http://en.wikipedia.org/wiki/Non-parametric_statistics)
    * Uses v-optimal bucketing so it deals well with outliers and sharp cliffs
    * Serialize (`getStateForSaving()`) and deserialize (`newFromSavedState()`) to preserve training between sessions
    
    ## Why the assumption of a normal distribution is bad in some cases ##
    
    The [wikipedia example of using Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Sex_classification) tries
    to determine if someone was male or female based upon the height, weight
    and shoe size. The assumption is that men are generally larger, heavier, and have larger shoe size than women. In the
    example, they use the mean and variance of the male-only and female-only populations to characterize those
    distributions. This works because these characteristics are generally normally distributed **and the distribution for
    men is generally to the right of the distribution for women**.
    
    However, let's ask a group of folks who work together if they consider themselves a team and let's try to use the size
    of the group as a feature to predict what a new group would say. If the group is very small (1-2 people), they are
    less likely to consider themselves a team (partnership maybe), but if they are too large (say > 10), they are also
    unlikely to refer to themselves as a team. The non-team distribution is bimodal, looking at its mean and variance
    completely mis-characterizes it. Also, the distribution is zero bound so it's likely to be asymmetric, which also
    poses problems for a normal distribution assumption.
    
    ## So what do we do instead? ##
    
    This classifier uses the actual sampled percentage for buckets of the data. This approach is often referred to
    as "building a non-parametric model", although "un-named distribution" strikes me a better label.
    
    **Pros/Cons**. The use of a non-parametric approach will allow us to deal with non-normal distributions (asymmetric,
    bimodal, etc.) without ever having to identify which nominal distribution is the best fit or having to ask the user
    (who may not know) what distribution to use. The downside to this approach is that it generally requires a larger
    training set. You will need to experiment to determine how small is too small for your situation.
    
    This approach is hinted at in the [wikipedia article on Bayesian classifiers](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)
    as "binning to discretize the feature values, to obtain a new set of Bernoulli-distributed features". However, this
    classifier does not create new separate Bernoulli features for each bin. Rather, it creates a mapping function from a feature
    value to a probability indicating how often the feature value is coincident with a particular outputField value. This mapping
    function is different for each bin.
    
    ## V-optimal bucketing ##
    
    There are two common approaches to bucketing:
    
    1. Make each bucket be equal in width along the x-axis (like we would for a histogram) (equi-width)
    2. Make each bucket have roughly the same number of data points (equi-depth)
    
    It turns out neither of the above works out well unless the training set is relatively large. Rather, there is an
    approach called [v-optimal bucketing](http://en.wikipedia.org/wiki/V-optimal_histograms) which attempts to find the
    optimal boundaries in the data. The basic idea is to look for the splits that provide the minimum total error-squared
    where the "error" for each point is the distance of that point from the arithmetic mean. This classifier uses v-optimal
    bucketing when the training set hass 144 or fewer rows. Above that it switches to equi-depth bucketing. Note, I only
    evaluated a single scenario (Rally RealTeam), but 144 was the point where equi-depth started to provide as-good results as
    v-optimal bucketing. Note, in my test, much larger sets had moderately _better_ results with equi-depth bucketing.
    
    The algorithm used here for v-optimal bucketing is slightly inspired by
    [this non-recursive code](http://www.mathcs.emory.edu/~cheung/Courses/584-StreamDB/Syllabus/06-Histograms/v-opt3.html).
    However, the implementation here is recursive and I've made some different choices about when to terminate the splitting. To
    understand the essence of the algorithm used, you need only look at the 9 lines of code in the `findBucketSplits()` function.
    The `optimalSplitFor2Buckets()` function will split the values into two buckets. It tries each possible split
    starting with only one in the bucket on the left all the way down to a split with only one in the bucket on the right.
    One of the design choices I made for this algorithm means that you can't precicely control the number of buckets. It
    also seems to have a tendency to create very lopsided bucketing breakdowns. The latter may be the reason that
    equi-depth bucketing has better results when there are hundreds of rows in the training
    set. We may wish to revisit this algorithm at a later time because my instinct is that there is probably some
    definition of "optimal" that is at least as good as equi-depth for large training sets. I suspect the current algorith
    favors splitting the left. A better algorithm wouldn't have a left and a right. It would find the optimal split for
    each of the current splits and take the one that gave the entire new splitting regime the lowest overall error.
    This new algorithm would be much more computationally intensive but for small training sets, I don't think it will
    be a deal breaker and we can always use equi-depth once for larger sets.
    
    ## Simple example ##
    
    First we need to require the classifier.
    
        {BayesianClassifier} = require('../')
    
    Before we start, let's take a look at our training set. The assumption is that we think TeamSize and HasChildProject
    will be predictors for RealTeam.
    
        trainingSet = [
          {TeamSize: 5, HasChildProject: 0, RealTeam: 1},
          {TeamSize: 3, HasChildProject: 1, RealTeam: 0},
          {TeamSize: 3, HasChildProject: 1, RealTeam: 1},
          {TeamSize: 1, HasChildProject: 0, RealTeam: 0},
          {TeamSize: 2, HasChildProject: 1, RealTeam: 0},
          {TeamSize: 2, HasChildProject: 0, RealTeam: 0},
          {TeamSize: 15, HasChildProject: 1, RealTeam: 0},
          {TeamSize: 27, HasChildProject: 1, RealTeam: 0},
          {TeamSize: 13, HasChildProject: 1, RealTeam: 1},
          {TeamSize: 7, HasChildProject: 0, RealTeam: 1},
          {TeamSize: 7, HasChildProject: 0, RealTeam: 0},
          {TeamSize: 9, HasChildProject: 1, RealTeam: 1},
          {TeamSize: 6, HasChildProject: 0, RealTeam: 1},
          {TeamSize: 5, HasChildProject: 0, RealTeam: 1},
          {TeamSize: 5, HasChildProject: 0, RealTeam: 0},
        ]
    
    Now, let's set up a simple config indicating our assumptions. Note how the type for TeamSize is 'continuous'
    whereas the type for HasChildProject is 'discrete' eventhough a number is stored. Continuous types must be numbers
    but discrete types can either be numbers or strings.
    
        config =
          outputField: "RealTeam"
          features: [
            {field: 'TeamSize', type: 'continuous'},
            {field: 'HasChildProject', type: 'discrete'}
          ]
    
    We can now instantiate the classifier with that config,
    
        classifier = new BayesianClassifier(config)
    
    and pass in our training set.
    
        percentWins = classifier.train(trainingSet)
    
    The call to `train()` returns the percentage of times that the trained classifier gets the right answer for the training
    set. This should usually be pretty high. Anything below say, 70% and you probably don't have the right "features"
    in your training set or you don't have enough training set data. Our made up exmple is a borderline case.
    
        console.log(percentWins)
         * 0.7333333333333333
    
    Now, let's see how the trained classifier is used to predict "RealTeam"-ness. We simply pass in an object with
    fields for each of our features. A very small team with child projects are definitely not a RealTeam.
    
        console.log(classifier.predict({TeamSize: 1, HasChildProject: 1}))
         * 0
    
    However, a mid-sized project with no child projects most certainly is a RealTeam.
    
        console.log(classifier.predict({TeamSize: 7, HasChildProject: 0}))
         * 1
    
    Here is a less obvious case, with one indicator going one way (too big) and another going the other way (no child projects).
    
        console.log(classifier.predict({TeamSize: 29, HasChildProject: 0}))
         * 0
    
    If you want to know the strength of the prediction, you can pass in `true` as the second parameter to the `predict()` method.
    
        console.log(classifier.predict({TeamSize: 29, HasChildProject: 0}, true))
         * { '0': 0.6956521739130435, '1': 0.30434782608695654 }
    
    We're only 69.6% sure this is not a RealTeam. Notice how the keys for the output are strings eventhough we passed in values
    of type Number for the RealTeam field in our training set. We had no choice in this case because keys of JavaScript
    Objects must be strings. However, the classifier is smart enough to know that you wanted
    
    Like the Lumenize calculators, you can save and restore the state of a trained classifier.
    
        savedState = classifier.getStateForSaving('some meta data')
        newClassifier = BayesianClassifier.newFromSavedState(savedState)
        console.log(newClassifier.meta)
         * some meta data
    
    It will make the same predictions.
    
        console.log(newClassifier.predict({TeamSize: 29, HasChildProject: 0}, true))
         * { '0': 0.6956521739130435, '1': 0.30434782608695654 }
     */

    function BayesianClassifier(userConfig) {
      this.userConfig = userConfig;

      /*
      @constructor
      @param {Object} userConfig See Config options for details.
      @cfg {String} outputField String indicating which field in the training set is what we are trying to predict
      @cfg {Object[]} features Array of Maps which specifies the fields to use as features. Each row in the array should
       be in the form of `{field: <fieldName>, type: <'continuous' | 'discrete'>}`. Note, that you can even declare Number type
       fields as 'discrete'. It is preferable to do this if you know that it can only be one of a hand full of values
       (0 vs 1 for example).
      
       **WARNING: If you choose 'discrete' for the feature type, then ALL possible values for that feature must appear
       in the training set. If the classifier is asked to make a prediction with a value that it has never seen
       before, it will fail catostrophically.**
       */
      this.config = utils.clone(this.userConfig);
      this.outputField = this.config.outputField;
      this.features = this.config.features;
    }

    BayesianClassifier.prototype.train = function(userSuppliedTrainingSet) {

      /*
      @method train
       Train the classifier with a training set.
      @return {Number} The percentage of time that the trained classifier returns the expected outputField for the rows
       in the training set. If this is low (say below 70%), you need more predictive fields and/or more data in your
       training set.
      @param {Object[]} userSuppliedTrainingSet an Array of Maps containing a field for the outputField as well as a field
       for each of the features specified in the config.
       */
      var bin, bucketGenerator, bucketer, countForThisValue, denominator, denominatorCell, dimensions, feature, featureCube, featureValues, filter, j, k, l, len, len1, len2, len3, len4, len5, len6, len7, loses, m, n, numerator, numeratorCell, o, outputDimension, outputValue, outputValuesCube, percentWins, prediction, q, r, ref, ref1, ref2, ref3, ref4, ref5, row, s, trainingSet, value, values, wins;
      trainingSet = utils.clone(userSuppliedTrainingSet);
      outputDimension = [
        {
          field: this.outputField
        }
      ];
      outputValuesCube = new OLAPCube({
        dimensions: outputDimension
      }, trainingSet);
      this.outputValues = outputValuesCube.getDimensionValues(this.outputField);
      this.outputFieldTypeIsNumber = true;
      ref = this.outputValues;
      for (j = 0, len = ref.length; j < len; j++) {
        value = ref[j];
        if (utils.type(value) !== 'number') {
          this.outputFieldTypeIsNumber = false;
        }
      }
      n = trainingSet.length;
      filter = {};
      this.baseProbabilities = {};
      ref1 = this.outputValues;
      for (k = 0, len1 = ref1.length; k < len1; k++) {
        outputValue = ref1[k];
        filter[this.outputField] = outputValue;
        countForThisValue = outputValuesCube.getCell(filter)._count;
        this.baseProbabilities[outputValue] = countForThisValue / n;
      }
      if (n >= 144) {
        bucketGenerator = Classifier.generateConstantQuantityBucketer;
      } else {
        bucketGenerator = Classifier.generateVOptimalBucketer;
      }
      ref2 = this.features;
      for (l = 0, len2 = ref2.length; l < len2; l++) {
        feature = ref2[l];
        if (feature.type === 'continuous') {
          values = (function() {
            var len3, m, results;
            results = [];
            for (m = 0, len3 = trainingSet.length; m < len3; m++) {
              row = trainingSet[m];
              results.push(row[feature.field]);
            }
            return results;
          })();
          bucketer = bucketGenerator(values);
          feature.bins = bucketer;
        } else if (feature.type === 'discrete') {

        } else {
          throw new Error("Unrecognized feature type: " + feature.type + ".");
        }
      }
      for (m = 0, len3 = trainingSet.length; m < len3; m++) {
        row = trainingSet[m];
        this.discreteizeRow(row);
      }
      ref3 = this.features;
      for (o = 0, len4 = ref3.length; o < len4; o++) {
        feature = ref3[o];
        dimensions = [
          {
            field: this.outputField,
            keepTotals: true
          }
        ];
        dimensions.push({
          field: feature.field
        });
        featureCube = new OLAPCube({
          dimensions: dimensions
        }, trainingSet);
        featureValues = featureCube.getDimensionValues(feature.field);
        if (feature.type === 'discrete') {
          feature.bins = (function() {
            var len5, q, results;
            results = [];
            for (q = 0, len5 = featureValues.length; q < len5; q++) {
              value = featureValues[q];
              results.push({
                value: value
              });
            }
            return results;
          })();
        }
        ref4 = feature.bins;
        for (q = 0, len5 = ref4.length; q < len5; q++) {
          bin = ref4[q];
          bin.probabilities = {};
          ref5 = this.outputValues;
          for (r = 0, len6 = ref5.length; r < len6; r++) {
            outputValue = ref5[r];
            filter = {};
            filter[feature.field] = bin.value;
            denominatorCell = featureCube.getCell(filter);
            if (denominatorCell != null) {
              denominator = denominatorCell._count;
            } else {
              denominator = 0;
            }
            filter[this.outputField] = outputValue;
            numeratorCell = featureCube.getCell(filter);
            numerator = (numeratorCell != null ? numeratorCell._count : void 0) | 0;
            bin.probabilities[outputValue] = numerator / denominator;
          }
        }
      }
      trainingSet = utils.clone(userSuppliedTrainingSet);
      wins = 0;
      loses = 0;
      for (s = 0, len7 = trainingSet.length; s < len7; s++) {
        row = trainingSet[s];
        prediction = this.predict(row);
        if (prediction === row[this.outputField]) {
          wins++;
        } else {
          loses++;
        }
      }
      percentWins = wins / (wins + loses);
      return percentWins;
    };

    BayesianClassifier.prototype.predict = function(row, returnProbabilities) {
      var bin, feature, j, k, len, len1, matchingBin, max, outputValue, outputValueForMax, probabilities, probability, ref, ref1, ref2;
      if (returnProbabilities == null) {
        returnProbabilities = false;
      }

      /*
      @method predict
       Use the trained classifier to make a prediction.
      @return {String|Number|Object} If returnProbabilities is false (the default), then it will return the prediction.
       If returnProbabilities is true, then it will return an Object indicating the probability for each possible
       outputField value.
      @param {Object} row an Object containing a field for each of the features specified by the config.
      @param {Boolean} [returnProbabilities = false] If true, then the output will indicate the probabilities of each
       possible outputField value. Otherwise, the output of a call to `predict()` will return the predicted value with
       the highest probability.
       */
      row = this.discreteizeRow(row);
      probabilities = {};
      ref = this.baseProbabilities;
      for (outputValue in ref) {
        probability = ref[outputValue];
        probabilities[outputValue] = probability;
      }
      ref1 = this.features;
      for (j = 0, len = ref1.length; j < len; j++) {
        feature = ref1[j];
        matchingBin = null;
        ref2 = feature.bins;
        for (k = 0, len1 = ref2.length; k < len1; k++) {
          bin = ref2[k];
          if (row[feature.field] === bin.value) {
            matchingBin = bin;
            break;
          }
        }
        if (matchingBin == null) {
          throw new Error("No matching bin for " + feature.field + "=" + row[feature.field] + " in the training set.");
        }
        for (outputValue in probabilities) {
          probability = probabilities[outputValue];
          probabilities[outputValue] = probability * matchingBin.probabilities[outputValue] / (probability * matchingBin.probabilities[outputValue] + (1 - probability) * (1 - matchingBin.probabilities[outputValue]));
        }
      }
      max = 0;
      outputValueForMax = null;
      for (outputValue in probabilities) {
        probability = probabilities[outputValue];
        if (probability > max) {
          max = probability;
          outputValueForMax = outputValue;
        }
      }
      if (returnProbabilities) {
        return probabilities;
      } else {
        if (this.outputFieldTypeIsNumber) {
          return Number(outputValueForMax);
        } else {
          return outputValueForMax;
        }
      }
    };

    BayesianClassifier.prototype.getStateForSaving = function(meta) {

      /*
      @method getStateForSaving
        Enables saving the state of a Classifier.
      
        See the bottom of the "Simple example" for example code of using this
        saving and restoring functionality.
      
      @param {Object} [meta] An optional parameter that will be added to the serialized output and added to the meta field
        within the deserialized Classifier
      @return {Object} Returns an Ojbect representing the state of the Classifier. This Object is suitable for saving to
        an object store. Use the static method `newFromSavedState()` with this Object as the parameter to reconstitute the Classifier.
       */
      var out;
      out = {
        userConfig: this.userConfig,
        outputField: this.outputField,
        outputValues: this.outputValues,
        outputFieldTypeIsNumber: this.outputFieldTypeIsNumber,
        baseProbabilities: this.baseProbabilities,
        features: this.features
      };
      if (meta != null) {
        out.meta = meta;
      }
      return out;
    };

    BayesianClassifier.newFromSavedState = function(p) {

      /*
      @method newFromSavedState
        Deserializes a previously stringified Classifier and returns a new Classifier.
      
        See the bottom of the "Simple example" for example code of using this
        saving and restoring functionality.
      
      @static
      @param {String/Object} p A String or Object from a previously saved Classifier state
      @return {Classifier}
       */
      var classifier;
      if (utils.type(p) === 'string') {
        p = JSON.parse(p);
      }
      classifier = new BayesianClassifier(p.userConfig);
      classifier.outputField = p.outputField;
      classifier.outputValues = p.outputValues;
      classifier.outputFieldTypeIsNumber = p.outputFieldTypeIsNumber;
      classifier.baseProbabilities = p.baseProbabilities;
      classifier.features = p.features;
      if (p.meta != null) {
        classifier.meta = p.meta;
      }
      return classifier;
    };

    return BayesianClassifier;

  })(Classifier);

  exports.Classifier = Classifier;

  exports.BayesianClassifier = BayesianClassifier;

}).call(this);

//# sourceMappingURL=Classifier.js.map

});

require.define("/src/Store.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3
(function() {
  var INFINITY, Store, Time, arrayOfMaps_To_CSVStyleArray, csvStyleArray_To_ArrayOfMaps, functions, ref, ref1, utils,
    indexOf = [].indexOf || function(item) { for (var i = 0, l = this.length; i < l; i++) { if (i in this && this[i] === item) return i; } return -1; };

  ref = require('tztime'), utils = ref.utils, Time = ref.Time;

  functions = require('./functions').functions;

  ref1 = require('./dataTransform'), arrayOfMaps_To_CSVStyleArray = ref1.arrayOfMaps_To_CSVStyleArray, csvStyleArray_To_ArrayOfMaps = ref1.csvStyleArray_To_ArrayOfMaps;

  INFINITY = '9999-01-01T00:00:00.000Z';

  Store = (function() {

    /*
    @class Store
    
    __An efficient, in-memory, datastore for snapshot data.__
    
    Note, this store takes advantage of JavaScript's prototype inheritance to store snapshots in memory. Since the next snapshot might
    only have one field different from the prior one, this saves a ton of space. There is some concern that this will
    slow down certain operations because the JavaScript engine has to search all fields in the current level before bumping up
    to the next. However, there is some evidence that modern JavaScript implementations handle this very efficiently.
    
    However, this choice means that each row in the snapshots array doesn't have all of the fields.
    
    Store keeps track of all of the fields it has seen so you can flatten a row(s) if necessary.
    
    Example:
    
        {Store} = require('../')
    
        snapshotCSVStyleArray = [
          ['RecordID', 'DefectID', 'Created_Date', 'Severity', 'Modified_Date', 'Status'],
          [         1,          1,   '2014-06-16',          5,    '2014-06-16',    'New'],
          [       100,          1,   '2014-06-16',          5,    '2014-07-17',    'In Progress'],
          [      1000,          1,   '2014-06-16',          5,    '2014-08-18',    'Done'],
        ]
    
        defects = require('../').csvStyleArray_To_ArrayOfMaps(snapshotCSVStyleArray)
    
        config =
          uniqueIDField: 'DefectID'
          validFromField: 'Modified_Date'
          idField: 'RecordID'
          defaultValues:
            Severity: 4
    
        store = new Store(config, defects)
    
        console.log(require('../').table.toString(store.snapshots, store.fields))
         * | Modified_Date            | _ValidTo                 | _PreviousValues | DefectID | RecordID | Created_Date | Severity | Status      |
         * | ------------------------ | ------------------------ | --------------- | -------- | -------- | ------------ | -------- | ----------- |
         * | 2014-06-16T00:00:00.000Z | 2014-07-17T00:00:00.000Z | [object Object] | 1        | 1        | 2014-06-16   | 5        | New         |
         * | 2014-07-17T00:00:00.000Z | 2014-08-18T00:00:00.000Z | [object Object] | 1        | 100      | 2014-06-16   | 5        | In Progress |
         * | 2014-08-18T00:00:00.000Z | 9999-01-01T00:00:00.000Z | [object Object] | 1        | 1000     | 2014-06-16   | 5        | Done        |
    
    That's pretty boring. We pretty much got out what we put in. There are a few things to notice though. First,
    Notice how the _ValidTo field is automatically set. Also, notice that it added the _PreviousValues field. This is
    a record of the immediately proceeding values for the fields that changed. In this way, the records not only
    represent the current snapshot; they also represent the state transition that occured to get into this snapshot
    state. That's what stateBoundaryCrossedFilter and other methods key off of.
    
    Also, under the covers, the prototype of each snapshot is the prior snapshot and only the fields that changed
    are actually stored in the next snapshot. So:
    
        console.log(store.snapshots[1] is store.snapshots[2].__proto__)
         * true
    
    The Store also keeps the equivalent of a database index on uniqueIDField and keeps a pointer to the last snapshot
    for each particular uniqueIDField. This provides a convenient way to do per entity analysis.
    
        console.log(store.byUniqueID['1'].snapshots[0].RecordID)
         * 1
    
        console.log(store.byUniqueID['1'].lastSnapshot.RecordID)
         * 1000
     */

    /*
    @property snapshots
    An Array of Objects
    
    The snapshots in compressed (via JavaScript inheritance) format
     */

    /*
    @property fields
    An Array of Strings
    
    The list of all fields that this Store has ever seen. Use to expand each row.
     */

    /*
    @property byUniqueID
    This is the database equivalent of an index by uniqueIDField.
    
    An Object in the form:
    
        {
          '1234': {
            snapshots: [...],
            lastSnapshot: <points to last snapshot for this uniqueID>
          },
          '7890': {
            ...
          },
          ...
        }
     */
    function Store(userConfig, snapshots) {
      this.userConfig = userConfig;

      /*
      @constructor
      
      @param {Object} config See Config options for details.
      @param {Object[]} [snapshots] Optional parameter allowing the population of the Store at instantiation.
      
      @cfg {String} [uniqueIDField = "ObjectID"] Specifies the field that identifies unique entities.
      @cfg {String} [validFromField = "_ValidFrom"]
      @cfg {String} [validToField = "_ValidTo"]
      @cfg {String} [idField = "_id"]
      @cfg {String} [tz = "GMT"]
      @cfg {Object} [defaultValues = {}] In some datastores, null numeric fields may be assumed to be zero and null
        boolean fields may be assumed to be false. Lumenize makes no such assumption and will crash if a field value
        is missing. the defaultValues becomes the root of prototype inheritance hierarchy.
       */
      this.config = utils.clone(this.userConfig);
      if (this.config.uniqueIDField == null) {
        this.config.uniqueIDField = 'ObjectID';
      }
      if (this.config.validFromField == null) {
        this.config.validFromField = '_ValidFrom';
      }
      if (this.config.validToField == null) {
        this.config.validToField = '_ValidTo';
      }
      if (this.config.tz == null) {
        this.config.tz = 'GMT';
      }
      if (this.config.defaultValues == null) {
        this.config.defaultValues = {};
      }
      this.config.defaultValues[this.config.validFromField] = new Time(1, Time.MILLISECOND).toString();
      if (this.config.idField == null) {
        this.config.idField = '_id';
      }
      this.snapshots = [];
      this.fields = [this.config.validFromField, this.config.validToField, '_PreviousValues', this.config.uniqueIDField];
      this.lastValidFrom = new Time(1, Time.MILLISECOND).toString();
      this.byUniqueID = {};
      this.addSnapshots(snapshots);
    }

    Store.prototype.addSnapshots = function(snapshots) {

      /*
      @method addSnapshots
        Adds the snapshots to the Store
      @param {Object[]} snapshots
      @chainable
      @return {Store} Returns this
       */
      var dataForUniqueID, i, key, len, newSnapshot, priorSnapshot, s, uniqueID, validFrom, validTo, value;
      snapshots = utils._.sortBy(snapshots, this.config.validFromField);
      for (i = 0, len = snapshots.length; i < len; i++) {
        s = snapshots[i];
        uniqueID = s[this.config.uniqueIDField];
        utils.assert(uniqueID != null, ("Missing " + this.config.uniqueIDField + " field in submitted snapshot: \n") + JSON.stringify(s, null, 2));
        dataForUniqueID = this.byUniqueID[uniqueID];
        if (dataForUniqueID == null) {
          dataForUniqueID = {
            snapshots: [],
            lastSnapshot: this.config.defaultValues
          };
          this.byUniqueID[uniqueID] = dataForUniqueID;
        }
        if (s[this.config.validFromField] < dataForUniqueID.lastSnapshot[this.config.validFromField]) {
          throw new Error("Got a new snapshot for a time earlier than the prior last snapshot for " + this.config.uniqueIDField + " " + uniqueID + ".");
        } else if (s[this.config.validFromField] === dataForUniqueID.lastSnapshot[this.config.validFromField]) {
          for (key in s) {
            value = s[key];
            dataForUniqueID.lastSnapshot[key] = value;
          }
        } else {
          validFrom = s[this.config.validFromField];
          validFrom = new Time(validFrom, null, this.config.tz).getISOStringInTZ(this.config.tz);
          utils.assert(validFrom >= dataForUniqueID.lastSnapshot[this.config.validFromField], "validFromField (" + validFrom + ") must be >= lastValidFrom (" + dataForUniqueID.lastSnapshot[this.config.validFromField] + ") for this entity");
          utils.assert(validFrom >= this.lastValidFrom, "validFromField (" + validFrom + ") must be >= lastValidFrom (" + this.lastValidFrom + ") for the Store");
          validTo = s[this.config.validTo];
          if (validTo != null) {
            validTo = new Time(validTo, null, this.config.tz).getISOStringInTZ(this.config.tz);
          } else {
            validTo = INFINITY;
          }
          priorSnapshot = dataForUniqueID.lastSnapshot;
          newSnapshot = {};
          newSnapshot._PreviousValues = {};
          for (key in s) {
            value = s[key];
            if (key !== this.config.validFromField && key !== this.config.validToField && key !== '_PreviousValues' && key !== this.config.uniqueIDField) {
              if (indexOf.call(this.fields, key) < 0) {
                this.fields.push(key);
              }
              if (value !== priorSnapshot[key]) {
                newSnapshot[key] = value;
                if (key !== this.config.idField) {
                  if (priorSnapshot[key] != null) {
                    newSnapshot._PreviousValues[key] = priorSnapshot[key];
                  } else {
                    newSnapshot._PreviousValues[key] = null;
                  }
                }
              }
            }
          }
          newSnapshot[this.config.uniqueIDField] = uniqueID;
          newSnapshot[this.config.validFromField] = validFrom;
          newSnapshot[this.config.validToField] = validTo;
          if (s._PreviousValues != null) {
            newSnapshot._PreviousValues = s._PreviousValues;
          }
          newSnapshot.__proto__ = priorSnapshot;
          if (priorSnapshot[this.config.validToField] === INFINITY) {
            priorSnapshot[this.config.validToField] = validFrom;
          }
          dataForUniqueID.lastSnapshot = newSnapshot;
          this.lastValidFrom = validFrom;
          this.byUniqueID[uniqueID].snapshots.push(newSnapshot);
          this.snapshots.push(newSnapshot);
        }
      }
      return this;
    };

    Store.prototype.filtered = function(filter) {

      /*
      @method filtered
        Returns the subset of the snapshots that match the filter
      @param {Function} filter
      @return {Object[]} An array of snapshots. Note, they will not be flattened so they have references to their prototypes
       */
      var i, len, ref2, result, s;
      result = [];
      ref2 = this.snapshots;
      for (i = 0, len = ref2.length; i < len; i++) {
        s = ref2[i];
        if (filter(s)) {
          result.push(s);
        }
      }
      return result;
    };

    Store.prototype.stateBoundaryCrossedFiltered = function(field, values, valueToTheRightOfBoundary, forward, assumeNullIsLowest) {
      var filter, index, left, right;
      if (forward == null) {
        forward = true;
      }
      if (assumeNullIsLowest == null) {
        assumeNullIsLowest = true;
      }

      /*
      @method stateBoundaryCrossedFiltered
        Returns the subset of the snapshots where the field transitions from the left of valueToTheRightOfBoundary to
        the right (inclusive)
      @param {String} field
      @param {String[]} values
      @param {String} valueToTheRightOfBoundary
      @param {Boolean} [forward = true] When true (the default), this will return the transitions from left to right
        However, if you set this to false, it will return the transitions right to left.
      @param {Boolean} [assumeNullIsLowest = true] Set to false if you don't want to consider transitions out of null
      @return {Object[]} An array or snapshots. Note, they will not be flattened so they have references to their prototypes
       */
      index = values.indexOf(valueToTheRightOfBoundary);
      utils.assert(index >= 0, "stateToTheRightOfBoundary must be in stateList");
      left = values.slice(0, index);
      if (assumeNullIsLowest) {
        left.unshift(null);
      }
      right = values.slice(index);
      if (forward) {
        filter = function(s) {
          var ref2, ref3;
          return s._PreviousValues.hasOwnProperty(field) && (ref2 = s._PreviousValues[field], indexOf.call(left, ref2) >= 0) && (ref3 = s[field], indexOf.call(right, ref3) >= 0);
        };
      } else {
        filter = function(s) {
          var ref2, ref3;
          return s._PreviousValues.hasOwnProperty(field) && (ref2 = s._PreviousValues[field], indexOf.call(right, ref2) >= 0) && (ref3 = s[field], indexOf.call(left, ref3) >= 0);
        };
      }
      return this.filtered(filter);
    };

    Store.prototype.stateBoundaryCrossedFilteredBothWays = function(field, values, valueToTheRightOfBoundary, assumeNullIsLowest) {
      var backward, forward;
      if (assumeNullIsLowest == null) {
        assumeNullIsLowest = true;
      }

      /*
      @method stateBoundaryCrossedFilteredBothWays
        Shortcut to stateBoundaryCrossedFiltered for when you need both directions
      @param {String} field
      @param {String[]} values
      @param {String} valueToTheRightOfBoundary
      @param {Boolean} [assumeNullIsLowest = true] Set to false if you don't want to consider transitions out of null
      @return {Object} An object with two root keys: 1) forward, 2) backward. The values are the arrays that are returned
        from stateBoundaryCrossedFiltered
       */
      forward = this.stateBoundaryCrossedFiltered(field, values, valueToTheRightOfBoundary, true, assumeNullIsLowest);
      backward = this.stateBoundaryCrossedFiltered(field, values, valueToTheRightOfBoundary, false, assumeNullIsLowest);
      return {
        forward: forward,
        backward: backward
      };
    };

    return Store;

  })();

  exports.Store = Store;

}).call(this);

//# sourceMappingURL=Store.js.map

});

require.define("/src/RandomPicker.js",function(require,module,exports,__dirname,__filename,process,global){// Generated by CoffeeScript 1.9.3
(function() {
  var RandomPicker;

  RandomPicker = (function() {

    /*
    Takes a config object like the one shown below, with the same format as is output by Lumenize.histogram()
    
        config =
          histogram: [
            { label: '< 10', count: 1 },  # histogram fields index, startOn, and endBelow are ignored, but returned by getRow() if provided
            { label: '10-20', count: 10 },
            { label: '20-30', count: 102 },
            { label: '30-40', count: 45},
            { label: '>= 40', count: 7}
          ]
    
    So that it will make more sense when used with hand generated distributions, it will also take the following
    
        config =
          distribution: [
            { value: -1.0, p: 0.25 }
            { value:  2.0, p: 0.50 },
            { value:  8.0, p: 0.25 }
          ]
    
    Note, that it runs the same exact code, just replacing what fields are used for the frequencyField and returnValueField
    Similarly, you can override these by explicitly including them in your config.
    
    Also, note that you need not worry about making your 'p' values add up to 1.0. It figures out the portion of the total
     */
    function RandomPicker(config) {
      var cumulative, i, j, k, len, len1, len2, r, ref, ref1, ref2, total;
      this.config = config;
      if (this.config.histogram != null) {
        this.table = this.config.histogram;
      } else if (this.config.distribution != null) {
        this.table = this.config.distribution;
      } else {
        throw new Error('Must provide either a histogram or distribution in your config.');
      }
      if (this.config.frequencyField == null) {
        if (this.config.histogram != null) {
          this.config.frequencyField = 'count';
        } else if (this.config.distribution != null) {
          this.config.frequencyField = 'p';
        }
      }
      if (this.config.returnValueField == null) {
        if (this.config.histogram != null) {
          this.config.returnValueField = 'label';
        } else if (this.config.distribution != null) {
          this.config.returnValueField = 'value';
        }
      }
      total = 0;
      ref = this.table;
      for (i = 0, len = ref.length; i < len; i++) {
        r = ref[i];
        total += r[this.config.frequencyField];
      }
      ref1 = this.table;
      for (j = 0, len1 = ref1.length; j < len1; j++) {
        r = ref1[j];
        r._p = r[this.config.frequencyField] / total;
      }
      cumulative = 0;
      ref2 = this.table;
      for (k = 0, len2 = ref2.length; k < len2; k++) {
        r = ref2[k];
        cumulative += r._p;
        r._pCumulative = cumulative;
      }
    }

    RandomPicker.prototype.getRow = function() {
      var i, len, n, r, ref;
      n = Math.random();
      ref = this.table;
      for (i = 0, len = ref.length; i < len; i++) {
        r = ref[i];
        if (n < r._pCumulative) {
          return r;
        }
      }
      return this.table[this.table.length - 1];
    };

    RandomPicker.prototype.get = function() {
      return this.getRow()[this.config.returnValueField];
    };

    return RandomPicker;

  })();

  exports.RandomPicker = RandomPicker;

}).call(this);

//# sourceMappingURL=RandomPicker.js.map

});
